{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911324d7-4429-41bc-b979-769a705cd945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import ast\n",
    "import os\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RAW_HANSARD_DIR = 'scraped_content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62863c6f-1940-4c06-a155-41d26bca546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportSection(Enum):\n",
    "    WRITTEN = 'Written Answers to Questions'\n",
    "    WRITTEN_NA = 'Written Answers to Questions for Oral Answer Not Answered by End of Question Time'\n",
    "    ORAL = 'Oral Answers to Questions'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759f4b8-16fc-4450-a923-8bac17a53f4f",
   "metadata": {},
   "source": [
    "**from html files, get question paragraphs and report metadata**\n",
    "\n",
    "we assume that all pqs are prefaced with #. (non sprs) or # (sprs). ignore follow up qns since we are only interested in mapping mps to topics, and the follow up qns will always be from the same mp and on the same topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0314366-9a4d-4d9e-b74d-9fd5ebfd7830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pq_paras = []\n",
    "    \n",
    "for file in os.listdir(RAW_HANSARD_DIR):\n",
    "    filepath = os.path.join(RAW_HANSARD_DIR, file)\n",
    "    if not os.path.isfile(filepath):\n",
    "        continue\n",
    " \n",
    "    # the files don't have consistent html formatting, but they fall into two major groups.\n",
    "    if file[0:4] == 'sprs':\n",
    "        is_sprs = True\n",
    "    else:\n",
    "        is_sprs = False\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        soup = bs(f, 'html.parser')\n",
    "        \n",
    "    if is_sprs:\n",
    "        # extract metadata from the table at the top of the page\n",
    "        topic_table = soup.find('table', {'class': 'topic'})\n",
    "        topic_text = topic_table.get_text()\n",
    "        \n",
    "        parl_no_label_span = re.match(r'Parliament No:', topic_text).span()\n",
    "        topic_text = topic_text[parl_no_label_span[1]:]\n",
    "        parl_no = int(re.match(r'\\d+', topic_text).group())\n",
    "\n",
    "        sit_date_label_span = re.match(r'.*Sitting Date:', topic_text).span()\n",
    "        topic_text = topic_text[sit_date_label_span[1]:]\n",
    "        sit_date = datetime.strptime(re.match(r'\\d+-\\d+-\\d+', topic_text).group(), '%d-%m-%Y')\n",
    "        \n",
    "        # extract report section via filename\n",
    "        if 'oral-answer' in file:\n",
    "            section = ReportSection.ORAL\n",
    "        elif 'written-answer-na' in file:\n",
    "            section = ReportSection.WRITTEN_NA\n",
    "        elif 'written-answer' in file:\n",
    "            section = ReportSection.WRITTEN\n",
    "        else:\n",
    "            raise 'unidentified section (sprs)'\n",
    "        \n",
    "        # extract paragraphs from report in the form of rows of table\n",
    "        report_table = soup.find('div', {'class': 'reportTable'})\n",
    "        report_table_rows = report_table.findChildren()\n",
    "\n",
    "        # find out which rows correspond to pqs and which rows don't.\n",
    "        for row in report_table_rows:\n",
    "            paragraph = row.get_text()\n",
    "            paragraph = paragraph.replace('\\xa0', ' ')\n",
    "            if not re.match(r'\\d+.{8,75} asked the .+', paragraph):\n",
    "                continue\n",
    "            paragraph_no_num = paragraph[\n",
    "                re.search('\\d+', paragraph).span()[1]:]\n",
    "            pq_paras.append((paragraph_no_num.strip(), sit_date, parl_no, section))\n",
    "    else:\n",
    "        # extract metadata from meta elements directly\n",
    "        sit_date_str = soup.find('meta', {'name': 'Sit_Date'})['content']\n",
    "        parl_no_str = soup.find('meta', {'name': 'Parl_No'})['content']\n",
    "        section_str = soup.find('meta', {'name': 'Sect_Name'})['content']\n",
    "        \n",
    "        sit_date = datetime.strptime(sit_date_str, '%Y-%m-%d')\n",
    "        parl_no = int(parl_no_str)\n",
    "        if 'NOT REACHED' in section_str:\n",
    "            section = ReportSection.WRITTEN_NA\n",
    "        elif 'ORAL' in section_str:\n",
    "            section = ReportSection.ORAL\n",
    "        elif 'WRITTEN' in section_str:\n",
    "            section = ReportSection.WRITTEN\n",
    "        else:\n",
    "            raise 'unidentified section (non sprs)'\n",
    "        \n",
    "        # extract paragraphs from table in the form of raw text (since each paragraph doesn't have its own element)\n",
    "        report_table = soup.find('div', {'class': 'reportTable'})\n",
    "        raw_text = report_table.get_text()\n",
    "        \n",
    "        # look for things like 1. 2. etc\n",
    "        first_number_dot_occurrence = re.search(r'\\d+\\. .{8,75} asked the ', raw_text)\n",
    "        \n",
    "        if not first_number_dot_occurrence:\n",
    "            continue\n",
    "\n",
    "        # cut off everything before the actual body of the text\n",
    "        raw_text = raw_text[first_number_dot_occurrence.span()[0]:]\n",
    "        \n",
    "        # formatting stuff\n",
    "        raw_text = raw_text.replace('\\n\\n', ' ')\n",
    "        raw_paras = raw_text.split('\\xa0\\xa0\\xa0\\xa0')\n",
    "        \n",
    "        new_pq_paras = list(\n",
    "            map(lambda s: (s[re.search('\\d+\\.', s).span()[1]:].strip(), sit_date, parl_no, section), # remove index, add sitting date, parl no, section\n",
    "                map(lambda s: re.sub('Column: \\d+', '', s.replace('  ', ' ').strip()), # remove column indicators and extra spaces\n",
    "                    filter(lambda para: re.match(r'\\d+\\. .{8,75} asked the ', para), raw_paras)))) # keep only paragraphs that are pqs.\n",
    "        \n",
    "        pq_paras += new_pq_paras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e9930a-84f1-483a-8415-3c2ec4d98245",
   "metadata": {},
   "source": [
    "**for merging with mps.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce675208-2543-4282-8a8f-eeb5d78f77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_df = pd.read_csv('mps.csv')\n",
    "mp_df.Party = mp_df.Party.apply(ast.literal_eval)\n",
    "mp_df.Parliaments = mp_df.Parliaments.apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9092638-96ca-46f6-8d9d-231cddbf0c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Party</th>\n",
       "      <th>Parliaments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Nithiah Nandan</td>\n",
       "      <td>[Nominated Member of Parliament]</td>\n",
       "      <td>(10,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Rahim Ishak</td>\n",
       "      <td>[People's Action Party]</td>\n",
       "      <td>(1, 2, 3, 4, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A.P. Rajah</td>\n",
       "      <td>[Independent Singapore Party Alliance]</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbas Abu Amin</td>\n",
       "      <td>[People's Action Party]</td>\n",
       "      <td>(5, 6, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abdul Aziz Karim</td>\n",
       "      <td>[People's Action Party]</td>\n",
       "      <td>(2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Zainul Abidin Rasheed</td>\n",
       "      <td>[People's Action Party]</td>\n",
       "      <td>(9, 10, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Zaqy Mohamad</td>\n",
       "      <td>[People's Action Party]</td>\n",
       "      <td>(11, 12, 13, 14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Zhulkarnain Abdul Rahim</td>\n",
       "      <td>[People's Action Party]</td>\n",
       "      <td>(14,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Zulkifli Bin Baharudin</td>\n",
       "      <td>[Nominated Member of Parliament]</td>\n",
       "      <td>(9,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Zulkifli Bin Mohamed</td>\n",
       "      <td>[People's Action Party]</td>\n",
       "      <td>(6, 7, 8)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>452 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name                                   Party  \\\n",
       "0           A Nithiah Nandan        [Nominated Member of Parliament]   \n",
       "1             A. Rahim Ishak                 [People's Action Party]   \n",
       "2                 A.P. Rajah  [Independent Singapore Party Alliance]   \n",
       "3             Abbas Abu Amin                 [People's Action Party]   \n",
       "4           Abdul Aziz Karim                 [People's Action Party]   \n",
       "..                       ...                                     ...   \n",
       "447    Zainul Abidin Rasheed                 [People's Action Party]   \n",
       "448             Zaqy Mohamad                 [People's Action Party]   \n",
       "449  Zhulkarnain Abdul Rahim                 [People's Action Party]   \n",
       "450   Zulkifli Bin Baharudin        [Nominated Member of Parliament]   \n",
       "451     Zulkifli Bin Mohamed                 [People's Action Party]   \n",
       "\n",
       "          Parliaments  \n",
       "0               (10,)  \n",
       "1     (1, 2, 3, 4, 5)  \n",
       "2              (0, 1)  \n",
       "3           (5, 6, 7)  \n",
       "4              (2, 3)  \n",
       "..                ...  \n",
       "447       (9, 10, 11)  \n",
       "448  (11, 12, 13, 14)  \n",
       "449             (14,)  \n",
       "450              (9,)  \n",
       "451         (6, 7, 8)  \n",
       "\n",
       "[452 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24dd9ce2-310e-44af-af6d-46d9406751a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mps = dict(\n",
    "    zip(mp_df.Name.apply(lambda x: x.lower()), # keys\n",
    "    zip(mp_df.Name, mp_df.Party, mp_df.Parliaments))) # values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a41c038-c9f4-4b92-9313-fe5fccdab091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for matching honorific+name in report to actual mp data.\n",
    "# cannot simply remove honorific as the programmer doesn't have an exhaustive list\n",
    "# of honorifics, and some are quite rare in everyday use (e.g. Inche Rahamat Bin Kenap).\n",
    "def honorific_name_to_mp_data(honorific_name):\n",
    "    honorific_name = honorific_name.lower()\n",
    "    \n",
    "    # try the easy way first (find and remove honorific)\n",
    "    honorific_match = re.match(r'(mr|mrs|ms|mdm|dr|prof|assoc prof|assoc prof dr|inche)', honorific_name)\n",
    "    if honorific_match:\n",
    "        name = honorific_name[honorific_match.span()[1]+1:]\n",
    "        if name in mps.keys():\n",
    "            return mps[name]\n",
    "        \n",
    "    # the hard way (levenshtein)\n",
    "    mp_names = list(mps.keys())\n",
    "    min_levenshtein = 99999\n",
    "    min_ind = -1\n",
    "    for i in range(len(mp_names)):\n",
    "        l_dist = levenshtein(mp_names[i], honorific_name)\n",
    "        if l_dist < min_levenshtein:\n",
    "            min_levenshtein = l_dist\n",
    "            min_ind = i\n",
    "    print(f'levenshtein matched {honorific_name} to {mp_names[min_ind]}')\n",
    "    return mps[mp_names[min_ind]]\n",
    "\n",
    "\n",
    "# borrowed from: https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/\n",
    "# we use levenshtein as it helps to protect against typos too, like the \"asked asked\" in:\n",
    "# https://sprs.parl.gov.sg/search/sprs3topic?reportid=oral-answer-2822\n",
    "def levenshtein(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc215967-6862-42e1-ab49-d2a3d863e567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "levenshtein matched prof lee shienloong to lee hsien loong\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Lee Hsien Loong',\n",
       " [\"People's Action Party\"],\n",
       " (6, 7, 8, 9, 10, 11, 12, 13, 14))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "honorific_name_to_mp_data('Prof Lee Shienloong')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fedc2b-7594-4b25-8313-d8977d25a4ea",
   "metadata": {},
   "source": [
    "**from question paragraphs, get askers, askees, questions**\n",
    "\n",
    "notes regarding minister titles:\n",
    "* Minister for Culture, Community and Youth is the only minister title with a comma\n",
    "* no questions were ever directed to minister mentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8845b9a4-aee1-407e-b23a-47ce3ac4b2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "levenshtein matched mr zhulkarnain abdul rahim asked to zhulkarnain abdul rahim\n",
      "levenshtein matched mr murali pillai to murali pillai sc\n"
     ]
    }
   ],
   "source": [
    "cap_word = r'[A-Z][a-z]+'\n",
    "cap_words = f'({cap_word})( {cap_word})*'\n",
    "mccy = 'Minister for Culture, Community and Youth'\n",
    "minister_for_something = f'({cap_words} )?Minister for {cap_words}( and (the )?{cap_words})?'\n",
    "something_minister = f'{cap_words} Minister'\n",
    "minister_regex = re.compile(f'(({mccy})|({minister_for_something})|({something_minister}))')\n",
    "\n",
    "pqs = []\n",
    "\n",
    "for pq_para in pq_paras:\n",
    "    para = pq_para[0]\n",
    "    asker_honorific_name, para = para.split(' asked the ', 1)\n",
    "    minister_match = re.search(minister_regex, para)\n",
    "    askee = para[:minister_match.span()[1]]\n",
    "    question = para[minister_match.span()[1]:].strip()\n",
    "    asker, asker_party, asker_parls = honorific_name_to_mp_data(asker_honorific_name)\n",
    "    pqs.append([asker, asker_party, asker_parls, askee, question, *pq_para[1:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883514f5-2bfa-4845-b83e-3d4cfbb4c88e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
