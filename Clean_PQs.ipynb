{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911324d7-4429-41bc-b979-769a705cd945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import os\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import re\n",
    "\n",
    "RAW_HANSARD_DIR = 'scraped_content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62863c6f-1940-4c06-a155-41d26bca546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportSection(Enum):\n",
    "    WRITTEN = 'Written Answers to Questions'\n",
    "    WRITTEN_NA = 'Written Answers to Questions for Oral Answer Not Answered by End of Question Time'\n",
    "    ORAL = 'Oral Answers to Questions'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759f4b8-16fc-4450-a923-8bac17a53f4f",
   "metadata": {},
   "source": [
    "**from html files, get question paragraphs and report metadata**\n",
    "\n",
    "we assume that all pqs are prefaced with #. (non sprs) or # (sprs). ignore follow up qns since we are only interested in mapping mps to topics, and the follow up qns will always be from the same mp and on the same topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0314366-9a4d-4d9e-b74d-9fd5ebfd7830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pq_paras = []\n",
    "    \n",
    "for file in os.listdir(RAW_HANSARD_DIR):\n",
    "    filepath = os.path.join(RAW_HANSARD_DIR, file)\n",
    "    if not os.path.isfile(filepath):\n",
    "        continue\n",
    " \n",
    "    # the files don't have consistent html formatting, but they fall into two major groups.\n",
    "    if file[0:4] == 'sprs':\n",
    "        is_sprs = True\n",
    "    else:\n",
    "        is_sprs = False\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        soup = bs(f, 'html.parser')\n",
    "        \n",
    "    if is_sprs:\n",
    "        # extract metadata from the table at the top of the page\n",
    "        topic_table = soup.find('table', {'class': 'topic'})\n",
    "        topic_text = topic_table.get_text()\n",
    "        \n",
    "        parl_no_label_span = re.match(r'Parliament No:', topic_text).span()\n",
    "        topic_text = topic_text[parl_no_label_span[1]:]\n",
    "        parl_no = int(re.match(r'\\d+', topic_text).group())\n",
    "\n",
    "        sit_date_label_span = re.match(r'.*Sitting Date:', topic_text).span()\n",
    "        topic_text = topic_text[sit_date_label_span[1]:]\n",
    "        sit_date = datetime.strptime(re.match(r'\\d+-\\d+-\\d+', topic_text).group(), '%d-%m-%Y')\n",
    "        \n",
    "        # extract report section via filename\n",
    "        if 'oral-answer' in file:\n",
    "            section = ReportSection.ORAL\n",
    "        elif 'written-answer-na' in file:\n",
    "            section = ReportSection.WRITTEN_NA\n",
    "        elif 'written-answer' in file:\n",
    "            section = ReportSection.WRITTEN\n",
    "        else:\n",
    "            raise 'unidentified section (sprs)'\n",
    "        \n",
    "        # extract paragraphs from report in the form of rows of table\n",
    "        report_table = soup.find('div', {'class': 'reportTable'})\n",
    "        report_table_rows = report_table.findChildren()\n",
    "\n",
    "        # find out which rows correspond to pqs and which rows don't.\n",
    "        for row in report_table_rows:\n",
    "            paragraph = row.get_text()\n",
    "            paragraph = paragraph.replace('\\xa0', ' ')\n",
    "            if not re.match(r'\\d+.{8,75} asked the .+', paragraph):\n",
    "                continue\n",
    "            paragraph_no_num = paragraph[\n",
    "                re.search('\\d+', paragraph).span()[1]:]\n",
    "            pq_paras.append((paragraph_no_num.strip(), sit_date, parl_no, section))\n",
    "    else:\n",
    "        # extract metadata from meta elements directly\n",
    "        sit_date_str = soup.find('meta', {'name': 'Sit_Date'})['content']\n",
    "        parl_no_str = soup.find('meta', {'name': 'Parl_No'})['content']\n",
    "        section_str = soup.find('meta', {'name': 'Sect_Name'})['content']\n",
    "        \n",
    "        sit_date = datetime.strptime(sit_date_str, '%Y-%m-%d')\n",
    "        parl_no = int(parl_no_str)\n",
    "        if 'NOT REACHED' in section_str:\n",
    "            section = ReportSection.WRITTEN_NA\n",
    "        elif 'ORAL' in section_str:\n",
    "            section = ReportSection.ORAL\n",
    "        elif 'WRITTEN' in section_str:\n",
    "            section = ReportSection.WRITTEN\n",
    "        else:\n",
    "            raise 'unidentified section (non sprs)'\n",
    "        \n",
    "        # extract paragraphs from table in the form of raw text (since each paragraph doesn't have its own element)\n",
    "        report_table = soup.find('div', {'class': 'reportTable'})\n",
    "        raw_text = report_table.get_text()\n",
    "        \n",
    "        # look for things like 1. 2. etc\n",
    "        first_number_dot_occurrence = re.search(r'\\d+\\. .{8,75} asked the ', raw_text)\n",
    "        \n",
    "        if not first_number_dot_occurrence:\n",
    "            continue\n",
    "\n",
    "        # cut off everything before the actual body of the text\n",
    "        raw_text = raw_text[first_number_dot_occurrence.span()[0]:]\n",
    "        \n",
    "        # formatting stuff\n",
    "        raw_text = raw_text.replace('\\n\\n', ' ')\n",
    "        raw_paras = raw_text.split('\\xa0\\xa0\\xa0\\xa0')\n",
    "        \n",
    "        new_pq_paras = list(\n",
    "            map(lambda s: (s[re.search('\\d+\\.', s).span()[1]:].strip(), sit_date, parl_no, section), # remove index, add sitting date, parl no, section\n",
    "                map(lambda s: re.sub('Column: \\d+', '', s.replace('  ', ' ').strip()), # remove column indicators and extra spaces\n",
    "                    filter(lambda para: re.match(r'\\d+\\. .{8,75} asked the ', para), raw_paras)))) # keep only paragraphs that are pqs.\n",
    "        \n",
    "        pq_paras += new_pq_paras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fedc2b-7594-4b25-8313-d8977d25a4ea",
   "metadata": {},
   "source": [
    "**from question paragraphs, get askers, askees, questions**\n",
    "\n",
    "notes regarding minister titles:\n",
    "* Minister for Culture, Community and Youth is the only minister title with a comma\n",
    "* no questions were ever directed to minister mentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8845b9a4-aee1-407e-b23a-47ce3ac4b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_word = r'[A-Z][a-z]+'\n",
    "cap_words = f'({cap_word})( {cap_word})*'\n",
    "mccy = 'Minister for Culture, Community and Youth'\n",
    "minister_for_something = f'({cap_words} )?Minister for {cap_words}( and (the )?{cap_words})?'\n",
    "something_minister = f'{cap_words} Minister'\n",
    "minister_regex = re.compile(f'(({mccy})|({minister_for_something})|({something_minister}))')\n",
    "\n",
    "pqs = []\n",
    "\n",
    "for pq_para in pq_paras:\n",
    "    para = pq_para[0]\n",
    "    asker, para = para.split(' asked the ', 1)\n",
    "    minister_match = re.search(minister_regex, para)\n",
    "    askee = para[:minister_match.span()[1]]\n",
    "    question = para[minister_match.span()[1]:].strip()\n",
    "    pqs.append([asker, askee, question, *pq_para[1:]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e76f1a-e626-442d-8346-fd5ca6345477",
   "metadata": {},
   "source": [
    "**merging with mps.csv into single csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b071e44-4eb9-47d3-a79e-3326746df212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
