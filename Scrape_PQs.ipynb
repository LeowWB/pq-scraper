{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this nb is responsible for scraping the data and handling all the messy html stuff. gives you a csv file containing the pq paragraphs and a bit of metadata.\n",
    "\n",
    "sometimes code is too fast for browser driver. in such cases, try increasing sleep time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import datetime\n",
    "import math\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time \n",
    "import os\n",
    "from enum import Enum\n",
    "import re\n",
    "import pandas as pd\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportSection(Enum):\n",
    "    WRITTEN = 'Written Answers to Questions'\n",
    "    WRITTEN_NA = 'Written Answers to Questions for Oral Answer Not Answered by End of Question Time'\n",
    "    ORAL = 'Oral Answers to Questions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVER_PATH = 'chromedriver_win32/chromedriver.exe'\n",
    "SEARCH_TERM = 'asked the' # can be blank\n",
    "# PARLIAMENT_INDEX = -1 # legislative assembly = 1, 1st parliament = 2, etc etc. -1 to ignore this field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_completely_viewable(driver, elem):\n",
    "    elem_left_bound = elem.location.get('x')\n",
    "    elem_top_bound = elem.location.get('y')\n",
    "    elem_width = elem.size.get('width')\n",
    "    elem_height = elem.size.get('height')\n",
    "    elem_right_bound = elem_left_bound + elem_width\n",
    "    elem_lower_bound = elem_top_bound + elem_height\n",
    "\n",
    "    win_upper_bound = driver.execute_script('return window.pageYOffset')\n",
    "    win_left_bound = driver.execute_script('return window.pageXOffset')\n",
    "    win_width = driver.execute_script('return document.documentElement.clientWidth')\n",
    "    win_height = driver.execute_script('return document.documentElement.clientHeight')\n",
    "    win_right_bound = win_left_bound + win_width\n",
    "    win_lower_bound = win_upper_bound + win_height\n",
    "\n",
    "    return all((win_left_bound <= elem_left_bound,\n",
    "                win_right_bound >= elem_right_bound,\n",
    "                win_upper_bound <= elem_top_bound,\n",
    "                win_lower_bound >= elem_lower_bound)\n",
    "              )\n",
    "\n",
    "def find_element(driver, elem):\n",
    "    y_height = 0\n",
    "    while not element_completely_viewable(driver, elem):\n",
    "        driver.execute_script(f\"window.scrollTo(0, {y_height})\") \n",
    "        y_height += 300\n",
    "        time.sleep(0.25)\n",
    "\n",
    "def find_and_click(driver, elem):\n",
    "    find_element(driver, elem)\n",
    "    if element_completely_viewable(driver, elem):\n",
    "        elem.click()\n",
    "    else:\n",
    "        print('finding and clicking agn')\n",
    "        find_and_click(driver, elem)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thisi\\AppData\\Local\\Temp\\ipykernel_23620\\1286528577.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(DRIVER_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search parameters submitted.\n",
      "11904 results found spanning 596 page(s)\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(DRIVER_PATH) \n",
    " \n",
    "page_url = 'https://sprs.parl.gov.sg/search/home' \n",
    "driver.get(page_url) \n",
    "driver.maximize_window() \n",
    "driver.implicitly_wait(20) \n",
    "time.sleep(2) \n",
    " \n",
    "# Get search box and fill it up \n",
    "\n",
    "search = driver.find_element(by=By.XPATH, value='/html/body/app-root/app-search/div/div[2]/div[2]/div[1]/div/div[1]/input')\n",
    "search.send_keys(SEARCH_TERM) \n",
    "\n",
    "# exact phrase search\n",
    "\n",
    "search_opt = driver.find_element(by=By.XPATH, value='/html/body/app-root/app-search/div/div[2]/div[2]/div[2]/div/div[1]/select')\n",
    "find_and_click(driver, search_opt)\n",
    "exact_search_opt = driver.find_element(by=By.XPATH, value='//*[@id=\"divmpscreen2\"]/div[2]/div[2]/div/div[1]/select/option[3]')\n",
    "find_and_click(driver, exact_search_opt)\n",
    " \n",
    "# Uncomment following two lines to only search in titles # \n",
    "#checkbox = driver.find_element_by_xpath('//*[@id=\"divmpscreen2\"]/div[2]/div[1]/div/label/input')\n",
    "#checkbox.click() \n",
    "\n",
    "# from 1st parliament to 14th. ignore legis. assembly cuz the parl website has no list of members.\n",
    "for i in range(2, 16):\n",
    "    session = driver.find_element(\n",
    "        by=By.XPATH, \n",
    "        value=f'/html/body/app-root/app-search/div/div[2]/div[2]/div[1]/div/div[3]/select/option[{i}]')\n",
    "    session.click() \n",
    " \n",
    "# advanced search - only look for oral and written answers to questions\n",
    "\n",
    "adv_search_opt = driver.find_element(by=By.XPATH, value='/html/body/app-root/app-search/div/div[3]/div/div[1]/h5/a')\n",
    "find_and_click(driver, adv_search_opt)\n",
    "section_selection = driver.find_element(by=By.XPATH, value='/html/body/app-root/app-search/div/div[3]/div/div[2]/div/div/div/div/div[3]/div/select')\n",
    "find_element(driver, section_selection)\n",
    "for selection_option_index in [13, 19, 20]: # corresponds to answers to questions    \n",
    "    option = driver.find_element(\n",
    "        by=By.XPATH, \n",
    "        value=f'/html/body/app-root/app-search/div/div[3]/div/div[2]/div/div/div/div/div[3]/div/select/option[{selection_option_index}]')\n",
    "    option.click()\n",
    "\n",
    "\n",
    "# Find submit element and press enter\n",
    "\n",
    "submit = driver.find_element(by=By.XPATH, value='/html/body/app-root/app-search/div/div[2]/div[2]/div[3]/div/button[2]') \n",
    "submit.send_keys(Keys.RETURN) \n",
    "\n",
    "print('Search parameters submitted.') \n",
    "\n",
    "# Switch window and check for number of search results \n",
    "\n",
    "driver.switch_to.window(driver.window_handles[1])\n",
    "driver.implicitly_wait(20) \n",
    "time.sleep(2) \n",
    "\n",
    "try:\n",
    "    num_res_label = driver.find_element(by=By.CLASS_NAME, value='showingResults')\n",
    "except: \n",
    "    print('Error when finding num_res_label')\n",
    "    \n",
    "num_res_text = num_res_label.get_attribute('innerHTML')\n",
    "    \n",
    "if 'No' in num_res_text:\n",
    "    print('no results found') # but site is quite erratic, may take a few tries to get results (idk why)\n",
    "else:\n",
    "    num_results = int(num_res_text[num_res_text.rfind(' ')+1:])\n",
    "    num_pages = math.ceil(num_results / 20)\n",
    "    print(f'{num_results} results found spanning {num_pages} page(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5299\n"
     ]
    }
   ],
   "source": [
    "pq_paras = pd.read_csv('pq_paras.csv').values.tolist()\n",
    "print(len(pq_paras))\n",
    "docs_saved = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n",
      "Seen 1 / 596 pages\n",
      "skipping\n",
      "Seen 2 / 596 pages\n",
      "skipping\n",
      "Seen 3 / 596 pages\n",
      "skipping\n",
      "Seen 4 / 596 pages\n",
      "skipping\n",
      "Seen 5 / 596 pages\n",
      "skipping\n",
      "Seen 6 / 596 pages\n",
      "skipping\n",
      "Seen 7 / 596 pages\n",
      "skipping\n",
      "Seen 8 / 596 pages\n",
      "skipping\n",
      "Seen 9 / 596 pages\n",
      "skipping\n",
      "Seen 10 / 596 pages\n",
      "skipping\n",
      "Seen 11 / 596 pages\n",
      "skipping\n",
      "Seen 12 / 596 pages\n",
      "skipping\n",
      "Seen 13 / 596 pages\n",
      "skipping\n",
      "Seen 14 / 596 pages\n",
      "skipping\n",
      "Seen 15 / 596 pages\n",
      "skipping\n",
      "Seen 16 / 596 pages\n",
      "skipping\n",
      "Seen 17 / 596 pages\n",
      "skipping\n",
      "Seen 18 / 596 pages\n",
      "skipping\n",
      "Seen 19 / 596 pages\n",
      "skipping\n",
      "Seen 20 / 596 pages\n",
      "skipping\n",
      "Seen 21 / 596 pages\n",
      "skipping\n",
      "Seen 22 / 596 pages\n",
      "skipping\n",
      "Seen 23 / 596 pages\n",
      "skipping\n",
      "Seen 24 / 596 pages\n",
      "skipping\n",
      "Seen 25 / 596 pages\n",
      "skipping\n",
      "Seen 26 / 596 pages\n",
      "skipping\n",
      "Seen 27 / 596 pages\n",
      "skipping\n",
      "Seen 28 / 596 pages\n",
      "skipping\n",
      "Seen 29 / 596 pages\n",
      "skipping\n",
      "Seen 30 / 596 pages\n",
      "skipping\n",
      "Seen 31 / 596 pages\n",
      "skipping\n",
      "Seen 32 / 596 pages\n",
      "skipping\n",
      "Seen 33 / 596 pages\n",
      "skipping\n",
      "Seen 34 / 596 pages\n",
      "skipping\n",
      "Seen 35 / 596 pages\n",
      "skipping\n",
      "Seen 36 / 596 pages\n",
      "skipping\n",
      "Seen 37 / 596 pages\n",
      "skipping\n",
      "Seen 38 / 596 pages\n",
      "skipping\n",
      "Seen 39 / 596 pages\n",
      "skipping\n",
      "Seen 40 / 596 pages\n",
      "skipping\n",
      "Seen 41 / 596 pages\n",
      "skipping\n",
      "Seen 42 / 596 pages\n",
      "skipping\n",
      "Seen 43 / 596 pages\n",
      "skipping\n",
      "Seen 44 / 596 pages\n",
      "skipping\n",
      "Seen 45 / 596 pages\n",
      "skipping\n",
      "Seen 46 / 596 pages\n",
      "skipping\n",
      "Seen 47 / 596 pages\n",
      "skipping\n",
      "Seen 48 / 596 pages\n",
      "skipping\n",
      "Seen 49 / 596 pages\n",
      "skipping\n",
      "Seen 50 / 596 pages\n",
      "skipping\n",
      "Seen 51 / 596 pages\n",
      "skipping\n",
      "Seen 52 / 596 pages\n",
      "skipping\n",
      "Seen 53 / 596 pages\n",
      "skipping\n",
      "Seen 54 / 596 pages\n",
      "skipping\n",
      "Seen 55 / 596 pages\n",
      "skipping\n",
      "Seen 56 / 596 pages\n",
      "skipping\n",
      "Seen 57 / 596 pages\n",
      "skipping\n",
      "Seen 58 / 596 pages\n",
      "skipping\n",
      "Seen 59 / 596 pages\n",
      "skipping\n",
      "Seen 60 / 596 pages\n",
      "skipping\n",
      "Seen 61 / 596 pages\n",
      "skipping\n",
      "Seen 62 / 596 pages\n",
      "skipping\n",
      "Seen 63 / 596 pages\n",
      "skipping\n",
      "Seen 64 / 596 pages\n",
      "skipping\n",
      "Seen 65 / 596 pages\n",
      "skipping\n",
      "Seen 66 / 596 pages\n",
      "skipping\n",
      "Seen 67 / 596 pages\n",
      "skipping\n",
      "Seen 68 / 596 pages\n",
      "skipping\n",
      "Seen 69 / 596 pages\n",
      "skipping\n",
      "Seen 70 / 596 pages\n",
      "skipping\n",
      "Seen 71 / 596 pages\n",
      "skipping\n",
      "Seen 72 / 596 pages\n",
      "skipping\n",
      "Seen 73 / 596 pages\n",
      "skipping\n",
      "Seen 74 / 596 pages\n",
      "skipping\n",
      "Seen 75 / 596 pages\n",
      "skipping\n",
      "Seen 76 / 596 pages\n",
      "skipping\n",
      "Seen 77 / 596 pages\n",
      "skipping\n",
      "Seen 78 / 596 pages\n",
      "skipping\n",
      "Seen 79 / 596 pages\n",
      "skipping\n",
      "Seen 80 / 596 pages\n",
      "skipping\n",
      "Seen 81 / 596 pages\n",
      "skipping\n",
      "Seen 82 / 596 pages\n",
      "skipping\n",
      "Seen 83 / 596 pages\n",
      "skipping\n",
      "Seen 84 / 596 pages\n",
      "skipping\n",
      "Seen 85 / 596 pages\n",
      "skipping\n",
      "Seen 86 / 596 pages\n",
      "skipping\n",
      "Seen 87 / 596 pages\n",
      "skipping\n",
      "Seen 88 / 596 pages\n",
      "skipping\n",
      "Seen 89 / 596 pages\n",
      "skipping\n",
      "Seen 90 / 596 pages\n",
      "skipping\n",
      "Seen 91 / 596 pages\n",
      "skipping\n",
      "Seen 92 / 596 pages\n",
      "skipping\n",
      "Seen 93 / 596 pages\n",
      "skipping\n",
      "Seen 94 / 596 pages\n",
      "skipping\n",
      "Seen 95 / 596 pages\n",
      "skipping\n",
      "Seen 96 / 596 pages\n",
      "skipping\n",
      "Seen 97 / 596 pages\n",
      "skipping\n",
      "Seen 98 / 596 pages\n",
      "skipping\n",
      "Seen 99 / 596 pages\n",
      "skipping\n",
      "Seen 100 / 596 pages\n",
      "skipping\n",
      "Seen 101 / 596 pages\n",
      "skipping\n",
      "Seen 102 / 596 pages\n",
      "skipping\n",
      "Seen 103 / 596 pages\n",
      "skipping\n",
      "Seen 104 / 596 pages\n",
      "skipping\n",
      "Seen 105 / 596 pages\n",
      "skipping\n",
      "Seen 106 / 596 pages\n",
      "skipping\n",
      "Seen 107 / 596 pages\n",
      "skipping\n",
      "Seen 108 / 596 pages\n",
      "skipping\n",
      "Seen 109 / 596 pages\n",
      "skipping\n",
      "Seen 110 / 596 pages\n",
      "skipping\n",
      "Seen 111 / 596 pages\n",
      "skipping\n",
      "Seen 112 / 596 pages\n",
      "skipping\n",
      "Seen 113 / 596 pages\n",
      "skipping\n",
      "Seen 114 / 596 pages\n",
      "skipping\n",
      "Seen 115 / 596 pages\n",
      "skipping\n",
      "Seen 116 / 596 pages\n",
      "skipping\n",
      "Seen 117 / 596 pages\n",
      "skipping\n",
      "Seen 118 / 596 pages\n",
      "skipping\n",
      "Seen 119 / 596 pages\n",
      "skipping\n",
      "Seen 120 / 596 pages\n",
      "skipping\n",
      "Seen 121 / 596 pages\n",
      "skipping\n",
      "Seen 122 / 596 pages\n",
      "skipping\n",
      "Seen 123 / 596 pages\n",
      "skipping\n",
      "Seen 124 / 596 pages\n",
      "skipping\n",
      "Seen 125 / 596 pages\n",
      "skipping\n",
      "Seen 126 / 596 pages\n",
      "skipping\n",
      "Seen 127 / 596 pages\n",
      "skipping\n",
      "Seen 128 / 596 pages\n",
      "skipping\n",
      "Seen 129 / 596 pages\n",
      "skipping\n",
      "Seen 130 / 596 pages\n",
      "skipping\n",
      "Seen 131 / 596 pages\n",
      "skipping\n",
      "Seen 132 / 596 pages\n",
      "skipping\n",
      "Seen 133 / 596 pages\n",
      "skipping\n",
      "Seen 134 / 596 pages\n",
      "skipping\n",
      "Seen 135 / 596 pages\n",
      "skipping\n",
      "Seen 136 / 596 pages\n",
      "skipping\n",
      "Seen 137 / 596 pages\n",
      "skipping\n",
      "Seen 138 / 596 pages\n",
      "skipping\n",
      "Seen 139 / 596 pages\n",
      "skipping\n",
      "Seen 140 / 596 pages\n",
      "skipping\n",
      "Seen 141 / 596 pages\n",
      "skipping\n",
      "Seen 142 / 596 pages\n",
      "skipping\n",
      "Seen 143 / 596 pages\n",
      "skipping\n",
      "Seen 144 / 596 pages\n",
      "skipping\n",
      "Seen 145 / 596 pages\n",
      "skipping\n",
      "Seen 146 / 596 pages\n",
      "skipping\n",
      "Seen 147 / 596 pages\n",
      "skipping\n",
      "Seen 148 / 596 pages\n",
      "skipping\n",
      "Seen 149 / 596 pages\n",
      "skipping\n",
      "Seen 150 / 596 pages\n",
      "skipping\n",
      "Seen 151 / 596 pages\n",
      "skipping\n",
      "Seen 152 / 596 pages\n",
      "skipping\n",
      "Seen 153 / 596 pages\n",
      "skipping\n",
      "Seen 154 / 596 pages\n",
      "skipping\n",
      "Seen 155 / 596 pages\n",
      "skipping\n",
      "Seen 156 / 596 pages\n",
      "skipping\n",
      "Seen 157 / 596 pages\n",
      "skipping\n",
      "Seen 158 / 596 pages\n",
      "skipping\n",
      "Seen 159 / 596 pages\n",
      "skipping\n",
      "Seen 160 / 596 pages\n",
      "skipping\n",
      "Seen 161 / 596 pages\n",
      "skipping\n",
      "Seen 162 / 596 pages\n",
      "skipping\n",
      "Seen 163 / 596 pages\n",
      "skipping\n",
      "Seen 164 / 596 pages\n",
      "skipping\n",
      "Seen 165 / 596 pages\n",
      "skipping\n",
      "Seen 166 / 596 pages\n",
      "skipping\n",
      "Seen 167 / 596 pages\n",
      "skipping\n",
      "Seen 168 / 596 pages\n",
      "skipping\n",
      "Seen 169 / 596 pages\n",
      "skipping\n",
      "Seen 170 / 596 pages\n",
      "skipping\n",
      "Seen 171 / 596 pages\n",
      "skipping\n",
      "Seen 172 / 596 pages\n",
      "skipping\n",
      "Seen 173 / 596 pages\n",
      "skipping\n",
      "Seen 174 / 596 pages\n",
      "skipping\n",
      "Seen 175 / 596 pages\n",
      "skipping\n",
      "Seen 176 / 596 pages\n",
      "skipping\n",
      "Seen 177 / 596 pages\n",
      "skipping\n",
      "Seen 178 / 596 pages\n",
      "skipping\n",
      "Seen 179 / 596 pages\n",
      "skipping\n",
      "Seen 180 / 596 pages\n",
      "skipping\n",
      "Seen 181 / 596 pages\n",
      "skipping\n",
      "Seen 182 / 596 pages\n",
      "skipping\n",
      "Seen 183 / 596 pages\n",
      "skipping\n",
      "Seen 184 / 596 pages\n",
      "skipping\n",
      "Seen 185 / 596 pages\n",
      "skipping\n",
      "Seen 186 / 596 pages\n",
      "skipping\n",
      "Seen 187 / 596 pages\n",
      "skipping\n",
      "Seen 188 / 596 pages\n",
      "skipping\n",
      "Seen 189 / 596 pages\n",
      "skipping\n",
      "Seen 190 / 596 pages\n",
      "skipping\n",
      "Seen 191 / 596 pages\n",
      "skipping\n",
      "Seen 192 / 596 pages\n",
      "skipping\n",
      "Seen 193 / 596 pages\n",
      "skipping\n",
      "Seen 194 / 596 pages\n",
      "skipping\n",
      "Seen 195 / 596 pages\n",
      "skipping\n",
      "Seen 196 / 596 pages\n",
      "skipping\n",
      "Seen 197 / 596 pages\n",
      "skipping\n",
      "Seen 198 / 596 pages\n",
      "skipping\n",
      "Seen 199 / 596 pages\n",
      "skipping\n",
      "Seen 200 / 596 pages\n",
      "skipping\n",
      "Seen 201 / 596 pages\n",
      "skipping\n",
      "Seen 202 / 596 pages\n",
      "skipping\n",
      "Seen 203 / 596 pages\n",
      "skipping\n",
      "Seen 204 / 596 pages\n",
      "skipping\n",
      "Seen 205 / 596 pages\n",
      "skipping\n",
      "Seen 206 / 596 pages\n",
      "skipping\n",
      "Seen 207 / 596 pages\n",
      "skipping\n",
      "Seen 208 / 596 pages\n",
      "skipping\n",
      "Seen 209 / 596 pages\n",
      "skipping\n",
      "Seen 210 / 596 pages\n",
      "skipping\n",
      "Seen 211 / 596 pages\n",
      "skipping\n",
      "Seen 212 / 596 pages\n",
      "skipping\n",
      "Seen 213 / 596 pages\n",
      "skipping\n",
      "Seen 214 / 596 pages\n",
      "skipping\n",
      "Seen 215 / 596 pages\n",
      "skipping\n",
      "Seen 216 / 596 pages\n",
      "skipping\n",
      "Seen 217 / 596 pages\n",
      "skipping\n",
      "Seen 218 / 596 pages\n",
      "skipping\n",
      "Seen 219 / 596 pages\n",
      "skipping\n",
      "Seen 220 / 596 pages\n",
      "skipping\n",
      "Seen 221 / 596 pages\n",
      "skipping\n",
      "Seen 222 / 596 pages\n",
      "skipping\n",
      "Seen 223 / 596 pages\n",
      "skipping\n",
      "Seen 224 / 596 pages\n",
      "skipping\n",
      "Seen 225 / 596 pages\n",
      "skipping\n",
      "Seen 226 / 596 pages\n",
      "skipping\n",
      "Seen 227 / 596 pages\n",
      "skipping\n",
      "Seen 228 / 596 pages\n",
      "skipping\n",
      "Seen 229 / 596 pages\n",
      "skipping\n",
      "Seen 230 / 596 pages\n",
      "skipping\n",
      "Seen 231 / 596 pages\n",
      "skipping\n",
      "Seen 232 / 596 pages\n",
      "skipping\n",
      "Seen 233 / 596 pages\n",
      "skipping\n",
      "Seen 234 / 596 pages\n",
      "skipping\n",
      "Seen 235 / 596 pages\n",
      "skipping\n",
      "Seen 236 / 596 pages\n",
      "skipping\n",
      "Seen 237 / 596 pages\n",
      "skipping\n",
      "Seen 238 / 596 pages\n",
      "skipping\n",
      "Seen 239 / 596 pages\n",
      "skipping\n",
      "Seen 240 / 596 pages\n",
      "skipping\n",
      "Seen 241 / 596 pages\n",
      "skipping\n",
      "Seen 242 / 596 pages\n",
      "skipping\n",
      "Seen 243 / 596 pages\n",
      "skipping\n",
      "Seen 244 / 596 pages\n",
      "can't find a single table, page is probably empty https://sprs.parl.gov.sg/search/topic?reportid=008_10090119_S0006_T0003\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 4900 / 11904 docs at 1132\n",
      "Seen 245 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 4920 / 11904 docs at 1133\n",
      "Seen 246 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 4940 / 11904 docs at 1133\n",
      "Seen 247 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 4960 / 11904 docs at 1134\n",
      "Seen 248 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 4980 / 11904 docs at 1135\n",
      "Seen 249 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5000 / 11904 docs at 1136\n",
      "Seen 250 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 Saved 5020 / 11904 docs at 1137\n",
      "Seen 251 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5040 / 11904 docs at 1138\n",
      "Seen 252 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5060 / 11904 docs at 1139\n",
      "Seen 253 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5080 / 11904 docs at 1140\n",
      "Seen 254 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5100 / 11904 docs at 1141\n",
      "Seen 255 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5120 / 11904 docs at 1142\n",
      "Seen 256 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5140 / 11904 docs at 1143\n",
      "Seen 257 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5160 / 11904 docs at 1144\n",
      "Seen 258 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5180 / 11904 docs at 1144\n",
      "Seen 259 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5200 / 11904 docs at 1145\n",
      "Seen 260 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5220 / 11904 docs at 1146\n",
      "Seen 261 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5240 / 11904 docs at 1147\n",
      "Seen 262 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5260 / 11904 docs at 1148\n",
      "Seen 263 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5280 / 11904 docs at 1149\n",
      "Seen 264 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5300 / 11904 docs at 1150\n",
      "Seen 265 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5320 / 11904 docs at 1151\n",
      "Seen 266 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5340 / 11904 docs at 1152\n",
      "Seen 267 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5360 / 11904 docs at 1154\n",
      "Seen 268 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5380 / 11904 docs at 1155\n",
      "Seen 269 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5400 / 11904 docs at 1156\n",
      "Seen 270 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5420 / 11904 docs at 1157\n",
      "Seen 271 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5440 / 11904 docs at 1158\n",
      "Seen 272 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5460 / 11904 docs at 1159\n",
      "Seen 273 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5480 / 11904 docs at 1200\n",
      "Seen 274 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5500 / 11904 docs at 1201\n",
      "Seen 275 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5520 / 11904 docs at 1202\n",
      "Seen 276 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5540 / 11904 docs at 1203\n",
      "Seen 277 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5560 / 11904 docs at 1204\n",
      "Seen 278 / 596 pages\n",
      "1 1 1 1 1 1 can't find a single table, page is probably empty https://sprs.parl.gov.sg/search/topic?reportid=009_10041117_S0003_T0007\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5580 / 11904 docs at 1205\n",
      "Seen 279 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5600 / 11904 docs at 1206\n",
      "Seen 280 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5620 / 11904 docs at 1207\n",
      "Seen 281 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5640 / 11904 docs at 1208\n",
      "Seen 282 / 596 pages\n",
      "1 1 1 1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 Saved 5660 / 11904 docs at 1209\n",
      "Seen 283 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5680 / 11904 docs at 1210\n",
      "Seen 284 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 Saved 5700 / 11904 docs at 1211\n",
      "Seen 285 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5720 / 11904 docs at 1212\n",
      "Seen 286 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5740 / 11904 docs at 1213\n",
      "Seen 287 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5760 / 11904 docs at 1214\n",
      "Seen 288 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5780 / 11904 docs at 1215\n",
      "Seen 289 / 596 pages\n",
      "1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 Saved 5800 / 11904 docs at 1216\n",
      "Seen 290 / 596 pages\n",
      "1 1 1 1 1 1 3 1 1 1 1 1 1 1 3 1 1 1 1 1 Saved 5820 / 11904 docs at 1217\n",
      "Seen 291 / 596 pages\n",
      "1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5840 / 11904 docs at 1218\n",
      "Seen 292 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5860 / 11904 docs at 1219\n",
      "Seen 293 / 596 pages\n",
      "1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 6 1 1 1 1 Saved 5880 / 11904 docs at 1220\n",
      "Seen 294 / 596 pages\n",
      "1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 Saved 5900 / 11904 docs at 1221\n",
      "Seen 295 / 596 pages\n",
      "4 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 Saved 5920 / 11904 docs at 1222\n",
      "Seen 296 / 596 pages\n",
      "1 1 1 1 1 2 1 1 1 1 1 1 1 3 1 1 1 1 1 1 Saved 5940 / 11904 docs at 1223\n",
      "Seen 297 / 596 pages\n",
      "1 1 1 1 1 1 3 1 1 1 1 2 1 1 1 1 1 1 1 1 Saved 5960 / 11904 docs at 1224\n",
      "Seen 298 / 596 pages\n",
      "1 1 2 1 2 1 7 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 5980 / 11904 docs at 1225\n",
      "Seen 299 / 596 pages\n",
      "1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 6000 / 11904 docs at 1226\n",
      "Seen 300 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 6020 / 11904 docs at 1227\n",
      "Seen 301 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 2 1 1 3 1 1 1 1 1 Saved 6040 / 11904 docs at 1228\n",
      "Seen 302 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 6060 / 11904 docs at 1229\n",
      "Seen 303 / 596 pages\n",
      "1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 6080 / 11904 docs at 1230\n",
      "Seen 304 / 596 pages\n",
      "1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Saved 6100 / 11904 docs at 1231\n",
      "Seen 305 / 596 pages\n",
      "1 1 1 1 1 1 exception'NoneType' object has no attribute 'span'\n",
      "> \u001b[1;32mc:\\users\\thisi\\appdata\\local\\temp\\ipykernel_23620\\2082298540.py\u001b[0m(181)\u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  continue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 1 1 2 2 1 1 1 1 3 1 Saved 6120 / 11904 docs at 1254\n",
      "Seen 306 / 596 pages\n",
      "1 1 1 1 1 1 1 1 1 1 "
     ]
    }
   ],
   "source": [
    "docs_to_skip = 4881 # should set to 0. use this if it crashes halfway.\n",
    "docs_saved = 0\n",
    "pages_seen = 0\n",
    "\n",
    "while (True):\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    \n",
    "    if docs_to_skip < 20:\n",
    "\n",
    "        elems = driver.find_elements(by=By.XPATH, value='/html/body/app-root/app-result/div/div/div[2]/div/div/div/div/div/div[1]/table/tbody')\n",
    "        links = list(map(lambda elem: elem.find_elements(by=By.XPATH, value='.//tr[1]/td[2]/a')[0], elems))\n",
    "\n",
    "        for link in links:\n",
    "            if docs_to_skip > 0:\n",
    "                docs_to_skip -= 1\n",
    "                docs_saved += 1\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                find_and_click(driver, link)\n",
    "\n",
    "                # Switch to page with content and get URL name\n",
    "                time.sleep(1)\n",
    "                while len(driver.window_handles) < 3:\n",
    "                    find_and_click(driver, link)\n",
    "                    print(f'trying this link agn')\n",
    "                    time.sleep(2)\n",
    "\n",
    "                driver.switch_to.window(driver.window_handles[2])         \n",
    "                item_key = driver.current_url.split('/')[-1]         \n",
    "                item_key = item_key.replace('?', '_') # Replace ? because it would be an invalid filename \n",
    "\n",
    "                file = item_key\n",
    "                page_source = driver.page_source\n",
    "\n",
    "                if file[0:4] == 'sprs':\n",
    "                    is_sprs = True\n",
    "                else:\n",
    "                    is_sprs = False\n",
    "\n",
    "                soup = bs(page_source, 'html.parser')\n",
    "                \n",
    "                if not soup.find('table'):\n",
    "                    # trust me, this happens. do exact phrase search for \"MISSELLING OF STRUCTURED PRODUCTS BY FINANCIAL INSTITUTIONS (UPDATE ON INVESTIGATION BY MAS)\"\n",
    "                    print(f\"can't find a single table, page is probably empty {driver.current_url}\")\n",
    "                    docs_saved += 1\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(driver.window_handles[1])\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "\n",
    "                if is_sprs:\n",
    "                    # extract metadata from the table at the top of the page\n",
    "                    topic_table = soup.find('table', {'class': 'topic'})\n",
    "                    topic_text = topic_table.get_text()\n",
    "\n",
    "                    parl_no_label_span = re.match(r'Parliament No:', topic_text).span()\n",
    "                    topic_text = topic_text[parl_no_label_span[1]:]\n",
    "                    parl_no = int(re.match(r'\\d+', topic_text).group())\n",
    "\n",
    "                    sit_date_label_span = re.match(r'.*Sitting Date:', topic_text).span()\n",
    "                    topic_text = topic_text[sit_date_label_span[1]:]\n",
    "                    sit_date = datetime.strptime(re.match(r'\\d+-\\d+-\\d+', topic_text).group(), '%d-%m-%Y')\n",
    "\n",
    "                    # extract report section via filename\n",
    "                    if 'oral-answer' in file:\n",
    "                        section = ReportSection.ORAL\n",
    "                    elif 'written-answer-na' in file:\n",
    "                        section = ReportSection.WRITTEN_NA\n",
    "                    elif 'written-answer' in file:\n",
    "                        section = ReportSection.WRITTEN\n",
    "                    else:\n",
    "                        raise 'unidentified section (sprs)'\n",
    "                    section = section.value\n",
    "\n",
    "                    # extract paragraphs from report in the form of rows of table\n",
    "                    report_table = soup.find('div', {'class': 'reportTable'})\n",
    "                    report_table_rows = report_table.findChildren()\n",
    "\n",
    "                    # find out which rows correspond to pqs and which rows don't.\n",
    "                    for row in report_table_rows:\n",
    "                        paragraph = row.get_text()\n",
    "                        paragraph = paragraph.replace('\\xa0', ' ')\n",
    "                        if not re.match(r'\\d+.{8,75} asked the .+', paragraph):\n",
    "                            continue\n",
    "                        paragraph_no_num = paragraph[\n",
    "                            re.search('\\d+', paragraph).span()[1]:]\n",
    "                        pq_paras.append((paragraph_no_num.strip(), sit_date, parl_no, section))\n",
    "                else:\n",
    "                    # extract metadata from meta elements directly\n",
    "                    sit_date_elem = soup.find('meta', {'name': 'Sit_Date'})\n",
    "                    parl_no_elem = soup.find('meta', {'name': 'Parl_No'})\n",
    "                    section_elem = soup.find('meta', {'name': 'Sect_Name'})\n",
    "                    \n",
    "                    if sit_date_elem:\n",
    "                        sit_date_str = sit_date_elem['content']\n",
    "                        sit_date = datetime.strptime(sit_date_str, '%Y-%m-%d')\n",
    "                    else:\n",
    "                        # i didn't wanna have this block but apparently the meta element isn't always there\n",
    "                        sit_date_str = driver.find_element(\n",
    "                            by=By.XPATH, \n",
    "                            value='/html/body/app-root/app-topic/div[2]/div/div/div/div/div[2]/div/div/div/div/div/table/tbody/tr/td/table/tbody/tr[5]/td[2]/font'\n",
    "                        ).get_attribute('innerHTML')\n",
    "                        sit_date = datetime.strptime(sit_date_str, '%d-%m-%Y')\n",
    "                        \n",
    "                    if parl_no_elem:\n",
    "                        parl_no_str = parl_no_elem['content']\n",
    "                    else:\n",
    "                        # i didn't wanna have this block but apparently the meta element isn't always there\n",
    "                        parl_no_str = driver.find_element(\n",
    "                            by=By.XPATH, \n",
    "                            value='/html/body/app-root/app-topic/div[2]/div/div/div/div/div[2]/div/div/div/div/div/table/tbody/tr/td/table/tbody/tr[1]/td[2]/font'\n",
    "                        ).get_attribute('innerHTML')\n",
    "                        \n",
    "                    if section_elem:\n",
    "                        section_str = section_elem['content']\n",
    "                    else:\n",
    "                        # i didn't wanna have this block but apparently the meta element isn't always there\n",
    "                        section_str = driver.find_element(\n",
    "                            by=By.XPATH, \n",
    "                            value='/html/body/app-root/app-topic/div[2]/div/div/div/div/div[2]/div/div/div/div/div/table/tbody/tr/td/table/tbody/tr[6]/td[2]/font'\n",
    "                        ).get_attribute('innerHTML')\n",
    "\n",
    "                    parl_no = int(parl_no_str)\n",
    "                    if 'NOT REACHED' in section_str or 'Not' in section_str:\n",
    "                        section = ReportSection.WRITTEN_NA\n",
    "                    elif 'ORAL' in section_str or 'Oral' in section_str:\n",
    "                        section = ReportSection.ORAL\n",
    "                    elif 'WRITTEN' in section_str or 'Written' in section_str:\n",
    "                        section = ReportSection.WRITTEN\n",
    "                    else:\n",
    "                        raise 'unidentified section (non sprs)'\n",
    "                    section = section.value\n",
    "\n",
    "                    # extract paragraphs from table in the form of raw text (since each paragraph doesn't have its own element)\n",
    "                    report_table = soup.find('div', {'class': 'reportTable'})\n",
    "                    if not report_table:\n",
    "                        print('no report table')\n",
    "                        raw_text = soup.get_text()\n",
    "                    else:\n",
    "                        raw_text = report_table.get_text()\n",
    "\n",
    "                    # look for things like 1. 2. etc\n",
    "                    first_number_dot_occurrence = re.search(r'\\d+\\.(\\s+)(.|\\s){8,75}(\\s+)asked(\\s+)the(\\s+)', raw_text)\n",
    "\n",
    "                    # cuz apparently sprs doesn't guarantee a dot being there.\n",
    "                    if not first_number_dot_occurrence:\n",
    "                        first_number_dot_occurrence = re.search(r'\\d+(\\s+)(.|\\s){8,75}(\\s+)asked(\\s+)the(\\s+)', raw_text)\n",
    "\n",
    "                    # cut off everything before the actual body of the text\n",
    "                    raw_text = raw_text[first_number_dot_occurrence.span()[0]:]\n",
    "\n",
    "                    # formatting stuff\n",
    "                    if '\\xa0' in raw_text:\n",
    "                        raw_text = raw_text.replace('\\n\\n', ' ')\n",
    "                        raw_paras = raw_text.split('\\xa0\\xa0\\xa0\\xa0')\n",
    "                    else:\n",
    "                        raw_paras = raw_text.split('\\n\\n')\n",
    "\n",
    "                    new_pq_paras = list(\n",
    "                        map(lambda s: (s[re.search('\\d+(\\.)?', s).span()[1]:].strip(), sit_date, parl_no, section), # remove index, add sitting date, parl no, section\n",
    "                            map(lambda s: re.sub('Column:(\\s+)\\d+', '', s.replace('  ', ' ').replace('\\n', ' ').strip()), # remove column indicators and extra spaces\n",
    "                                filter(lambda para: re.match(r'\\d+(\\.)?(\\s+)(.|\\s){8,75}(\\s+)asked(\\s+)the(\\s+)', para), raw_paras)))) # keep only paragraphs that are pqs.\n",
    "                    \n",
    "                    pq_paras += new_pq_paras\n",
    "                    print(str(len(new_pq_paras)) + ' ', end='')\n",
    "\n",
    "                docs_saved += 1\n",
    "                if docs_saved % 20 == 0:\n",
    "                    print(f'Saved {docs_saved} / {num_results} docs at {datetime.now().strftime(\"%H%M\")}')\n",
    "\n",
    "                # Close tab         \n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[1])\n",
    "                time.sleep(1)\n",
    "            except Exception as e:\n",
    "                print('exception' + str(e))\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "                \n",
    "                docs_saved += 1\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[1])\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "    else:\n",
    "        docs_saved += 20\n",
    "        docs_to_skip -= 20\n",
    "        print('skipping')\n",
    "        \n",
    "    if docs_saved == num_results:\n",
    "        break\n",
    "    elif docs_saved == 20: # if we're on the first results page then there is no previous page button\n",
    "        next_page = driver.find_element(\n",
    "            by=By.XPATH, \n",
    "            value='/html/body/app-root/app-result/div/div/div[2]/div/div/div/div/div/div[1]/div[3]/section/ul/li[1]/a')\n",
    "    else: # if we're not on the first results page then there is a previous page button\n",
    "        next_page = driver.find_element(\n",
    "            by=By.XPATH, \n",
    "            value='/html/body/app-root/app-result/div/div/div[2]/div/div/div/div/div/div[1]/div[3]/section/ul/li[3]/a')\n",
    "    \n",
    "    find_and_click(driver, next_page)\n",
    "    pages_seen += 1\n",
    "    print(f'Seen {pages_seen} / {num_pages} pages')\n",
    "\n",
    "    # Sleep momentarily because next page takes a while to load     \n",
    "    time.sleep(2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_paras_df = pd.DataFrame(pq_paras, columns=['para', 'sit_date', 'parl_no', 'section'])\n",
    "pq_paras_df.to_csv('pq_paras.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_saved, len(pq_paras)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
