{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbdbd63a-9d50-493b-967f-0078c4e50214",
   "metadata": {},
   "source": [
    "run the mp scraper one and the actual hansard scraper one. then you'll have some html files of hansard and a csv file of mps. then run this nb.\n",
    "\n",
    "if u wanna find code that deals w edge cases, find comments that start with \"edge case\". examples are given. i started writing those comments q l8 tho so i don't guarantee that i commented on all of them. \n",
    "\n",
    "also admittedly the code isn't written v well cuz my priority is to make it work. ig i can make it nice if i have extra time but deadlines and all :skull\n",
    "\n",
    "**the csv file you get from this is delimited by '|'. if reading with code make sure u account for that. if opening in excel, follow these instrns (https://support.affinity.co/hc/en-us/articles/360044453711-How-to-open-CSV-files-with-the-correct-delimiter-separator).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911324d7-4429-41bc-b979-769a705cd945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import ast\n",
    "import os\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pdb import set_trace as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e9930a-84f1-483a-8415-3c2ec4d98245",
   "metadata": {},
   "source": [
    "**for merging with mps.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce675208-2543-4282-8a8f-eeb5d78f77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_df = pd.read_csv('mps.csv')\n",
    "mp_df.Parliaments = mp_df.Parliaments.apply(ast.literal_eval)\n",
    "mps = dict(\n",
    "    zip(mp_df.Name.apply(lambda x: x.replace('.', '').replace(',', '').lower()), # keys\n",
    "    zip(mp_df.Name, mp_df.Party, mp_df.Parliaments))) # values\n",
    "mp_names = list(mps.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c72765-1e10-4f66-b0c5-de5d4ad837c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alr_matched = set() # honorific+names that have alr been matched to names so we don't spam the print\n",
    "ministers_found = set() # minister titles that have alr been found (to be used for future searches in case of typos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a41c038-c9f4-4b92-9313-fe5fccdab091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge case: (topic_reportid=004_20111020_S0007_T0001.html). see, told u some honorifics r rly rare.\n",
    "honorific_regex = r'(mrs|mr|ms|miss|mdm|er dr|er|assoc prof dr|assoc prof|asst prof|prof|dr|inche|encik|bg \\[ns\\]|mg \\[ns\\]|lg \\[ns\\]|gen \\[ns\\]|col \\[ns\\]|ltc \\[ns\\]|bg|mg|lg|gen|col|ltc)'\n",
    "honorific_bracket_regex = f'\\({honorific_regex} .+\\)'\n",
    "    \n",
    "# for matching honorific+name in report to actual mp data.\n",
    "# cannot simply remove honorific as the programmer doesn't have an exhaustive list\n",
    "# of honorifics, and some are quite rare in everyday use (e.g. Inche Rahamat Bin Kenap).\n",
    "def honorific_name_to_mp_data(honorific_name):\n",
    "    honorific_name = honorific_name.replace('.','').replace(',','').replace(':','').lower().strip()\n",
    "    honorific_name = re.sub('\\(.+\\)', '', honorific_name)\n",
    "    \n",
    "    # try the easy way first (find and remove honorific)\n",
    "    honorific_match = re.match(honorific_regex, honorific_name)\n",
    "    if honorific_match:\n",
    "        name = honorific_name[honorific_match.span()[1]+1:]\n",
    "        if name in mps.keys():\n",
    "            return mps[name]\n",
    "        \n",
    "        # seems quite common for them to write \"asked\" twice in the hansard proceedings\n",
    "        last_asked = name.rfind(' asked')\n",
    "        if last_asked and name[:last_asked] in mps.keys():\n",
    "            return mps[name[:last_asked]]\n",
    "\n",
    "        # slightly harder way (rearranging words)\n",
    "        for mp_name in mp_names:\n",
    "            mp_name_words = set(mp_name.split(' '))\n",
    "            name_words = set(name.split(' '))\n",
    "            if mp_name_words == name_words:\n",
    "                if (honorific_name, mp_name) not in alr_matched:\n",
    "                    #print(f'rearranging matched {honorific_name} to {mp_name}')\n",
    "                    alr_matched.add((honorific_name, mp_name))\n",
    "                return mps[mp_name]\n",
    "            \n",
    "            # for omission of chinese name\n",
    "            if len(mp_name_words) - len(name_words) <= 2 and len(name_words) >= 2 and name_words.issubset(mp_name_words):\n",
    "                if (honorific_name, mp_name) not in alr_matched:\n",
    "                    print(f'allowing omitted words in name matched {honorific_name} to {mp_name}')\n",
    "                    alr_matched.add((honorific_name, mp_name))\n",
    "                return mps[mp_name]\n",
    "                \n",
    "    digit_match = re.search('\\d+', honorific_name)\n",
    "    if digit_match:\n",
    "        # names shldn't have digits\n",
    "        honorific_name = honorific_name[digit_match.span()[1]:]\n",
    "        return honorific_name_to_mp_data(honorific_name)\n",
    "        \n",
    "    # the hard way (levenshtein)\n",
    "    closest_name = levenshtein_best_match(honorific_name, mp_names)\n",
    "    \n",
    "    if (honorific_name, closest_name) not in alr_matched:\n",
    "        print(f'levenshtein matched {honorific_name} to {closest_name}')\n",
    "        if re.sub('[A-Za-z]+', '', honorific_name) == honorific_name:\n",
    "            assert False, 'might wna check this out'\n",
    "        alr_matched.add((honorific_name, closest_name))\n",
    "    return mps[closest_name]\n",
    "\n",
    "def levenshtein_best_match(value, options):\n",
    "    min_levenshtein = 99999\n",
    "    min_val = None\n",
    "    for option in options:\n",
    "        l_dist = levenshtein(option, value)\n",
    "        if l_dist < min_levenshtein:\n",
    "            min_levenshtein = l_dist\n",
    "            min_val = option\n",
    "    return min_val\n",
    "            \n",
    "\n",
    "# borrowed from: https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/\n",
    "# we use levenshtein as it helps to protect against typos too, like the \"asked asked\" in:\n",
    "# https://sprs.parl.gov.sg/search/sprs3topic?reportid=oral-answer-2822\n",
    "def levenshtein(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2eee96-c726-4f73-a0ab-a5b630687de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pqs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b55804-1d18-45fa-8518-78a1bacdc56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportSection(Enum):\n",
    "    WRITTEN = 'Written Answers to Questions'\n",
    "    WRITTEN_NA = 'Written Answers to Questions for Oral Answer Not Answered by End of Question Time'\n",
    "    ORAL = 'Oral Answers to Questions'\n",
    "    BUDGET = 'Budget'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd366a7a-0882-4584-a7ec-423a6a23fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_word = r'[A-Z][a-z]+'\n",
    "cap_words = f'({cap_word})( {cap_word})*'\n",
    "mccy = '(Acting )?Minister for Culture, Community and Youth'\n",
    "mica = '(Acting )?Minister for Information, Communications and the Arts'\n",
    "mcdys = '(Acting )?Minister for Community Development, Youth( and|,) Sports'\n",
    "micma = 'Minister-in-charge of Muslim Affairs'\n",
    "minister_for_something = f'({cap_words} )?Minister( of State)? (for|of) (the )?{cap_words}( and (the )?{cap_words})?( \\({cap_words}( and {cap_words})?\\))?'\n",
    "something_minister = f'{cap_words} Minister'\n",
    "one_minister_regex = f'(({mccy})|({mica})|({mcdys})|({micma})|({minister_for_something})|({something_minister}))'\n",
    "minister_regex = re.compile(f'{one_minister_regex}( and (the )?{one_minister_regex})?') # can have multiple targets\n",
    "\n",
    "def first_two_capitalized(words):\n",
    "    return words[0][0].isupper() and words[1][0].isupper() and words[0][1] and words[0][1].islower()\n",
    "\n",
    "def trim_off_non_pq_content_at_start(para):\n",
    "    para_words = para.split(' ')\n",
    "    if first_two_capitalized(para_words):\n",
    "        return para\n",
    "    \n",
    "    # i assume honorific+name has at least two words capitalized and non-numbers\n",
    "    while not first_two_capitalized(para_words):\n",
    "        para_words = para_words[1:]\n",
    "    \n",
    "    return ' '.join(para_words)\n",
    "\n",
    "# extracts the first substring which is a substring of ministers\n",
    "def extract_first_ministers(para):\n",
    "    minister_match = re.search(minister_regex, para)\n",
    "    if not minister_match:\n",
    "        # report might've been in the wrong case; try to match to existing ministers\n",
    "        minister_match = re.search(\n",
    "            '(' + '|'.join(list(map(lambda s: s.lower().replace(' for ', '.{1,5}'), ministers_found))) + ')',\n",
    "            para.lower()\n",
    "        )\n",
    "        if not minister_match:\n",
    "            minister_match = re.search(\n",
    "            '(' + '|'.join(list(map(lambda s: s.lower().replace(' for ', '(\\s)*(for|of)(\\s)*'), ministers_found))) + ')',\n",
    "            para.lower()\n",
    "        )\n",
    "        if not minister_match:\n",
    "            for existing_minister in ministers_found:\n",
    "                if existing_minister.replace(' ', '') in para.replace(' ', ''):\n",
    "                    minister_match = re.search('(\\s)?'.join(c for c in existing_minister.replace(' ', '').lower()), para.lower())\n",
    "                    break\n",
    "        minister = levenshtein_best_match(minister_match.group(), ministers_found)\n",
    "        print(f'found minister: {str(minister_match.group())}; matched to {minister}')\n",
    "    else:\n",
    "        minister = para[:minister_match.span()[1]].replace(' of ', ' for ').replace('for State', 'of State')\n",
    "        ministers_found.add(minister)\n",
    "\n",
    "    para = para.replace(minister_match.group(), '').strip()\n",
    "\n",
    "    if ' and Leader' in minister:\n",
    "        minister = minister[:-11]\n",
    "\n",
    "    if minister[:4] == 'The ':\n",
    "        minister = minister[4:]\n",
    "    \n",
    "    # edge cases: (sprs3topic_reportid=written-answer-na-7122)\n",
    "    minister = minister.replace('Trade Industry', 'Trade and Industry')\n",
    "    \n",
    "    while not minister[-1].isalpha() and minister[-1] != ')':\n",
    "        minister = minister[:-1]\n",
    "    \n",
    "    return minister, para\n",
    "\n",
    "def parse_speaker_title_honorific_name(speaker):\n",
    "    honorific_bracket_search = re.search(honorific_bracket_regex, speaker.lower())\n",
    "    honorific_name = speaker[honorific_bracket_search.span()[0]+1 : honorific_bracket_search.span()[1]-1].strip()\n",
    "    responder_title = re.sub(honorific_bracket_regex, '', speaker, flags=re.IGNORECASE).replace(' of ', ' for ').replace('for State', 'of State').strip()\n",
    "    if responder_title[:4] == 'The ':\n",
    "        responder_title = responder_title[4:].strip()\n",
    "    return honorific_name, responder_title\n",
    "\n",
    "def get_ministers_and_question(para):\n",
    "    askee, question = extract_first_ministers(para)\n",
    "    \n",
    "    if not re.search('and (the )?Minister', askee):\n",
    "        return (askee,), question   \n",
    "    else:\n",
    "        askee = askee.replace('and the Minister', 'and Minister')\n",
    "        askees = askee.split(' and Minister')\n",
    "        return (askees[0], 'Minister' + askees[1]), question\n",
    "\n",
    "def get_section_name(section_name_raw):\n",
    "    if 'answered' in section_name_raw:\n",
    "        return ReportSection.WRITTEN_NA\n",
    "    elif 'written' in section_name_raw:\n",
    "        return ReportSection.WRITTEN\n",
    "    elif 'oral' in section_name_raw:\n",
    "        return ReportSection.ORAL\n",
    "    elif 'budget' in section_name_raw:\n",
    "        return ReportSection.BUDGET\n",
    "    else:\n",
    "        raise f'no section name??? {section_name_raw}'\n",
    "\n",
    "# for budget cut usage\n",
    "def is_useful_speaker_spoken(ss):\n",
    "    if 'Chairman' in ss[0] or 'Speaker' in ss[0]:\n",
    "        return False\n",
    "    \n",
    "    if len(ss[1]) > 300:\n",
    "        return True\n",
    "    \n",
    "    if len(ss[1]) < 75:\n",
    "        return False\n",
    "    \n",
    "    for substr in ['withdraw', 'beg leave', 'please', 'permission', 'cuts']:\n",
    "        if substr in ss[1]:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "        \n",
    "ministry_keywords_dict = {\n",
    "    'MCCY': ['Muslim Affairs', 'Culture', 'Youth', 'Sports','Community'], \n",
    "    'MOT':['Transport'], \n",
    "    'MINDEF':['Defence'],\n",
    "    'MinLaw':['Law'], \n",
    "    'MTI':['Trade and Industry'], \n",
    "    'MOM':['Manpower'], \n",
    "    'MND':['National Development'], \n",
    "    'MHA':['Home Affairs'],\n",
    "    'MOH':['Health'], \n",
    "    'MFA':['Foreign Affairs'], \n",
    "    'MSF':['Social and Family Development','Social Services Integration'], \n",
    "    'MOF':['Finance'],  \n",
    "    'MOE':['Education'], \n",
    "    'MSE':['Environment and Water Resources','Sustainability and the Environment'],\n",
    "    'MCI':['Information','Communications and Information','Information, Communications and the Arts'],\n",
    "    'PMO':['Coordinating Minister for National Security', 'Prime Minister', 'Senior Minister'] \n",
    "    #\"Deputy Prime Minister\" dropping this for now because DPM may also have specific portfolios, rather than having the issue fall under PMO\n",
    "    #e.g. HSK holding MOF portfolio when he was DPM\n",
    "}\n",
    "\n",
    "def identify_portfolios(titles):\n",
    "    return tuple(set(map(lambda title: identify_portfolio(title), titles)))\n",
    "\n",
    "def identify_portfolio(title): \n",
    "    for k, v in ministry_keywords_dict.items():\n",
    "        words_re = re.compile('|'.join(v))\n",
    "        if words_re.search(title):\n",
    "            return k\n",
    "    if title != '':\n",
    "        print(f'no portfolio? {title}')\n",
    "\n",
    "def is_admin_guy(title, known_admin_guys):\n",
    "    title = title.lower()\n",
    "    if title in known_admin_guys:\n",
    "        return True\n",
    "    is_admin_guy = ('speaker' in title or 'chairman' in title or 'leader' in title) and 'minister' not in title\n",
    "    if not is_admin_guy:\n",
    "        return False\n",
    "    honorific_bracket_search = re.search(honorific_bracket_regex, title)\n",
    "    if honorific_bracket_search:\n",
    "        known_admin_guys.add(honorific_bracket_search.group()[1:-1])\n",
    "        print(f'added new admin guy for current file: {honorific_bracket_search.group()[1:-1]} (originally {title})')\n",
    "    return True\n",
    "\n",
    "def is_pq_asker(guy, known_pq_askers):\n",
    "    if 'Minister' in guy or 'Speaker' in guy or 'Leader' in guy or 'Chairman' in guy or len(list(filter(lambda x: x in guy, ['ernacular', 'Mandarin', 'Chinese', 'Hokkien', 'Cantonese', 'Teochew', 'Malay', 'Bahasa', 'Tamil', 'Hindi', 'Indian']))) > 0:\n",
    "        return False\n",
    "    guy = honorific_name_to_mp_data(re.sub(r'\\(.*\\)', '', guy).strip())[0].lower()\n",
    "    return guy in known_pq_askers\n",
    "    \n",
    "def soup_to_pqs(soup, file):\n",
    "    # print(file)\n",
    "    # seems to happen quite often sadly\n",
    "    if soup.get_text() == '':\n",
    "        print(f'empty text {file}')\n",
    "        return\n",
    "    \n",
    "    stripped_strings = list(map(\n",
    "        lambda text: re.sub(r'\\s+', ' ', text),\n",
    "        filter(\n",
    "            lambda text: not re.match(r'Page:\\s+\\d+', text) and not re.match(r'Column:\\s+\\d+', text),\n",
    "            [text for text in soup.stripped_strings])))\n",
    "    if len(stripped_strings) < 20: # the table at the top of the page alr accounts for most of this.\n",
    "        return\n",
    "    parl_no = int(stripped_strings[3])\n",
    "    sess_no = int(stripped_strings[5])\n",
    "    vol_no = int(stripped_strings[7])\n",
    "    sitting_no = int(stripped_strings[9])\n",
    "    sitting_date = datetime.strptime(stripped_strings[11], '%d-%m-%Y')\n",
    "    section_name = get_section_name(stripped_strings[13].lower())\n",
    "    title = stripped_strings[15]\n",
    "    the_rest = stripped_strings[19:]\n",
    "\n",
    "    if section_name != ReportSection.BUDGET:\n",
    "        # trim off useless preamble stuff\n",
    "        while len(the_rest) > 0 and not re.match(r'\\d\\d?', the_rest[0]):\n",
    "            the_rest = the_rest[1:]\n",
    "\n",
    "        if len(the_rest) == 0:\n",
    "            return\n",
    "        \n",
    "        # edge case: (sprs3topic_reportid=oral-answer-859.html). the \"for the Minister for the Environment and Water Resources\" should be in brackets\n",
    "        for i in range(len(the_rest)):\n",
    "            if re.match(f'for the ({one_minister_regex})', the_rest[i]) and i > 0 and the_rest[i-1][-1] != '(': \n",
    "                the_rest[i] = f'({the_rest[i]})'\n",
    "\n",
    "        indices_corresponding_to_pqs = []\n",
    "        indices_corresponding_to_speakers = []\n",
    "        maybe_more_pqs = True\n",
    "        for i in range(len(the_rest)):\n",
    "            if the_rest[i][0] == ':' or (\n",
    "                i-1 >= 0 and the_rest[i-1][-1] == ':' and the_rest[i-1] in list(map(lambda s: re.sub('\\s+', ' ', s.get_text().strip()), soup.select('strong')))): # edge case: (sprs3topic_reportid=oral-answer-2239.html), Ong Ye Kung's first response has the colon bolded, whereas it's normally not bolded. this throws us off. extra check in the condition is to resolve this.\n",
    "                actual_index_to_append = i-1\n",
    "\n",
    "                # edge case: (sprs3topic_reportid=oral-answer-1632.html), \"The Senior Minister of State for Home Affairs (Mr Desmond Lee) (for the Minister for Home Affairs)\" is broken up into multiple entries for some reason. this loop is to ensure the full name and title gets saved. notice the colon is split from the rest.\n",
    "                # edge case: (topic_reportid=008_20120710_S0007_T0006). similar story. but now the colon is with the name, even tho it's still broken up\n",
    "                # edge case: (sprs3topic_reportid=oral-answer-1159). faishal ibrahim's first response is another one. colon placement is terribad. this is why i need the re.sub. \n",
    "                while (the_rest[actual_index_to_append][0] == '(' and (\n",
    "                    the_rest[actual_index_to_append][-1] == ')' or re.sub('\\)\\s+:', '):', the_rest[actual_index_to_append])[-2:] == '):'\n",
    "                )) or ' ' not in the_rest[actual_index_to_append]: # edge case: (sprs3topic?reportid=written-answer-53). \"teo\" is separate from \"josephine\" in the html it seems\n",
    "                    actual_index_to_append -= 1\n",
    "                # edge case: (sprs3topic_reportid=oral-answer-2760.html), \"The Minister of State for Home Affairs (Mr Desmond Tan) (for the  Minister for Home Affairs)\" is also cut in the middle for some reason zzz\n",
    "                # edge case: (sprs3topic_reportid=oral-answer-362.html) need a loop otherwise we won't get iswaran's title properly (both brackets broken off in the html)\n",
    "                bracket_count = 0\n",
    "                for j in range(actual_index_to_append, i):\n",
    "                    bracket_count += the_rest[j].count('(') - the_rest[j].count(')')\n",
    "                while bracket_count != 0:\n",
    "                    actual_index_to_append -= 1\n",
    "                    if actual_index_to_append < 0:\n",
    "                        print(f'returning cuz of bad brackets in {file}')\n",
    "                        return\n",
    "                    bracket_count += the_rest[actual_index_to_append].count('(') - the_rest[actual_index_to_append].count(')')\n",
    "                if len(list(filter(lambda x: x in the_rest[actual_index_to_append][:20], ['ernacular', 'Mandarin', 'Chinese', 'Hokkien', 'Cantonese', 'Teochew', 'Malay', 'Bahasa', 'Tamil', 'Hindi', 'Indian']))) > 0:\n",
    "                    continue # to avoid picking up stuff like (In Mandarin) etc\n",
    "                indices_corresponding_to_speakers.append(actual_index_to_append)\n",
    "                maybe_more_pqs = False\n",
    "            elif re.match(r'\\d\\d?', the_rest[i]) and maybe_more_pqs:\n",
    "                indices_corresponding_to_pqs.append(i)\n",
    "\n",
    "        if len(indices_corresponding_to_pqs) == 0:\n",
    "            print(f'no pqs? {file}')\n",
    "            return\n",
    "        if len(indices_corresponding_to_speakers) == 0:\n",
    "            print(f'no speakers? {file}') # edge case: (sprs3topic_reportid=oral-answer-1729.html)\n",
    "            return\n",
    "\n",
    "        pq_sublists = []\n",
    "        pq_qn_indices = []\n",
    "        while len(indices_corresponding_to_pqs) > 1:\n",
    "            pq_qn_indices.append(the_rest[indices_corresponding_to_pqs[0]])\n",
    "            pq_sublists.append(the_rest[indices_corresponding_to_pqs[0]+1:indices_corresponding_to_pqs[1]])\n",
    "            indices_corresponding_to_pqs = indices_corresponding_to_pqs[1:]\n",
    "\n",
    "        pq_qn_indices.append(the_rest[indices_corresponding_to_pqs[0]])\n",
    "        pq_sublists.append(the_rest[indices_corresponding_to_pqs[0]+1:indices_corresponding_to_speakers[0]])\n",
    "\n",
    "        speaking_sublists = []\n",
    "\n",
    "        while len(indices_corresponding_to_speakers) > 1:\n",
    "            speaking_sublists.append(the_rest[indices_corresponding_to_speakers[0]:indices_corresponding_to_speakers[1]])\n",
    "            indices_corresponding_to_speakers = indices_corresponding_to_speakers[1:]\n",
    "\n",
    "        speaking_sublists.append(the_rest[indices_corresponding_to_speakers[0]:])\n",
    "\n",
    "        new_pqs = []\n",
    "        new_pq_indices = []\n",
    "        known_pq_askers = set() # edge case (sprs3topic?reportid=oral-answer-2133). deal w cases where the first guy to speak is actly a pq asker himself. they nvr say anyth useful if they speak first\n",
    "\n",
    "        for pq_i, sl in zip(pq_qn_indices, pq_sublists):\n",
    "            pq_para = ' '.join(sl)\n",
    "\n",
    "            #pq_para = trim_off_non_pq_content_at_start(pq_para) # sometimes we end up mistaking other numbers in the text as being the pq numbers. so we deal w that here.\n",
    "            if ' asked the ' not in pq_para:\n",
    "                continue\n",
    "            asker_honorific_name, pq_para = pq_para.split(' asked the ', 1)    \n",
    "            ministers, question = get_ministers_and_question(pq_para)\n",
    "\n",
    "            if question[0] == ',':\n",
    "                question = question[1:].strip()\n",
    "            if len(asker_honorific_name.strip()) == 0:\n",
    "                return\n",
    "            asker, asker_party, asker_parls = honorific_name_to_mp_data(asker_honorific_name.strip())\n",
    "            new_pq_indices.append(int(pq_i))\n",
    "            new_pqs.append([asker, asker_party, asker_parls, ministers, question, parl_no, sess_no, vol_no, sitting_no, sitting_date, section_name, title])\n",
    "            known_pq_askers.add(asker.lower())\n",
    "\n",
    "        # find out what's said after the pqs have been asked, and who says it\n",
    "        speakers_and_spokens = []\n",
    "        for sl in speaking_sublists:\n",
    "            text = ' '.join(sl)\n",
    "            text = re.sub('\\(\\s+', '(', text) # edge case: (sprs3topic_reportid=oral-answer-910.html). seems to be some invisible char between an open bracket and \"for the Minister\".\n",
    "            split_result = text.split(':', 1)\n",
    "            if len(split_result) < 2:\n",
    "                return\n",
    "            speaker, spoken = split_result\n",
    "            speaker = speaker.strip()\n",
    "            spoken = spoken.strip()\n",
    "            while len(spoken) > 0 and not spoken[0].isalpha():\n",
    "                spoken = spoken[1:].strip()\n",
    "            if len(spoken) == 0: # edge case (sprs3topic_reportid=written-answer-4142.html). sometimes people are just lost for words i guess.\n",
    "                return\n",
    "            if spoken[:11].lower() == 'question no' or (len(spoken) < 20 and spoken[:8].lower() == 'question'):\n",
    "                continue\n",
    "            \n",
    "            speaker = re.sub(f'\\(for .*\\)', '', speaker)\n",
    "            speaker = re.sub(f'for the ({one_minister_regex})', '', speaker)\n",
    "            speaker = re.sub(f'\\(on behalf of .*\\)', '', speaker)\n",
    "            spoken = re.sub('\\[(.|\\s){1,60}\\]', '', spoken) # remove things like [Please refer to yadda yadda]\n",
    "            speakers_and_spokens.append([speaker, spoken])\n",
    "\n",
    "        known_admin_guys = set() # edge case: (sprs3topic_reportid=oral-answer-1325). have to weed out all instances of Desmond Lee from just this file cuz he's an admin guy here. sadly he's not referred to as \"The Deputy Leader\" but as \"Desmond Lee\"\n",
    "        #st()\n",
    "        \n",
    "        # speaker never says anyth useful\n",
    "        while len(speakers_and_spokens) > 0 and (\n",
    "            is_admin_guy(speakers_and_spokens[0][0], known_admin_guys) or is_pq_asker(speakers_and_spokens[0][0], known_pq_askers) or (\n",
    "                section_name == ReportSection.ORAL and 'minister' not in speakers_and_spokens[0][0].lower() # edge case: (sprs3topic?reportid=oral-answer-446). pritam singh decided to say stuff when it wasn't his turn.\n",
    "            )\n",
    "        ):\n",
    "            speakers_and_spokens = speakers_and_spokens[1:]\n",
    "        while len(speakers_and_spokens) > 0 and (\n",
    "            is_admin_guy(speakers_and_spokens[-1][0], known_admin_guys) or is_pq_asker(speakers_and_spokens[-1][0], known_pq_askers) or (\n",
    "                section_name == ReportSection.ORAL and 'minister' not in speakers_and_spokens[-1][0].lower()\n",
    "            )\n",
    "        ):\n",
    "            speakers_and_spokens = speakers_and_spokens[:-1]\n",
    "\n",
    "        # edge case: (sprs3topic_reportid=oral-answer-1325) and many others. sometimes there are really no responses.\n",
    "        if len(speakers_and_spokens) == 0:\n",
    "            return\n",
    "\n",
    "        # edge case: (sprs3topic_reportid=oral-answer-1356.html). there's too many colons at the start of paragraphs which don't actly correspond to people saying new things. we resolve that here.\n",
    "        indices_to_merge = []\n",
    "        for i in range(1, len(speakers_and_spokens)):\n",
    "            speaker = speakers_and_spokens[i][0]\n",
    "            if re.sub('\\W+', '', re.sub('\\(.+\\)', '', speaker)).strip() == '':\n",
    "                indices_to_merge.append(i)\n",
    "        \n",
    "        for i in reversed(indices_to_merge):\n",
    "            speakers_and_spokens[i-1][1] += ' ' + speakers_and_spokens[i][1]\n",
    "            speakers_and_spokens.pop(i)\n",
    "\n",
    "        # if minister title is provided then we take. else, just take the name.\n",
    "        first_responder, first_response = speakers_and_spokens[0]\n",
    "\n",
    "        if 'Minister' in first_responder:\n",
    "            if 'Minister' in re.sub('\\(.+\\)', '', first_responder): # what usually happens\n",
    "                first_responder_honorific_name, first_responder_title = parse_speaker_title_honorific_name(first_responder)\n",
    "            else: # edge case: (sprs3topic_reportid=oral-answer-362.html). iswaran speaks on a minister's behalf, but it doesn't say what minister he is\n",
    "                first_responder_honorific_name = re.sub('\\(.+\\)', '', first_responder).strip()\n",
    "                first_responder_title = ''\n",
    "            first_responder_name = honorific_name_to_mp_data(first_responder_honorific_name)[0]\n",
    "        else:\n",
    "            first_responder_title = ''\n",
    "            if re.match(honorific_regex, first_responder.lower()):\n",
    "                first_responder_name = honorific_name_to_mp_data(first_responder)[0]\n",
    "            else:\n",
    "                first_responder_name = honorific_name_to_mp_data('Mr ' + first_responder)[0]\n",
    "        \n",
    "        # edge case: (sprs3topic_reportid=oral-answer-27)\n",
    "        first_responder_title = first_responder_title.replace('Affiars', 'Affairs').replace('Parlamentary', 'Parliamentary')\n",
    "        speakers_and_spokens = speakers_and_spokens[1:]\n",
    "\n",
    "        # if there's more than 1 pq, the responder will ask the speaker for permission to hit all the qns at once,\n",
    "        # and the speaker will grant permission. and then there may be a bit more admin back and forth.\n",
    "        # we wanna remove that.\n",
    "        if len(new_pqs) > 1:\n",
    "            while len(speakers_and_spokens) > 0 and 'speaker' in speakers_and_spokens[0][0].lower():\n",
    "                first_response = speakers_and_spokens[1][1]\n",
    "                speakers_and_spokens = speakers_and_spokens[2:]\n",
    "\n",
    "        # the new pqs now have their responses ready, we can save them.\n",
    "        for new_pq in new_pqs:\n",
    "            pqs.append(new_pq + [[[first_responder_name, first_responder_title, first_response]], True])\n",
    "\n",
    "        # pqs settled. now move on to followup (sqs)\n",
    "\n",
    "        if section_name in (ReportSection.WRITTEN, ReportSection.WRITTEN_NA):\n",
    "            return # there are no sqs in written responses\n",
    "\n",
    "        new_sqs = []\n",
    "        responder_names_to_titles = dict()\n",
    "        responder_names_to_titles[first_responder_name] = first_responder_title\n",
    "\n",
    "        for speaker, spoken in speakers_and_spokens:\n",
    "            if is_admin_guy(speaker, known_admin_guys):\n",
    "                continue # speaker says nothing useful\n",
    "\n",
    "            if '(' in speaker: # if there's a brack8 then we've never seen this person speak before\n",
    "                honorific_bracket_search = re.search(honorific_bracket_regex, speaker.lower())\n",
    "                if honorific_bracket_search: # honorific and name occur inside brackets for responders, outside for askers\n",
    "                    is_response = True\n",
    "                    honorific_name, responder_title = parse_speaker_title_honorific_name(speaker)\n",
    "                    speaker_data = honorific_name_to_mp_data(honorific_name)\n",
    "                    responder_name = speaker_data[0]\n",
    "                    responder_names_to_titles[responder_name] = responder_title\n",
    "                else: # if there's no honorific inside brack8, then honorific must be outside brack8. this only happens for asker.\n",
    "                    is_response = False\n",
    "                    honorific_name = re.sub('\\(.+\\)', '', speaker)\n",
    "                    speaker_data = honorific_name_to_mp_data(honorific_name)\n",
    "            else: # if there's no brack8 then we've seen the person speak before\n",
    "                speaker_data = honorific_name_to_mp_data(speaker)\n",
    "                if speaker_data[0] not in responder_names_to_titles.keys(): # check whether the person is a known responder\n",
    "                    is_response = False\n",
    "                    asker_name = speaker_data[0]\n",
    "                else:\n",
    "                    is_response = True\n",
    "                    responder_name = speaker_data[0]\n",
    "                    responder_title = responder_names_to_titles[responder_name]\n",
    "\n",
    "            if is_response:\n",
    "                for new_sq in new_sqs:\n",
    "                    new_sq = new_sq + [[[responder_name, responder_title, spoken]], False]\n",
    "                    new_sq[3] = (responder_title,) # backfill the missing askee title\n",
    "                    pqs.append(new_sq)\n",
    "                new_sqs = []\n",
    "            else:\n",
    "                new_sqs.append([\n",
    "                    speaker_data[0],\n",
    "                    speaker_data[1],\n",
    "                    speaker_data[2],\n",
    "                    None, # instead of ner to find out who the target of the qn is, we just backfill it l8r when we get the response\n",
    "                    spoken,\n",
    "                    parl_no,\n",
    "                    sess_no,\n",
    "                    vol_no,\n",
    "                    sitting_no,\n",
    "                    sitting_date,\n",
    "                    section_name,\n",
    "                    title\n",
    "                ])\n",
    "        return\n",
    "    else: # budget cuts\n",
    "        # don't want things like (In Malay): [refer to vernacular speech]\n",
    "        paras = list(map(lambda x: re.sub('\\[(.|\\s){1,60}\\]', '', re.sub('\\s+', ' ', x.get_text().replace('\\xa0', ' ').replace('\\ufeff', '').strip())), soup.select('p')))\n",
    "        speakers_and_spokens = []\n",
    "        next_speaker = None\n",
    "        next_spoken = None\n",
    "\n",
    "        for para in paras:\n",
    "            if not next_speaker:\n",
    "                if ':' not in para:\n",
    "                    continue\n",
    "                next_speaker, next_spoken = para.split(':', maxsplit=1)\n",
    "                next_speaker = next_speaker.strip()\n",
    "                next_spoken = next_spoken.strip()\n",
    "            else:\n",
    "                if ':' in para and (\n",
    "                    para.find(':') < 50 or (\n",
    "                        para.find(':') < 150 and para[para.find(':')-1] == ')'\n",
    "                    )\n",
    "                ) and (\n",
    "                    re.match(honorific_regex, para.lower()) or\n",
    "                    re.search(f'\\(In {cap_word}\\):', para) or (\n",
    "                        para[:4] == 'The ' and (\n",
    "                            'Minister' in para[:para.find(':')] or 'Chairman' in para[:para.find(':')] or 'Speaker' in para[:para.find(':')]))):\n",
    "                    speakers_and_spokens.append([next_speaker.strip(), next_spoken.strip()])\n",
    "                    next_speaker, next_spoken = para.split(':', maxsplit=1)\n",
    "                    next_speaker = next_speaker.strip()\n",
    "                    next_spoken = next_spoken.strip()\n",
    "                else:\n",
    "                    next_spoken += f' {para.strip()}'\n",
    "                    \n",
    "        if next_speaker and next_spoken:\n",
    "            speakers_and_spokens.append([next_speaker.strip(), next_spoken.strip()])\n",
    "        \n",
    "        speakers_and_spokens = list(filter(lambda x: x[0][:4] != 'Page' and x[0][:6] != 'Column', speakers_and_spokens))\n",
    "\n",
    "        # edge case: (sprs3topic_reportid=budget-700.html). there's a tendency to wrongly flag \"Mr Heng Chee How is right about our hard truths:\" as a speaker.\n",
    "        # we resolve this here.\n",
    "        incorrect_speaker_indices = []\n",
    "        for i in range(1, len(speakers_and_spokens)):\n",
    "            if len(list(filter(lambda x: len(x) > 0 and x[0].islower() and x not in ['de', 'bin', 'binte', 'so', 'do', 's/o', 'd/o', 's.o', 'd.o', 's.o.', 'd.o.', 'the', 'of', 'for', 'and', 'to', 'by', 'in', 'at', 'on'], re.sub('(^([A-Z][a-z]\\s-\\.,)+|\\(.+\\))', '', speakers_and_spokens[i][0]).split(' ')))) > 0:\n",
    "                incorrect_speaker_indices.append(i)\n",
    "                #print(f'dont think this is a real speaker {speakers_and_spokens[i][0]} in {file}')\n",
    "                \n",
    "        for i in reversed(incorrect_speaker_indices):\n",
    "            speakers_and_spokens[i-1][1] += ' ' + speakers_and_spokens[i][1]\n",
    "            speakers_and_spokens.pop(i)\n",
    "        \n",
    "        # get rid of closing remarks by admin ppl\n",
    "        while len(speakers_and_spokens) > 0 and ('Speaker' in speakers_and_spokens[-1][0] or 'Chairman' in speakers_and_spokens[-1][0]):\n",
    "            speakers_and_spokens = speakers_and_spokens[:-1]\n",
    "            \n",
    "        for i in range(len(speakers_and_spokens)):\n",
    "            ss = speakers_and_spokens[i]\n",
    "            # get rid of things like (In Malay): or in any other lang rly\n",
    "            ss[1] = re.sub(f'\\(In {cap_word}\\):', '', ss[1]).strip()\n",
    "            if re.match(f'\\(In {cap_word}\\)', ss[0]):\n",
    "                ss[0] = speakers_and_spokens[i-1][0]\n",
    "                \n",
    "        responder_names_to_titles = dict()\n",
    "        askers = set()\n",
    "        \n",
    "        # normalize the speaker names to not have title and honorifics, and also determine which ones are askers and which are responders\n",
    "        for ss in speakers_and_spokens:\n",
    "            if 'Chairman' in ss[0] or 'Speaker' in ss[0]:\n",
    "                continue\n",
    "            \n",
    "            ss[0] = re.sub('\\(In .+\\)', '', ss[0]) # remove those (In Malay) things too\n",
    "\n",
    "            if '(' not in ss[0]:\n",
    "                guessed_speaker_name = ss[0].split(' ', maxsplit=1)[1]\n",
    "                if guessed_speaker_name in responder_names_to_titles.keys() or guessed_speaker_name in askers:\n",
    "                    ss[0] = guessed_speaker_name\n",
    "                    continue\n",
    "                else:\n",
    "                    ss[0] = honorific_name_to_mp_data(ss[0])[0]\n",
    "                    if ss[0] not in responder_names_to_titles.keys():\n",
    "                        askers.add(ss[0])\n",
    "            elif re.search(honorific_bracket_regex, ss[0].lower()):\n",
    "                honorific_name, responder_title = parse_speaker_title_honorific_name(ss[0])\n",
    "                responder_name = honorific_name_to_mp_data(honorific_name)[0]\n",
    "                if responder_title[:4] == 'The ':\n",
    "                    responder_title = responder_title[4:]\n",
    "                responder_names_to_titles[responder_name] = responder_title\n",
    "                ss[0] = responder_name\n",
    "            else:\n",
    "                honorific_name = re.sub('\\(.+\\)', '', ss[0])\n",
    "                asker_name = honorific_name_to_mp_data(honorific_name)[0]\n",
    "                askers.add(asker_name)\n",
    "                ss[0] = asker_name\n",
    "        \n",
    "        speakers_and_spokens = list(filter(is_useful_speaker_spoken, speakers_and_spokens))\n",
    "        \n",
    "        if len(speakers_and_spokens) == 0:\n",
    "            return\n",
    "        \n",
    "        # there's nvr anyth good after the last responder speaks\n",
    "        while len(speakers_and_spokens) > 0 and speakers_and_spokens[-1][0] not in responder_names_to_titles.keys():\n",
    "            speakers_and_spokens = speakers_and_spokens[:-1]\n",
    "            \n",
    "        # remove stuff said b4 any qns are asked, cuz obv not relevant to any qns if said so early\n",
    "        while len(speakers_and_spokens) > 0 and speakers_and_spokens[0][0] not in askers:\n",
    "            speakers_and_spokens = speakers_and_spokens[1:]\n",
    "            \n",
    "        if len(speakers_and_spokens) == 0:\n",
    "            return\n",
    "        \n",
    "        # when same person speaks twice in a row, merge. unless it's asking qns (so we get 2 separate pqs)\n",
    "        repeated_speaker_indices = []\n",
    "        for i in range(1, len(speakers_and_spokens)):\n",
    "            if speakers_and_spokens[i][0] == speakers_and_spokens[i-1][0] and speakers_and_spokens[i][0] in responder_names_to_titles.keys():\n",
    "                repeated_speaker_indices.append(i)\n",
    "                \n",
    "        for i in reversed(repeated_speaker_indices):\n",
    "            speakers_and_spokens[i-1][1] += ' ' + speakers_and_spokens[i][1]\n",
    "            speakers_and_spokens.pop(i)\n",
    "        \n",
    "        new_pqs = []\n",
    "        halfway_through_response = False\n",
    "        first_wave = True\n",
    "\n",
    "        for ss in speakers_and_spokens:\n",
    "            speaker_data = honorific_name_to_mp_data(f'Mr {ss[0]}') # not elegant, shld fix l8r\n",
    "            if ss[0] in askers:\n",
    "                if halfway_through_response:\n",
    "                    halfway_through_response = False\n",
    "                    for new_pq in new_pqs:\n",
    "                        new_pq[3] = tuple(new_pq[3])\n",
    "                    pqs.extend(new_pqs)\n",
    "                    new_pqs = []\n",
    "                    first_wave = False\n",
    "                new_pqs.append([\n",
    "                    speaker_data[0], speaker_data[1], speaker_data[2], None, ss[1], parl_no, sess_no, vol_no, sitting_no, sitting_date, section_name, title, None, None])\n",
    "            elif ss[0] in responder_names_to_titles.keys():\n",
    "                halfway_through_response = True\n",
    "                for new_pq in new_pqs:\n",
    "                    responder_title = responder_names_to_titles[ss[0]] \n",
    "                    if not new_pq[3]:\n",
    "                        new_pq[3] = [responder_title]\n",
    "                    elif responder_title not in new_pq[3]: # if alr in, no need to append\n",
    "                        new_pq[3].append(responder_title)\n",
    "                    new_pq[-1] = first_wave\n",
    "                    if not new_pq[-2]:\n",
    "                        new_pq[-2] = [[ss[0], responder_title, ss[1]]]\n",
    "                    else:\n",
    "                        new_pq[-2].append([ss[0], responder_title, ss[1]])\n",
    "            else:\n",
    "                print(ss)\n",
    "                print(askers)\n",
    "                print(responder_names_to_titles)\n",
    "                assert False\n",
    "        \n",
    "        for new_pq in new_pqs:\n",
    "            new_pq[3] = tuple(new_pq[3])\n",
    "        pqs.extend(new_pqs)\n",
    "        new_pqs = []\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0314366-9a4d-4d9e-b74d-9fd5ebfd7830",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sprs3topic_reportid=oral-answer-2382.html\n",
      "0/1\n",
      "=====DONE==================================================\n",
      "total pqs: 2\n",
      "total files: 1\n",
      "avg pqs per file: 2.0\n",
      "files with exceptions: []\n"
     ]
    }
   ],
   "source": [
    "pqs = []\n",
    "files_and_exceptions = []\n",
    "#files_to_run_through = ['sprs3topic_reportid=budget-1898.html','topic_reportid=006_20120306_S0004_T0004.html','sprs3topic_reportid=budget-1630.html']\n",
    "#files_to_run_through = os.listdir('scraped_content')\n",
    "files_to_run_through = ['sprs3topic?reportid=oral-answer-2382']\n",
    "\n",
    "for i in range(len(files_to_run_through)):\n",
    "    file = files_to_run_through[i]\n",
    "    file = file.replace('?', '_')\n",
    "    if '.html' not in file:\n",
    "        file = file + '.html'\n",
    "    print(file)\n",
    "    filepath = os.path.join('scraped_content', file)\n",
    "    if os.stat(filepath).st_size < 200000: # the html elements alr take up more than 300kb, so if a file is this small then someth's wrong\n",
    "        continue\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8-sig', errors='ignore') as f:\n",
    "            soup = bs(f, 'html.parser')\n",
    "        soup_to_pqs(soup, file)\n",
    "    except Exception as e:\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        if i < 50:\n",
    "            raise e\n",
    "        else:\n",
    "            print(f'exception: {str(e)} - {file}')\n",
    "            files_and_exceptions.append([file, e])\n",
    "            continue\n",
    "        \n",
    "    if i%50==0:\n",
    "        print(f'{i}/{len(files_to_run_through)}')\n",
    "        \n",
    "print('=====DONE==================================================')\n",
    "print(f'total pqs: {len(pqs)}')\n",
    "print(f'total files: {len(files_to_run_through)}')\n",
    "print(f'avg pqs per file: {len(pqs)/len(files_to_run_through)}')\n",
    "print(f'files with exceptions: {files_and_exceptions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5608b546-0ed8-4316-81e0-e05a747efa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pqs_pickle_raw', 'wb') as f:\n",
    "    pickle.dump(pqs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "539c1b8b-e6f7-46bf-b94c-c8677665482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pqs_pickle_raw', 'rb') as f:\n",
    "    pqs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "883514f5-2bfa-4845-b83e-3d4cfbb4c88e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filled_title_count': 0, 'missing_title_count': 0}\n",
      "ppl who still have no titles:\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "pq_df = pd.DataFrame(pqs, columns=['asker_name', 'asker_party', 'asker_parliaments', 'askees', 'question', 'parliament_no', 'session_no', 'volume_no', 'sitting_no', 'sitting_date', 'report_section', 'title', 'responses', 'is_pq'])\n",
    "def tidy_up_title(title):\n",
    "    if title == '':\n",
    "        return ''\n",
    "    while not title[-1].isalpha() and title[-1] != ')':\n",
    "        title = title[:-1]\n",
    "    title = title.replace('Youth, Sports', 'Youth and Sports')\n",
    "    return title\n",
    "\n",
    "pq_df.askees = pq_df.askees.apply(lambda x: tuple(map(tidy_up_title, x)))\n",
    "pq_df.responses = pq_df.responses.apply(lambda x: list(map(lambda y: [y[0], tidy_up_title(y[1]), y[2]], x)))\n",
    "\n",
    "# parliament no, name -> title\n",
    "known_titles = dict()\n",
    "for parl_no in [12,13,14]:\n",
    "    known_titles[parl_no] = dict()\n",
    "known_titles[13]['Lee Hsien Loong'] = 'Prime Minister'\n",
    "known_titles[14]['Tharman Shanmugaratnam'] = 'Senior Minister'\n",
    "\n",
    "for parl_no, responses in zip(pq_df.parliament_no, pq_df.responses):\n",
    "    for response in responses:\n",
    "        if response[0] not in known_titles[parl_no].keys() and response[1] != '':\n",
    "            known_titles[parl_no][response[0]] = response[1]\n",
    "\n",
    "stats = {'filled_title_count': 0, 'missing_title_count': 0}\n",
    "still_none = set()\n",
    "            \n",
    "def fill_in_missing_titles(row, stats, still_none):\n",
    "    titles_found = set()\n",
    "    for response in row.responses:\n",
    "        if response[1] != '':\n",
    "            titles_found.add(response[1])\n",
    "            continue\n",
    "        stats['missing_title_count'] += 1\n",
    "        if response[0] in known_titles[row.parliament_no].keys():\n",
    "            guessed_title = known_titles[row.parliament_no][response[0]]\n",
    "            response[1] = guessed_title\n",
    "            titles_found.add(guessed_title)\n",
    "            stats['filled_title_count'] += 1\n",
    "        else:\n",
    "            still_none.add((response[0], row.parliament_no))\n",
    "    # for budget qns and all sqs, we infer the askees based on the responder. we don't do this for non-budget pqs cuz the askee title is explicitly given.\n",
    "    if row.report_section == ReportSection.BUDGET or not row.is_pq:\n",
    "        row.askees = tuple(titles_found)\n",
    "    return row\n",
    "            \n",
    "pq_df = pq_df.apply(lambda x: fill_in_missing_titles(x, stats, still_none), axis=1)\n",
    "pq_df.insert(4, 'askees_portfolios', pq_df.askees.apply(identify_portfolios))\n",
    "pq_df.responses = pq_df.responses.apply(lambda y: list(map(lambda x: (x[0], x[1], identify_portfolio(x[1]), x[2]), y)))\n",
    "print(stats)\n",
    "print('ppl who still have no titles:')\n",
    "print(still_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5492e668-20bd-477c-af29-92ae0ea94210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asker_name</th>\n",
       "      <th>asker_party</th>\n",
       "      <th>asker_parliaments</th>\n",
       "      <th>askees</th>\n",
       "      <th>askees_portfolios</th>\n",
       "      <th>question</th>\n",
       "      <th>parliament_no</th>\n",
       "      <th>session_no</th>\n",
       "      <th>volume_no</th>\n",
       "      <th>sitting_no</th>\n",
       "      <th>sitting_date</th>\n",
       "      <th>report_section</th>\n",
       "      <th>title</th>\n",
       "      <th>responses</th>\n",
       "      <th>is_pq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carrie Tan</td>\n",
       "      <td>People's Action Party</td>\n",
       "      <td>(14,)</td>\n",
       "      <td>(Minister for Manpower,)</td>\n",
       "      <td>(MOM,)</td>\n",
       "      <td>(a) for each year from 2015 to 2019, how many ...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>17</td>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>ReportSection.ORAL</td>\n",
       "      <td>Child And Elder Care as Reasons for Not Partic...</td>\n",
       "      <td>[(Gan Siow Huang, Minister of State for Manpow...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carrie Tan</td>\n",
       "      <td>People's Action Party</td>\n",
       "      <td>(14,)</td>\n",
       "      <td>(Minister for Manpower,)</td>\n",
       "      <td>(MOM,)</td>\n",
       "      <td>(a) for each year from 2015 to 2019, how many ...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>17</td>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>ReportSection.ORAL</td>\n",
       "      <td>Child And Elder Care as Reasons for Not Partic...</td>\n",
       "      <td>[(Gan Siow Huang, Minister of State for Manpow...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   asker_name            asker_party asker_parliaments  \\\n",
       "0  Carrie Tan  People's Action Party             (14,)   \n",
       "1  Carrie Tan  People's Action Party             (14,)   \n",
       "\n",
       "                     askees askees_portfolios  \\\n",
       "0  (Minister for Manpower,)            (MOM,)   \n",
       "1  (Minister for Manpower,)            (MOM,)   \n",
       "\n",
       "                                            question  parliament_no  \\\n",
       "0  (a) for each year from 2015 to 2019, how many ...             14   \n",
       "1  (a) for each year from 2015 to 2019, how many ...             14   \n",
       "\n",
       "   session_no  volume_no  sitting_no sitting_date      report_section  \\\n",
       "0           1         95          17   2021-02-02  ReportSection.ORAL   \n",
       "1           1         95          17   2021-02-02  ReportSection.ORAL   \n",
       "\n",
       "                                               title  \\\n",
       "0  Child And Elder Care as Reasons for Not Partic...   \n",
       "1  Child And Elder Care as Reasons for Not Partic...   \n",
       "\n",
       "                                           responses  is_pq  \n",
       "0  [(Gan Siow Huang, Minister of State for Manpow...   True  \n",
       "1  [(Gan Siow Huang, Minister of State for Manpow...   True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b10be6-e33f-4d37-9194-0f2c9936a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_df.to_csv('pqs.csv', index=False, sep='|') # sep=',' gives formatting issues \n",
    "with open('pqs.csv', 'r+', encoding='utf-8-sig', errors='ignore') as f:\n",
    "    content = f.read()\n",
    "    f.seek(0)\n",
    "    f.write(f'sep=|\\n{content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cda24a8-34bc-42ad-bc1f-6dc220aae435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parties: {\"People's Action Party\"} (len: 1)\n",
      "\n",
      "askees: {'Minister for Manpower'} (len: 1)\n",
      "\n",
      "askees portfolios: {'MOM'} (len: 1)\n",
      "\n",
      "responder titles: {'Minister of State for Manpower'} (len: 1)\n"
     ]
    }
   ],
   "source": [
    "#assert all(pq_df.parliament_no < 15) and all(pq_df.parliament_no >= 12)\n",
    "# assert all(map(lambda x: not x[0].isupper(), pq_df.question.values)) \n",
    "#assert all(map(lambda x: not x[:3] == 'and', pq_df.question.values)) \n",
    "parties_set = set(pq_df.asker_party.values)\n",
    "print(f'parties: {parties_set} (len: {len(parties_set)})\\n')\n",
    "askee_set = set([askees for sublist in pq_df.askees for askees in sublist])\n",
    "print(f'askees: {askee_set} (len: {len(askee_set)})\\n')\n",
    "askees_portfolios_set = set([askees_portfolios for sublist in pq_df.askees_portfolios for askees_portfolios in sublist])\n",
    "print(f'askees portfolios: {askees_portfolios_set} (len: {len(askees_portfolios_set)})\\n')\n",
    "responder_title_set = set([response[1] for responses in pq_df.responses for response in responses])\n",
    "print(f'responder titles: {responder_title_set} (len: {len(responder_title_set)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b90b30e-8e35-4dfb-93f2-b5d381b26033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(pq_df.asker_name.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c547b906-6b9c-4934-ac3d-9b8c3a345c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 'Carrie Tan', 2, 'Carrie Tan', 1, 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_count = 999\n",
    "min_mp = None\n",
    "max_count = 0\n",
    "max_mp = None\n",
    "less_than_ten = 0\n",
    "just_one = 0\n",
    "for name in set(pq_df.asker_name.values):\n",
    "    count_here = pq_df[pq_df.asker_name == name]['asker_name'].count()\n",
    "    if count_here < min_count:\n",
    "        min_count = count_here\n",
    "        min_mp = name\n",
    "    if count_here > max_count:\n",
    "        max_count = count_here\n",
    "        max_mp = name\n",
    "    if count_here < 10:\n",
    "        less_than_ten += 1\n",
    "    if count_here == 1:\n",
    "        just_one += 1\n",
    "        \n",
    "min_count, min_mp, max_count, max_mp, less_than_ten, just_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "207ca49c-ad90-4ef4-8b8f-05e89a3595a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: sitting_date, dtype: int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# questions relevant to mccy\n",
    "pq_df[pq_df['askees_portfolios'].apply(lambda x: 'MCCY' in x)].sitting_date.apply(lambda x: str(x)[:4]).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9ec0e39-dd9d-4e0c-9db6-3d336ff748ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReportSection.ORAL    2\n",
       "Name: report_section, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq_df['report_section'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ad80437-daf1-4ebd-8626-6fffe2e2f621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    2\n",
       "Name: is_pq, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq_df['is_pq'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
