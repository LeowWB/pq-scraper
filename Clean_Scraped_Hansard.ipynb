{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbdbd63a-9d50-493b-967f-0078c4e50214",
   "metadata": {},
   "source": [
    "run the mp scraper one and the actual hansard scraper one. then you'll have some html files of hansard and a csv file of mps. then run this nb.\n",
    "\n",
    "if u wanna find code that deals w edge cases, find comments that start with \"edge case\". examples are given. i started writing those comments q l8 tho so i don't guarantee that i commented on all of them. \n",
    "\n",
    "**the csv file you get from this is delimited by '|'. if reading with code make sure u account for that. if opening in excel, follow these instrns (https://support.affinity.co/hc/en-us/articles/360044453711-How-to-open-CSV-files-with-the-correct-delimiter-separator).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911324d7-4429-41bc-b979-769a705cd945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import ast\n",
    "import os\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pdb import set_trace as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e9930a-84f1-483a-8415-3c2ec4d98245",
   "metadata": {},
   "source": [
    "**for merging with mps.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce675208-2543-4282-8a8f-eeb5d78f77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_df = pd.read_csv('mps.csv')\n",
    "mp_df.Parliaments = mp_df.Parliaments.apply(ast.literal_eval)\n",
    "mps = dict(\n",
    "    zip(mp_df.Name.apply(lambda x: x.replace('.', '').replace(',', '').lower()), # keys\n",
    "    zip(mp_df.Name, mp_df.Party, mp_df.Parliaments))) # values\n",
    "mp_names = list(mps.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c72765-1e10-4f66-b0c5-de5d4ad837c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alr_matched = set() # honorific+names that have alr been matched to names so we don't spam the print\n",
    "ministers_found = set() # minister titles that have alr been found (to be used for future searches in case of typos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a41c038-c9f4-4b92-9313-fe5fccdab091",
   "metadata": {},
   "outputs": [],
   "source": [
    "honorific_regex = r'(mr|mrs|ms|miss|mdm|dr|er dr|prof|assoc prof|er|asst prof|assoc prof dr|inche|encik)'\n",
    "\n",
    "# for matching honorific+name in report to actual mp data.\n",
    "# cannot simply remove honorific as the programmer doesn't have an exhaustive list\n",
    "# of honorifics, and some are quite rare in everyday use (e.g. Inche Rahamat Bin Kenap).\n",
    "def honorific_name_to_mp_data(honorific_name):\n",
    "    honorific_name = honorific_name.replace('.','').replace(',','').replace(':','').lower().strip()\n",
    "    honorific_name = re.sub('\\(.+\\)', '', honorific_name)\n",
    "    \n",
    "    # try the easy way first (find and remove honorific)\n",
    "    honorific_match = re.match(honorific_regex, honorific_name)\n",
    "    if honorific_match:\n",
    "        name = honorific_name[honorific_match.span()[1]+1:]\n",
    "        if name in mps.keys():\n",
    "            return mps[name]\n",
    "        \n",
    "        # seems quite common for them to write \"asked\" twice in the hansard proceedings\n",
    "        last_asked = name.rfind(' asked')\n",
    "        if last_asked and name[:last_asked] in mps.keys():\n",
    "            return mps[name[:last_asked]]\n",
    "\n",
    "        # slightly harder way (rearranging words)\n",
    "        for mp_name in mp_names:\n",
    "            mp_name_words = set(mp_name.split(' '))\n",
    "            name_words = set(name.split(' '))\n",
    "            if mp_name_words == name_words:\n",
    "                if (honorific_name, mp_name) not in alr_matched:\n",
    "                    #print(f'rearranging matched {honorific_name} to {mp_name}')\n",
    "                    alr_matched.add((honorific_name, mp_name))\n",
    "                return mps[mp_name]\n",
    "            \n",
    "            # for omission of chinese name\n",
    "            if len(mp_name_words) - len(name_words) <= 2 and len(name_words) >= 2 and name_words.issubset(mp_name_words):\n",
    "                if (honorific_name, mp_name) not in alr_matched:\n",
    "                    print(f'allowing omitted words in name matched {honorific_name} to {mp_name}')\n",
    "                    alr_matched.add((honorific_name, mp_name))\n",
    "                return mps[mp_name]\n",
    "                \n",
    "    digit_match = re.search('\\d+', honorific_name)\n",
    "    if digit_match:\n",
    "        # names shldn't have digits\n",
    "        honorific_name = honorific_name[digit_match.span()[1]:]\n",
    "        return honorific_name_to_mp_data(honorific_name)\n",
    "        \n",
    "    # the hard way (levenshtein)\n",
    "    closest_name = levenshtein_best_match(honorific_name, mp_names)\n",
    "    \n",
    "    if (honorific_name, closest_name) not in alr_matched:\n",
    "        print(f'levenshtein matched {honorific_name} to {closest_name}')\n",
    "        alr_matched.add((honorific_name, closest_name))\n",
    "    return mps[closest_name]\n",
    "\n",
    "def levenshtein_best_match(value, options):\n",
    "    min_levenshtein = 99999\n",
    "    min_val = None\n",
    "    for option in options:\n",
    "        l_dist = levenshtein(option, value)\n",
    "        if l_dist < min_levenshtein:\n",
    "            min_levenshtein = l_dist\n",
    "            min_val = option\n",
    "    return min_val\n",
    "            \n",
    "\n",
    "# borrowed from: https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/\n",
    "# we use levenshtein as it helps to protect against typos too, like the \"asked asked\" in:\n",
    "# https://sprs.parl.gov.sg/search/sprs3topic?reportid=oral-answer-2822\n",
    "def levenshtein(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2eee96-c726-4f73-a0ab-a5b630687de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pqs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b55804-1d18-45fa-8518-78a1bacdc56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportSection(Enum):\n",
    "    WRITTEN = 'Written Answers to Questions'\n",
    "    WRITTEN_NA = 'Written Answers to Questions for Oral Answer Not Answered by End of Question Time'\n",
    "    ORAL = 'Oral Answers to Questions'\n",
    "    BUDGET = 'Budget'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759f4b8-16fc-4450-a923-8bac17a53f4f",
   "metadata": {},
   "source": [
    "we assume that all pqs are prefaced with #. (non sprs) or # (sprs). ignore follow up qns since we are only interested in mapping mps to topics, and the follow up qns will always be from the same mp and on the same topic.\n",
    "\n",
    "notes regarding minister titles:\n",
    "* Minister for Culture, Community and Youth is the only minister title with a comma\n",
    "* but there used to be Minister for Information, Communication and the Arts and Minister for Community Development, Youth and Sports\n",
    "* no questions were ever directed to minister mentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd366a7a-0882-4584-a7ec-423a6a23fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_word = r'[A-Z][a-z]+'\n",
    "cap_words = f'({cap_word})( {cap_word})*'\n",
    "mccy = '(Acting )?Minister for Culture, Community and Youth'\n",
    "mica = '(Acting )?Minister for Information, Communications and the Arts'\n",
    "mcdys = '(Acting )?Minister for Community Development, Youth( and|,) Sports'\n",
    "micma = 'Minister-in-charge of Muslim Affairs'\n",
    "minister_for_something = f'({cap_words} )?Minister( of State)? (for|of) (the )?{cap_words}( and (the )?{cap_words})?( \\({cap_word}\\))?'\n",
    "something_minister = f'{cap_words} Minister'\n",
    "one_minister_regex = f'(({mccy})|({mica})|({mcdys})|({micma})|({minister_for_something})|({something_minister}))'\n",
    "minister_regex = re.compile(f'{one_minister_regex}( and (the )?{one_minister_regex})?') # can have multiple targets\n",
    "\n",
    "def first_two_capitalized(words):\n",
    "    return words[0][0].isupper() and words[1][0].isupper() and words[0][1] and words[0][1].islower()\n",
    "\n",
    "def trim_off_non_pq_content_at_start(para):\n",
    "    para_words = para.split(' ')\n",
    "    if first_two_capitalized(para_words):\n",
    "        return para\n",
    "    \n",
    "    # i assume honorific+name has at least two words capitalized and non-numbers\n",
    "    while not first_two_capitalized(para_words):\n",
    "        para_words = para_words[1:]\n",
    "    \n",
    "    return ' '.join(para_words)\n",
    "\n",
    "# extracts the first substring which is a substring of ministers\n",
    "def extract_first_ministers(para):\n",
    "    minister_match = re.search(minister_regex, para)\n",
    "    if not minister_match:\n",
    "        # report might've been in the wrong case; try to match to existing ministers\n",
    "        minister_match = re.search(\n",
    "            '(' + '|'.join(list(map(lambda s: s.lower().replace(' for ', '.{1,5}'), ministers_found))) + ')',\n",
    "            para.lower()\n",
    "        )\n",
    "        if not minister_match:\n",
    "            minister_match = re.search(\n",
    "            '(' + '|'.join(list(map(lambda s: s.lower().replace(' for ', '(\\s)*(for|of)(\\s)*'), ministers_found))) + ')',\n",
    "            para.lower()\n",
    "        )\n",
    "        if not minister_match:\n",
    "            for existing_minister in ministers_found:\n",
    "                if existing_minister.replace(' ', '') in para.replace(' ', ''):\n",
    "                    minister_match = re.search('(\\s)?'.join(c for c in existing_minister.replace(' ', '').lower()), para.lower())\n",
    "                    break\n",
    "        minister = levenshtein_best_match(minister_match.group(), ministers_found)\n",
    "        print(f'found minister: {str(minister_match.group())}; matched to {minister}')\n",
    "    else:\n",
    "        minister = para[:minister_match.span()[1]].replace(' of ', ' for ')\n",
    "        ministers_found.add(minister)\n",
    "\n",
    "    para = para.replace(minister_match.group(), '').strip()\n",
    "\n",
    "    if ' and Leader' in minister:\n",
    "        minister = minister[:-11]\n",
    "\n",
    "    if minister[:4] == 'The ':\n",
    "        minister = minister[4:]\n",
    "        \n",
    "    return minister, para\n",
    "\n",
    "def parse_speaker_title_honorific_name(speaker):\n",
    "    honorific_bracket_regex = f'\\({honorific_regex} .+\\)'\n",
    "    honorific_bracket_search = re.search(honorific_bracket_regex, speaker.lower())\n",
    "    honorific_name = speaker[honorific_bracket_search.span()[0]+1 : honorific_bracket_search.span()[1]-1].strip()\n",
    "    responder_title = re.sub(honorific_bracket_regex, '', speaker, flags=re.IGNORECASE).replace(' of ', ' for ').strip()\n",
    "    if responder_title[:4] == 'The ':\n",
    "        responder_title = responder_title[4:].strip()\n",
    "    return honorific_name, responder_title\n",
    "\n",
    "def get_ministers_and_question(para):\n",
    "    askee, question = extract_first_ministers(para)\n",
    "    \n",
    "    if not re.search('and (the )?Minister', askee):\n",
    "        return (askee,), question   \n",
    "    else:\n",
    "        askee = askee.replace('and the Minister', 'and Minister')\n",
    "        askees = askee.split(' and Minister')\n",
    "        return (askees[0], 'Minister' + askees[1]), question\n",
    "\n",
    "def get_section_name(section_name_raw):\n",
    "    if 'answered' in section_name_raw:\n",
    "        return ReportSection.WRITTEN_NA\n",
    "    elif 'written' in section_name_raw:\n",
    "        return ReportSection.WRITTEN\n",
    "    elif 'oral' in section_name_raw:\n",
    "        return ReportSection.ORAL\n",
    "    elif 'budget' in section_name_raw:\n",
    "        return ReportSection.BUDGET\n",
    "    else:\n",
    "        raise f'no section name??? {section_name_raw}'\n",
    "\n",
    "ministry_keywords_dict = {\n",
    "    'MCCY': ['Muslim Affairs', 'Culture', 'Youth', 'Sports','Community'], \n",
    "    'MOT':['Transport'], \n",
    "    'MINDEF':['Defence'],\n",
    "    'MinLaw':['Law'], \n",
    "    'MTI':['Trade and Industry'], \n",
    "    'MOM':['Manpower'], \n",
    "    'MND':['National Development'], \n",
    "    'MHA':['Home Affairs'], \n",
    "    'MOH':['Health'], \n",
    "    'MFA':['Foreign Affairs'], \n",
    "    'MSF':['Social and Family Development'], \n",
    "    'MOF':['Finance'],  \n",
    "    'MOE':['Education'], \n",
    "    'MSE':['the Environment and Water Resources','Sustainability and the Environment'],\n",
    "    'MCI':['Information','Communications and Information','Information, Communications and the Arts'],\n",
    "    'PMO':['Coordinating Minister for National Security','Prime Minister'] \n",
    "    #\"Deputy Prime Minister\" dropping this for now because DPM may also have specific portfolios, rather than having the issue fall under PMO\n",
    "    #e.g. HSK holding MOF portfolio when he was DPM\n",
    "}\n",
    "\n",
    "def identify_portfolios(titles):\n",
    "    return tuple(set(map(lambda title: identify_portfolio(title), titles)))\n",
    "\n",
    "def identify_portfolio(title): \n",
    "    for k, v in ministry_keywords_dict.items():\n",
    "        words_re = re.compile('|'.join(v))\n",
    "        if words_re.search(title):\n",
    "            return k\n",
    "    print(f'no portfolio? {title}')\n",
    "    \n",
    "def soup_to_pqs(soup, file):\n",
    "    # print(file)\n",
    "    # seems to happen quite often sadly\n",
    "    if soup.get_text() == '':\n",
    "        print(f'empty text {file}')\n",
    "        return\n",
    "    \n",
    "    stripped_strings = list(map(\n",
    "        lambda text: re.sub(r'\\s+', ' ', text),\n",
    "        filter(\n",
    "            lambda text: not re.match(r'Page:\\s+\\d+', text) and not re.match(r'Column:\\s+\\d+', text),\n",
    "            [text for text in soup.stripped_strings])))\n",
    "    if len(stripped_strings) < 20: # the table at the top of the page alr accounts for most of this.\n",
    "        return\n",
    "    parl_no = int(stripped_strings[3])\n",
    "    sess_no = int(stripped_strings[5])\n",
    "    vol_no = int(stripped_strings[7])\n",
    "    sitting_no = int(stripped_strings[9])\n",
    "    sitting_date = datetime.strptime(stripped_strings[11], '%d-%m-%Y')\n",
    "    section_name = get_section_name(stripped_strings[13].lower())\n",
    "    title = stripped_strings[15]\n",
    "    the_rest = stripped_strings[19:]\n",
    "    \n",
    "    if section_name == ReportSection.BUDGET:\n",
    "        return # TODO TODO TODOTODOTODO TODO TODO ============================================================================\n",
    "    \n",
    "    while len(the_rest) > 0 and not re.match(r'\\d\\d?', the_rest[0]):\n",
    "        the_rest = the_rest[1:]\n",
    "        \n",
    "    if len(the_rest) == 0:\n",
    "        return\n",
    "        \n",
    "    indices_corresponding_to_pqs = []\n",
    "    indices_corresponding_to_speakers = []\n",
    "    maybe_more_pqs = True\n",
    "    for i in range(len(the_rest)):\n",
    "        if the_rest[i][0] == ':' or (i-1 >= 0 and the_rest[i-1][-1] == ':' and the_rest[i-1] in list(map(lambda s: s.get_text().strip(), soup.select('strong')))): # edge case: (sprs3topic_reportid=oral-answer-2239.html), Ong Ye Kung's first response has the colon bolded, whereas it's normally not bolded. this throws us off. extra check in the condition is to resolve this.\n",
    "            actual_index_to_append = i-1\n",
    "            # edge case: (sprs3topic_reportid=oral-answer-1632.html), \"The Senior Minister of State for Home Affairs (Mr Desmond Lee) (for the Minister for Home Affairs)\" is broken up into multiple entries for some reason. this loop is to ensure the full name and title gets saved.\n",
    "            while the_rest[actual_index_to_append][0] == '(' and the_rest[actual_index_to_append][-1] == ')':\n",
    "                actual_index_to_append -= 1\n",
    "            # edge case: (sprs3topic_reportid=oral-answer-2760.html), \"The Minister of State for Home Affairs (Mr Desmond Tan) (for the  Minister for Home Affairs)\" is also cut in the middle for some reason zzz\n",
    "            bracket_count = the_rest[actual_index_to_append].count('(') - the_rest[actual_index_to_append].count(')')\n",
    "            while bracket_count != 0:\n",
    "                actual_index_to_append -= 1\n",
    "                bracket_count += the_rest[actual_index_to_append].count('(') - the_rest[actual_index_to_append].count(')')\n",
    "            indices_corresponding_to_speakers.append(actual_index_to_append)\n",
    "            maybe_more_pqs = False\n",
    "        elif re.match(r'\\d\\d?', the_rest[i]) and maybe_more_pqs:\n",
    "            indices_corresponding_to_pqs.append(i)\n",
    "            \n",
    "    if len(indices_corresponding_to_pqs) == 0:\n",
    "        print(f'no pqs? {file}')\n",
    "        return\n",
    "    if len(indices_corresponding_to_speakers) == 0:\n",
    "        print(f'no speakers? {file}')\n",
    "        return\n",
    "        \n",
    "    pq_sublists = []\n",
    "    pq_qn_indices = []\n",
    "    while len(indices_corresponding_to_pqs) > 1:\n",
    "        pq_qn_indices.append(the_rest[indices_corresponding_to_pqs[0]])\n",
    "        pq_sublists.append(the_rest[indices_corresponding_to_pqs[0]+1:indices_corresponding_to_pqs[1]])\n",
    "        indices_corresponding_to_pqs = indices_corresponding_to_pqs[1:]\n",
    "        \n",
    "    pq_qn_indices.append(the_rest[indices_corresponding_to_pqs[0]])\n",
    "    pq_sublists.append(the_rest[indices_corresponding_to_pqs[0]+1:indices_corresponding_to_speakers[0]])\n",
    "    \n",
    "    speaking_sublists = []\n",
    "    \n",
    "    while len(indices_corresponding_to_speakers) > 1:\n",
    "        speaking_sublists.append(the_rest[indices_corresponding_to_speakers[0]:indices_corresponding_to_speakers[1]])\n",
    "        indices_corresponding_to_speakers = indices_corresponding_to_speakers[1:]\n",
    "    \n",
    "    speaking_sublists.append(the_rest[indices_corresponding_to_speakers[0]:])\n",
    "    \n",
    "    new_pqs = []\n",
    "    new_pq_indices = []\n",
    "    \n",
    "    for pq_i, sl in zip(pq_qn_indices, pq_sublists):\n",
    "        pq_para = ' '.join(sl)\n",
    "        \n",
    "        #pq_para = trim_off_non_pq_content_at_start(pq_para) # sometimes we end up mistaking other numbers in the text as being the pq numbers. so we deal w that here.\n",
    "        if ' asked the ' not in pq_para:\n",
    "            continue\n",
    "        asker_honorific_name, pq_para = pq_para.split(' asked the ', 1)    \n",
    "        ministers, question = get_ministers_and_question(pq_para)\n",
    "\n",
    "        if question[0] == ',':\n",
    "            question = question[1:].strip()\n",
    "        if len(asker_honorific_name.strip()) == 0:\n",
    "            return\n",
    "        asker, asker_party, asker_parls = honorific_name_to_mp_data(asker_honorific_name.strip())\n",
    "        new_pq_indices.append(int(pq_i))\n",
    "        new_pqs.append([asker, asker_party, asker_parls, ministers, question, parl_no, sess_no, vol_no, sitting_no, sitting_date, section_name, title])\n",
    "    \n",
    "    # find out what's said after the pqs have been asked, and who says it\n",
    "    speakers_and_spokens = []\n",
    "    for sl in speaking_sublists:\n",
    "        text = ' '.join(sl)\n",
    "        speaker, spoken = text.split(':', 1)\n",
    "        speaker = speaker.strip()\n",
    "        spoken = spoken.strip()\n",
    "        while len(spoken) > 0 and not spoken[0].isalpha():\n",
    "            spoken = spoken[1:].strip()\n",
    "        if len(spoken) == 0: # edge case (sprs3topic_reportid=written-answer-4142.html). sometimes people are just lost for words i guess.\n",
    "            return\n",
    "        if spoken[:len('Question No')] == 'Question No':\n",
    "            continue\n",
    "        speaker = re.sub(f'\\(for the .*\\)', '', speaker)\n",
    "        speaker = re.sub(f'\\(on behalf of the .*\\)', '', speaker)\n",
    "        speakers_and_spokens.append([speaker, spoken])\n",
    "\n",
    "    # speaker never says anyth useful\n",
    "    while 'speaker' in speakers_and_spokens[0][0].lower():\n",
    "        speakers_and_spokens = speakers_and_spokens[1:]\n",
    "    while 'speaker' in speakers_and_spokens[-1][0].lower() or 'leader' in speakers_and_spokens[-1][0].lower():\n",
    "        speakers_and_spokens = speakers_and_spokens[:-1]\n",
    "    \n",
    "    # if minister title is provided then we take. else, just take the name.\n",
    "    first_responder, first_response = speakers_and_spokens[0]\n",
    "    if 'Minister' in first_responder:\n",
    "        first_responder_honorific_name, first_responder_title = parse_speaker_title_honorific_name(first_responder)\n",
    "        first_responder_name = honorific_name_to_mp_data(first_responder_honorific_name)[0]\n",
    "    else:\n",
    "        first_responder_title = ''\n",
    "        first_responder_name = first_responder\n",
    "    \n",
    "    speakers_and_spokens = speakers_and_spokens[1:]\n",
    "    \n",
    "    # if there's more than 1 pq, the responder will ask the speaker for permission to hit all the qns at once,\n",
    "    # and the speaker will grant permission. and then there may be a bit more admin back and forth.\n",
    "    # we wanna remove that.\n",
    "    if len(new_pqs) > 1:\n",
    "        while len(speakers_and_spokens) > 0 and 'speaker' in speakers_and_spokens[0][0].lower():\n",
    "            first_response = speakers_and_spokens[1][1]\n",
    "            speakers_and_spokens = speakers_and_spokens[2:]\n",
    "\n",
    "    # the new pqs now have their responses ready, we can save them.\n",
    "    for new_pq in new_pqs:\n",
    "        pqs.append(new_pq + [first_responder_name, first_responder_title, first_response, True])\n",
    "        \n",
    "    # pqs settled. now move on to followup (sqs)\n",
    "    \n",
    "    if section_name in (ReportSection.WRITTEN, ReportSection.WRITTEN_NA):\n",
    "        return # there are no sqs in written responses\n",
    "    \n",
    "    new_sqs = []\n",
    "    responder_names_to_titles = dict()\n",
    "    responder_names_to_titles[first_responder_name] = first_responder_title\n",
    "\n",
    "    for speaker, spoken in speakers_and_spokens:\n",
    "        if 'speaker' in speaker.lower() or 'leader' in speaker.lower():\n",
    "            continue # speaker says nothing useful\n",
    "        \n",
    "        if '(' in speaker: # if there's a brack8 then we've never seen this person speak before\n",
    "            honorific_bracket_search = re.search(f'\\({honorific_regex} .+\\)', speaker.lower())\n",
    "            if honorific_bracket_search: # honorific and name occur inside brackets for responders, outside for askers\n",
    "                is_response = True\n",
    "                honorific_name, responder_title = parse_speaker_title_honorific_name(speaker)\n",
    "                speaker_data = honorific_name_to_mp_data(honorific_name)\n",
    "                responder_name = speaker_data[0]\n",
    "                responder_names_to_titles[responder_name] = responder_title\n",
    "            else: # if there's no honorific inside brack8, then honorific must be outside brack8. this only happens for asker.\n",
    "                is_response = False\n",
    "                honorific_name = re.sub('\\(.+\\)', '', speaker)\n",
    "                speaker_data = honorific_name_to_mp_data(honorific_name)\n",
    "        else: # if there's no brack8 then we've seen the person speak before\n",
    "            speaker_data = honorific_name_to_mp_data(speaker)\n",
    "            if speaker_data[0] not in responder_names_to_titles.keys(): # check whether the person is a known responder\n",
    "                is_response = False\n",
    "                asker_name = speaker_data[0]\n",
    "            else:\n",
    "                is_response = True\n",
    "                responder_name = speaker_data[0]\n",
    "                responder_title = responder_names_to_titles[responder_name]\n",
    "    \n",
    "        if is_response:\n",
    "            for new_sq in new_sqs:\n",
    "                new_sq = new_sq + [responder_name, responder_title, spoken, False]\n",
    "                new_sq[3] = (responder_title,) # backfill the missing askee title\n",
    "                pqs.append(new_sq)\n",
    "            new_sqs = []\n",
    "        else:\n",
    "            new_sqs.append([\n",
    "                speaker_data[0],\n",
    "                speaker_data[1],\n",
    "                speaker_data[2],\n",
    "                None, # instead of ner to find out who the target of the qn is, we just backfill it l8r when we get the response\n",
    "                spoken,\n",
    "                parl_no,\n",
    "                sess_no,\n",
    "                vol_no,\n",
    "                sitting_no,\n",
    "                sitting_date,\n",
    "                section_name,\n",
    "                title\n",
    "            ])\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0314366-9a4d-4d9e-b74d-9fd5ebfd7830",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sprs3topic_reportid=oral-answer-1523.html\n",
      "0/1\n",
      "=====DONE==================================================\n",
      "total pqs: 3\n",
      "total files: 1\n",
      "avg pqs per file: 3.0\n",
      "files with exceptions: []\n"
     ]
    }
   ],
   "source": [
    "pqs = []\n",
    "files_and_exceptions = []\n",
    "files_to_run_through = ['sprs3topic_reportid=oral-answer-1523.html']#os.listdir('scraped_content')[500:525]\n",
    "\n",
    "for i in range(len(files_to_run_through)):\n",
    "    file = files_to_run_through[i]\n",
    "    print(file)\n",
    "    filepath = os.path.join('scraped_content', file)\n",
    "    if os.stat(filepath).st_size < 200000: # the html elements alr take up more than 300kb, so if a file is this small then someth's wrong\n",
    "        continue\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8-sig', errors='ignore') as f:\n",
    "            soup = bs(f, 'html.parser')\n",
    "        soup_to_pqs(soup, file)\n",
    "    except Exception as e:\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        raise e\n",
    "        #print(f'exception: {str(e)} - {file}')\n",
    "        #files_and_exceptions.append([file, e])\n",
    "        #continue\n",
    "        \n",
    "    if i%25==0:\n",
    "        print(f'{i}/{len(files_to_run_through)}')\n",
    "        \n",
    "print('=====DONE==================================================')\n",
    "print(f'total pqs: {len(pqs)}')\n",
    "print(f'total files: {len(files_to_run_through)}')\n",
    "print(f'avg pqs per file: {len(pqs)/len(files_to_run_through)}')\n",
    "print(f'files with exceptions: {files_and_exceptions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "883514f5-2bfa-4845-b83e-3d4cfbb4c88e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asker_name</th>\n",
       "      <th>asker_party</th>\n",
       "      <th>asker_parliaments</th>\n",
       "      <th>askees</th>\n",
       "      <th>askees_portfolios</th>\n",
       "      <th>question</th>\n",
       "      <th>parliament_no</th>\n",
       "      <th>session_no</th>\n",
       "      <th>volume_no</th>\n",
       "      <th>sitting_no</th>\n",
       "      <th>sitting_date</th>\n",
       "      <th>report_section</th>\n",
       "      <th>title</th>\n",
       "      <th>responder_portfolio</th>\n",
       "      <th>responder_name</th>\n",
       "      <th>responder_title</th>\n",
       "      <th>response</th>\n",
       "      <th>is_pq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desmond Choo</td>\n",
       "      <td>People's Action Party</td>\n",
       "      <td>(13, 14)</td>\n",
       "      <td>(Minister for Education (Schools),)</td>\n",
       "      <td>(MOE,)</td>\n",
       "      <td>(a) what is the current capacity and take-up r...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>58</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>ReportSection.ORAL</td>\n",
       "      <td>Take-up Rate and Affordability of After-school...</td>\n",
       "      <td>MOE</td>\n",
       "      <td>Ng Chee Meng</td>\n",
       "      <td>Minister for Education (Schools)</td>\n",
       "      <td>Mr Speaker, over the last six years, MOE has i...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desmond Choo</td>\n",
       "      <td>People's Action Party</td>\n",
       "      <td>(13, 14)</td>\n",
       "      <td>(Minister for Education (Schools),)</td>\n",
       "      <td>(MOE,)</td>\n",
       "      <td>Speaker, I would like to thank the Minister fo...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>58</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>ReportSection.ORAL</td>\n",
       "      <td>Take-up Rate and Affordability of After-school...</td>\n",
       "      <td>MOE</td>\n",
       "      <td>Ng Chee Meng</td>\n",
       "      <td>Minister for Education (Schools)</td>\n",
       "      <td>Mr Speaker, I thank the Member for his questio...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intan Azura Mokhtar</td>\n",
       "      <td>People's Action Party</td>\n",
       "      <td>(12, 13)</td>\n",
       "      <td>(Minister for Education (Schools),)</td>\n",
       "      <td>(MOE,)</td>\n",
       "      <td>May I ask the Minister whether there are plans...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>58</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>ReportSection.ORAL</td>\n",
       "      <td>Take-up Rate and Affordability of After-school...</td>\n",
       "      <td>MOE</td>\n",
       "      <td>Ng Chee Meng</td>\n",
       "      <td>Minister for Education (Schools)</td>\n",
       "      <td>I thank the Member for her question. Indeed, t...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            asker_name            asker_party asker_parliaments  \\\n",
       "0         Desmond Choo  People's Action Party          (13, 14)   \n",
       "1         Desmond Choo  People's Action Party          (13, 14)   \n",
       "2  Intan Azura Mokhtar  People's Action Party          (12, 13)   \n",
       "\n",
       "                                askees askees_portfolios  \\\n",
       "0  (Minister for Education (Schools),)            (MOE,)   \n",
       "1  (Minister for Education (Schools),)            (MOE,)   \n",
       "2  (Minister for Education (Schools),)            (MOE,)   \n",
       "\n",
       "                                            question  parliament_no  \\\n",
       "0  (a) what is the current capacity and take-up r...             13   \n",
       "1  Speaker, I would like to thank the Minister fo...             13   \n",
       "2  May I ask the Minister whether there are plans...             13   \n",
       "\n",
       "   session_no  volume_no  sitting_no sitting_date      report_section  \\\n",
       "0           1         94          58   2018-02-05  ReportSection.ORAL   \n",
       "1           1         94          58   2018-02-05  ReportSection.ORAL   \n",
       "2           1         94          58   2018-02-05  ReportSection.ORAL   \n",
       "\n",
       "                                               title responder_portfolio  \\\n",
       "0  Take-up Rate and Affordability of After-school...                 MOE   \n",
       "1  Take-up Rate and Affordability of After-school...                 MOE   \n",
       "2  Take-up Rate and Affordability of After-school...                 MOE   \n",
       "\n",
       "  responder_name                   responder_title  \\\n",
       "0   Ng Chee Meng  Minister for Education (Schools)   \n",
       "1   Ng Chee Meng  Minister for Education (Schools)   \n",
       "2   Ng Chee Meng  Minister for Education (Schools)   \n",
       "\n",
       "                                            response  is_pq  \n",
       "0  Mr Speaker, over the last six years, MOE has i...   True  \n",
       "1  Mr Speaker, I thank the Member for his questio...  False  \n",
       "2  I thank the Member for her question. Indeed, t...  False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq_df = pd.DataFrame(pqs, columns=['asker_name', 'asker_party', 'asker_parliaments', 'askees', 'question', 'parliament_no', 'session_no', 'volume_no', 'sitting_no', 'sitting_date', 'report_section', 'title', 'responder_name', 'responder_title', 'response', 'is_pq'])\n",
    "pq_df.insert(4, 'askees_portfolios', pq_df.askees.apply(identify_portfolios))\n",
    "pq_df.insert(13, 'responder_portfolio', pq_df.responder_title.apply(identify_portfolio))\n",
    "pq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b10be6-e33f-4d37-9194-0f2c9936a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_df.to_csv('pqs.csv', index=False, sep='|') # sep=',' gives formatting issues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cda24a8-34bc-42ad-bc1f-6dc220aae435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parties: {\"People's Action Party\"} (len: 1)\n",
      "\n",
      "askees: {'Minister for Education (Schools)'} (len: 1)\n"
     ]
    }
   ],
   "source": [
    "assert all(pq_df.parliament_no < 15) and all(pq_df.parliament_no >= 12)\n",
    "# assert all(map(lambda x: not x[0].isupper(), pq_df.question.values)) \n",
    "assert all(map(lambda x: not x[:3] == 'and', pq_df.question.values)) \n",
    "parties_set = set(pq_df.asker_party.values)\n",
    "print(f'parties: {parties_set} (len: {len(parties_set)})')\n",
    "print()\n",
    "askee_set = set([askees for sublist in pq_df.askees for askees in sublist])\n",
    "print(f'askees: {askee_set} (len: {len(askee_set)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b90b30e-8e35-4dfb-93f2-b5d381b26033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(pq_df.asker_name.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c547b906-6b9c-4934-ac3d-9b8c3a345c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'Intan Azura Mokhtar', 2, 'Desmond Choo', 2, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_count = 999\n",
    "min_mp = None\n",
    "max_count = 0\n",
    "max_mp = None\n",
    "less_than_ten = 0\n",
    "just_one = 0\n",
    "for name in set(pq_df.asker_name.values):\n",
    "    count_here = pq_df[pq_df.asker_name == name]['asker_name'].count()\n",
    "    if count_here < min_count:\n",
    "        min_count = count_here\n",
    "        min_mp = name\n",
    "    if count_here > max_count:\n",
    "        max_count = count_here\n",
    "        max_mp = name\n",
    "    if count_here < 10:\n",
    "        less_than_ten += 1\n",
    "    if count_here == 1:\n",
    "        just_one += 1\n",
    "        \n",
    "min_count, min_mp, max_count, max_mp, less_than_ten, just_one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
