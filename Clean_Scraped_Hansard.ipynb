{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbdbd63a-9d50-493b-967f-0078c4e50214",
   "metadata": {},
   "source": [
    "run the mp scraper one and the actual hansard scraper one. then you'll have some html files of hansard and a csv file of mps. then run this nb.\n",
    "\n",
    "if u wanna find code that deals w edge cases, find comments that start with \"edge case\". examples are given. i started writing those comments q l8 tho so i don't guarantee that i commented on all of them. \n",
    "\n",
    "**the csv file you get from this is delimited by '|'. if reading with code make sure u account for that. if opening in excel, follow these instrns (https://support.affinity.co/hc/en-us/articles/360044453711-How-to-open-CSV-files-with-the-correct-delimiter-separator).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911324d7-4429-41bc-b979-769a705cd945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import ast\n",
    "import os\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pdb import set_trace as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e9930a-84f1-483a-8415-3c2ec4d98245",
   "metadata": {},
   "source": [
    "**for merging with mps.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce675208-2543-4282-8a8f-eeb5d78f77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_df = pd.read_csv('mps.csv')\n",
    "mp_df.Party = mp_df.Party.apply(ast.literal_eval)\n",
    "mp_df.Parliaments = mp_df.Parliaments.apply(ast.literal_eval)\n",
    "mps = dict(\n",
    "    zip(mp_df.Name.apply(lambda x: x.replace('.', '').replace(',', '').lower()), # keys\n",
    "    zip(mp_df.Name, mp_df.Party, mp_df.Parliaments))) # values\n",
    "mp_names = list(mps.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c72765-1e10-4f66-b0c5-de5d4ad837c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alr_matched = set() # honorific+names that have alr been matched to names so we don't spam the print\n",
    "ministers_found = set() # minister titles that have alr been found (to be used for future searches in case of typos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a41c038-c9f4-4b92-9313-fe5fccdab091",
   "metadata": {},
   "outputs": [],
   "source": [
    "honorific_regex = r'(mr|mrs|ms|miss|mdm|dr|er dr|prof|assoc prof|er|asst prof|assoc prof dr|inche|encik)'\n",
    "\n",
    "# for matching honorific+name in report to actual mp data.\n",
    "# cannot simply remove honorific as the programmer doesn't have an exhaustive list\n",
    "# of honorifics, and some are quite rare in everyday use (e.g. Inche Rahamat Bin Kenap).\n",
    "def honorific_name_to_mp_data(honorific_name):\n",
    "    honorific_name = honorific_name.replace('.','').replace(',','').lower().strip()\n",
    "    \n",
    "    # try the easy way first (find and remove honorific)\n",
    "    honorific_match = re.match(honorific_regex, honorific_name)\n",
    "    if honorific_match:\n",
    "        name = honorific_name[honorific_match.span()[1]+1:]\n",
    "        if name in mps.keys():\n",
    "            return mps[name]\n",
    "        \n",
    "        # seems quite common for them to write \"asked\" twice in the hansard proceedings\n",
    "        last_asked = name.rfind(' asked')\n",
    "        if last_asked and name[:last_asked] in mps.keys():\n",
    "            return mps[name[:last_asked]]\n",
    "\n",
    "        # slightly harder way (rearranging words)\n",
    "        for mp_name in mp_names:\n",
    "            mp_name_words = set(mp_name.split(' '))\n",
    "            name_words = set(name.split(' '))\n",
    "            if mp_name_words == name_words:\n",
    "                if (honorific_name, mp_name) not in alr_matched:\n",
    "                    #print(f'rearranging matched {honorific_name} to {mp_name}')\n",
    "                    alr_matched.add((honorific_name, mp_name))\n",
    "                return mps[mp_name]\n",
    "            \n",
    "            # for omission of chinese name\n",
    "            if len(mp_name_words) - len(name_words) <= 2 and len(name_words) >= 2 and name_words.issubset(mp_name_words):\n",
    "                if (honorific_name, mp_name) not in alr_matched:\n",
    "                    print(f'allowing omitted words in name matched {honorific_name} to {mp_name}')\n",
    "                    alr_matched.add((honorific_name, mp_name))\n",
    "                return mps[mp_name]\n",
    "                \n",
    "    digit_match = re.search('\\d+', honorific_name)\n",
    "    if digit_match:\n",
    "        # names shldn't have digits\n",
    "        honorific_name = honorific_name[digit_match.span()[1]:]\n",
    "        return honorific_name_to_mp_data(honorific_name)\n",
    "        \n",
    "    # the hard way (levenshtein)\n",
    "    closest_name = levenshtein_best_match(honorific_name, mp_names)\n",
    "    \n",
    "    if (honorific_name, closest_name) not in alr_matched:\n",
    "        print(f'levenshtein matched {honorific_name} to {closest_name}')\n",
    "        alr_matched.add((honorific_name, closest_name))\n",
    "    return mps[closest_name]\n",
    "\n",
    "def levenshtein_best_match(value, options):\n",
    "    min_levenshtein = 99999\n",
    "    min_val = None\n",
    "    for option in options:\n",
    "        l_dist = levenshtein(option, value)\n",
    "        if l_dist < min_levenshtein:\n",
    "            min_levenshtein = l_dist\n",
    "            min_val = option\n",
    "    return min_val\n",
    "            \n",
    "\n",
    "# borrowed from: https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/\n",
    "# we use levenshtein as it helps to protect against typos too, like the \"asked asked\" in:\n",
    "# https://sprs.parl.gov.sg/search/sprs3topic?reportid=oral-answer-2822\n",
    "def levenshtein(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2eee96-c726-4f73-a0ab-a5b630687de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pqs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b55804-1d18-45fa-8518-78a1bacdc56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportSection(Enum):\n",
    "    WRITTEN = 'Written Answers to Questions'\n",
    "    WRITTEN_NA = 'Written Answers to Questions for Oral Answer Not Answered by End of Question Time'\n",
    "    ORAL = 'Oral Answers to Questions'\n",
    "    BUDGET = 'Budget'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759f4b8-16fc-4450-a923-8bac17a53f4f",
   "metadata": {},
   "source": [
    "we assume that all pqs are prefaced with #. (non sprs) or # (sprs). ignore follow up qns since we are only interested in mapping mps to topics, and the follow up qns will always be from the same mp and on the same topic.\n",
    "\n",
    "notes regarding minister titles:\n",
    "* Minister for Culture, Community and Youth is the only minister title with a comma\n",
    "* but there used to be Minister for Information, Communication and the Arts and Minister for Community Development, Youth and Sports\n",
    "* no questions were ever directed to minister mentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd366a7a-0882-4584-a7ec-423a6a23fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_word = r'[A-Z][a-z]+'\n",
    "cap_words = f'({cap_word})( {cap_word})*'\n",
    "mccy = '(Acting )?Minister for Culture, Community and Youth'\n",
    "mica = '(Acting )?Minister for Information, Communications and the Arts'\n",
    "mcdys = '(Acting )?Minister for Community Development, Youth( and|,) Sports'\n",
    "micma = 'Minister-in-charge of Muslim Affairs'\n",
    "minister_for_something = f'({cap_words} )?Minister( of State)? (for|of) (the )?{cap_words}( and (the )?{cap_words})?'\n",
    "something_minister = f'{cap_words} Minister'\n",
    "one_minister_regex = f'(({mccy})|({mica})|({mcdys})|({micma})|({minister_for_something})|({something_minister}))'\n",
    "minister_regex = re.compile(f'{one_minister_regex}( and (the )?{one_minister_regex})?') # can have multiple targets\n",
    "\n",
    "def first_two_capitalized(words):\n",
    "    return words[0][0].isupper() and words[1][0].isupper() and words[0][1] and words[0][1].islower()\n",
    "\n",
    "def trim_off_non_pq_content_at_start(para):\n",
    "    para_words = para.split(' ')\n",
    "    if first_two_capitalized(para_words):\n",
    "        return para\n",
    "    \n",
    "    # i assume honorific+name has at least two words capitalized and non-numbers\n",
    "    while not first_two_capitalized(para_words):\n",
    "        para_words = para_words[1:]\n",
    "    \n",
    "    return ' '.join(para_words)\n",
    "\n",
    "def get_ministers_and_question(para):\n",
    "    minister_match = re.search(minister_regex, para)\n",
    "    if not minister_match:\n",
    "        # report might've been in the wrong case; try to match to existing ministers\n",
    "        minister_match = re.search(\n",
    "            '(' + '|'.join(list(map(lambda s: s.lower().replace(' for ', '.{1,5}'), ministers_found))) + ')',\n",
    "            para.lower()\n",
    "        )\n",
    "        if not minister_match:\n",
    "            minister_match = re.search(\n",
    "            '(' + '|'.join(list(map(lambda s: s.lower().replace(' for ', '(\\s)*(for|of)(\\s)*'), ministers_found))) + ')',\n",
    "            para.lower()\n",
    "        )\n",
    "        if not minister_match:\n",
    "            for existing_minister in ministers_found:\n",
    "                if existing_minister.replace(' ', '') in para.replace(' ', ''):\n",
    "                    minister_match = re.search('(\\s)?'.join(c for c in existing_minister.replace(' ', '').lower()), para.lower())\n",
    "                    break\n",
    "        min_minister = levenshtein_best_match(minister_match.group(), ministers_found)\n",
    "        print(f'found minister: {str(minister_match.group())}; matched to {min_minister}')\n",
    "        askee = min_minister\n",
    "    else:\n",
    "        askee = para[:minister_match.span()[1]].replace(' of ', ' for ')\n",
    "        ministers_found.add(askee)\n",
    "    question = para[minister_match.span()[1]:].strip()\n",
    "    if ' and Leader' in askee:\n",
    "        askee = askee[:-11]\n",
    "        print(f'removed \"and leader\" from {askee}')\n",
    "    \n",
    "    if not re.search('and (the )?Minister', askee):\n",
    "        return (askee,), question   \n",
    "    else:\n",
    "        askee = askee.replace('and the Minister', 'and Minister')\n",
    "        askees = askee.split(' and Minister')\n",
    "        return (askees[0], 'Minister' + askees[1]), question\n",
    "\n",
    "def soup_to_pqs(soup, file):\n",
    "    # print(file)\n",
    "    # seems to happen quite often sadly\n",
    "    if soup.get_text() == '':\n",
    "        print(f'empty text {file}')\n",
    "        return\n",
    "    \n",
    "    stripped_strings = list(map(\n",
    "        lambda text: re.sub(r'\\s+', ' ', text),\n",
    "        filter(\n",
    "            lambda text: not re.match(r'Page:\\s+\\d+', text) and not re.match(r'Column:\\s+\\d+', text),\n",
    "            [text for text in soup.stripped_strings])))\n",
    "    if len(stripped_strings) < 19: # the table at the top of the page alr accounts for most of this.\n",
    "        return\n",
    "    parl_no = int(stripped_strings[3])\n",
    "    sess_no = int(stripped_strings[5])\n",
    "    vol_no = int(stripped_strings[7])\n",
    "    sitting_no = int(stripped_strings[9])\n",
    "    sitting_date = datetime.strptime(stripped_strings[11], '%d-%m-%Y')\n",
    "    section_name_raw = stripped_strings[13].lower()\n",
    "    \n",
    "    if 'answered' in section_name_raw:\n",
    "        section_name = ReportSection.WRITTEN_NA\n",
    "    elif 'written' in section_name_raw:\n",
    "        section_name = ReportSection.WRITTEN\n",
    "    elif 'oral' in section_name_raw:\n",
    "        section_name = ReportSection.ORAL\n",
    "    elif 'budget' in section_name_raw:\n",
    "        section_name = ReportSection.BUDGET\n",
    "    else:\n",
    "        raise f'no section name??? {section_name_raw}'\n",
    "    \n",
    "    title = stripped_strings[15]\n",
    "    the_rest = stripped_strings[19:]\n",
    "    \n",
    "    if section_name == ReportSection.BUDGET:\n",
    "        return # TODO TODO TODOTODOTODO TODO TODO ============================================================================\n",
    "    \n",
    "    while len(the_rest) > 0 and not re.match(r'\\d\\d?', the_rest[0]):\n",
    "        the_rest = the_rest[1:]\n",
    "        \n",
    "    if len(the_rest) == 0:\n",
    "        return\n",
    "        \n",
    "    indices_corresponding_to_pqs = []\n",
    "    indices_corresponding_to_speakers = []\n",
    "    maybe_more_pqs = True\n",
    "    for i in range(len(the_rest)):\n",
    "        if the_rest[i][0] == ':' or (i-1 >= 0 and the_rest[i-1][-1] == ':' and the_rest[i-1] in list(map(lambda s: s.get_text().strip(), soup.select('strong')))): # edge case: (sprs3topic_reportid=oral-answer-2239.html), Ong Ye Kung's first response has the colon bolded, whereas it's normally not bolded. this throws us off. extra check in the condition is to resolve this.\n",
    "            actual_index_to_append = i-1\n",
    "            # edge case: (sprs3topic_reportid=oral-answer-1632.html), \"The Senior Minister of State for Home Affairs (Mr Desmond Lee) (for the Minister for Home Affairs)\" is broken up into multiple entries for some reason. this loop is to ensure the full name and title gets saved.\n",
    "            while the_rest[actual_index_to_append][0] == '(' and the_rest[actual_index_to_append][-1] == ')':\n",
    "                actual_index_to_append -= 1\n",
    "            indices_corresponding_to_speakers.append(actual_index_to_append)\n",
    "            maybe_more_pqs = False\n",
    "        elif re.match(r'\\d\\d?', the_rest[i]) and maybe_more_pqs:\n",
    "            indices_corresponding_to_pqs.append(i)\n",
    "            \n",
    "    if len(indices_corresponding_to_pqs) == 0:\n",
    "        print(f'no pqs? {file}')\n",
    "        return\n",
    "    if len(indices_corresponding_to_speakers) == 0:\n",
    "        print(f'no speakers? {file}')\n",
    "        return\n",
    "        \n",
    "    pq_sublists = []\n",
    "    pq_qn_indices = []\n",
    "    while len(indices_corresponding_to_pqs) > 1:\n",
    "        pq_qn_indices.append(the_rest[indices_corresponding_to_pqs[0]])\n",
    "        pq_sublists.append(the_rest[indices_corresponding_to_pqs[0]+1:indices_corresponding_to_pqs[1]])\n",
    "        indices_corresponding_to_pqs = indices_corresponding_to_pqs[1:]\n",
    "        \n",
    "    pq_qn_indices.append(the_rest[indices_corresponding_to_pqs[0]])\n",
    "    pq_sublists.append(the_rest[indices_corresponding_to_pqs[0]+1:indices_corresponding_to_speakers[0]])\n",
    "    \n",
    "    speaking_sublists = []\n",
    "    \n",
    "    while len(indices_corresponding_to_speakers) > 1:\n",
    "        speaking_sublists.append(the_rest[indices_corresponding_to_speakers[0]:indices_corresponding_to_speakers[1]])\n",
    "        indices_corresponding_to_speakers = indices_corresponding_to_speakers[1:]\n",
    "    \n",
    "    speaking_sublists.append(the_rest[indices_corresponding_to_speakers[0]:])\n",
    "    \n",
    "    new_pqs = []\n",
    "    new_pq_indices = []\n",
    "    \n",
    "    for pq_i, sl in zip(pq_qn_indices, pq_sublists):\n",
    "        pq_para = ' '.join(sl)\n",
    "        \n",
    "        #pq_para = trim_off_non_pq_content_at_start(pq_para) # sometimes we end up mistaking other numbers in the text as being the pq numbers. so we deal w that here.\n",
    "        if ' asked the ' not in pq_para:\n",
    "            continue\n",
    "        asker_honorific_name, pq_para = pq_para.split(' asked the ', 1)    \n",
    "        ministers, question = get_ministers_and_question(pq_para)\n",
    "\n",
    "        if question[0] == ',':\n",
    "            question = question[1:].strip()\n",
    "        if len(asker_honorific_name.strip()) == 0:\n",
    "            return\n",
    "        asker, asker_party, asker_parls = honorific_name_to_mp_data(asker_honorific_name.strip())\n",
    "        new_pq_indices.append(int(pq_i))\n",
    "        new_pqs.append([asker, asker_party[0], asker_parls, ministers, question, parl_no, sess_no, vol_no, sitting_no, sitting_date, section_name, title])\n",
    "    \n",
    "    speakers_and_spokens = []\n",
    "    for sl in speaking_sublists:\n",
    "        speaker = sl[0]\n",
    "        if 'speaker' in speaker.lower(): # ignore since the speaker of the house only says administrative things\n",
    "            continue\n",
    "        spoken = ' '.join(sl[1:])\n",
    "        while len(spoken) > 0 and not spoken[0].isalpha():\n",
    "            spoken = spoken[1:]\n",
    "        if len(spoken) == 0: # edge case (sprs3topic_reportid=written-answer-4142.html). sometimes people are just lost for words i guess.\n",
    "            return\n",
    "        if spoken[:len('Question No')] == 'Question No':\n",
    "            continue\n",
    "        speaker = re.sub(f'\\(for the .*\\)', '', speaker)\n",
    "        speaker = re.sub(f'\\(on behalf of the .*\\)', '', speaker)\n",
    "        if len(speakers_and_spokens) == 0:\n",
    "            speaker_title_match = re.search(minister_regex, speaker)\n",
    "            if not speaker_title_match:\n",
    "                responder_title = ''\n",
    "                if section_name == ReportSection.ORAL: # only oral answers include speaker title. \n",
    "                    print(f'no title for this speaker {speaker} in this file {file}')\n",
    "            else:\n",
    "                responder_title = speaker_title_match.group()\n",
    "        speaker = re.sub(minister_regex, '', speaker)\n",
    "        in_bracket_honorific_match = re.search(f'\\({honorific_regex}.+\\)', speaker.lower())\n",
    "        if in_bracket_honorific_match:\n",
    "            honorific_match_group = in_bracket_honorific_match.group()[1:-1]\n",
    "            if len(honorific_match_group) == 0:\n",
    "                return\n",
    "            speaker = honorific_name_to_mp_data(honorific_match_group)[0]\n",
    "        else:\n",
    "            speaker = re.sub(f'\\(.+\\)', '', speaker)\n",
    "            if len(speaker) == 0:\n",
    "                return\n",
    "            speaker = honorific_name_to_mp_data(speaker)[0]\n",
    "        speakers_and_spokens.append([speaker, spoken])\n",
    "        \n",
    "    assert len(new_pqs) == len(new_pq_indices)\n",
    "        \n",
    "    if len(new_pqs) == 0:\n",
    "        return\n",
    "        \n",
    "    # only 1 pq was asked. so everything else in the file must be related to that pq.\n",
    "    if len(new_pqs) == 1:\n",
    "        responder, response = speakers_and_spokens[0]\n",
    "        new_pqs[0].append(responder)\n",
    "        new_pqs[0].append(responder_title)\n",
    "        new_pqs[0].append(response)\n",
    "        follow_ups = speakers_and_spokens[1:]\n",
    "        new_pqs[0].append(follow_ups)\n",
    "        pqs.append(new_pqs[0])\n",
    "        return\n",
    "    \n",
    "    if len(speakers_and_spokens) == 0:\n",
    "        print(f'found file with no responses {file}')\n",
    "        for new_pq in new_pqs:\n",
    "            new_pq.append('')\n",
    "            new_pq.append('')\n",
    "            new_pq.append('')\n",
    "            new_pq.append([])\n",
    "            pqs.append(new_pq)\n",
    "        return\n",
    "    \n",
    "    # only 1 person spoke after all the pqs were asked. so this person must be responding to all the pqs.\n",
    "    if len(speakers_and_spokens) == 1:\n",
    "        responder, response = speakers_and_spokens[0]\n",
    "        for new_pq in new_pqs:\n",
    "            new_pq.append(responder)\n",
    "            new_pq.append(responder_title)\n",
    "            new_pq.append(response)\n",
    "            new_pq.append([]) # no follow-ups after main response\n",
    "            pqs.append(new_pq)\n",
    "        return\n",
    "\n",
    "    # past this point, the html file has more than one pq, and more than one response to those pqs. \n",
    "    assert len(new_pqs) > 1\n",
    "    assert len(speakers_and_spokens) > 1\n",
    "    \n",
    "    relevant_followups = dict() # stores which spoken thing is relevant to which pq\n",
    "    for new_pq_i in new_pq_indices:\n",
    "        relevant_followups[new_pq_i] = []\n",
    "    first_responder, first_response = speakers_and_spokens[0]\n",
    "    \n",
    "    # usually the responder responds to all the qns at once. we just wanna confirm that.\n",
    "    qn_indices_covered_by_first_response = set()\n",
    "    range_matches = re.findall(r'\\d+ to \\d+', first_response) # e.g. \"i wanna cover qns x to y and z to w\"\n",
    "    if range_matches and len(range_matches) > 0:\n",
    "        for range_match in range_matches:\n",
    "            qn_indices_covered_by_first_response = qn_indices_covered_by_first_response.union(set(range(*list(map(int, range_match.split(' to '))))))\n",
    "    range_matches = re.findall(r'\\d+( )?-( )?\\d+', first_response) # e.g. \"i wanna cover qns x-y and z-w\"\n",
    "    if range_matches and len(range_matches) > 0:\n",
    "        for range_match in range_matches:\n",
    "            qn_indices_covered_by_first_response = qn_indices_covered_by_first_response.union(set(range(*list(map(int, range_match.split('-'))))))\n",
    "    qn_indices_covered_by_first_response = qn_indices_covered_by_first_response.union(set(map(int, re.findall(r'\\d+', first_response))))\n",
    "    if set(new_pq_indices).issubset(qn_indices_covered_by_first_response) or 'all' in first_response or 'together' in first_response or 'every' in first_response:\n",
    "        # the first responder is responding to all the questions at once. \n",
    "        for pq_i in new_pq_indices:\n",
    "            # speakers_and_spokens[0] is asking for permission to answer all qns at once. speakers_and_spokens[1] is the actual response.\n",
    "            relevant_followups[pq_i].append(speakers_and_spokens[1])\n",
    "        speakers_and_spokens = speakers_and_spokens[2:]\n",
    "    else:\n",
    "        print(\"i genuinely don't think we'll reach this point. but if we do, find out which questions this current response is addressing\")\n",
    "        print('rmb to remove the consumed entries from speakers_and_spokens')\n",
    "        print(f'file is {file}')\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "\n",
    "    # no follow-ups after main response\n",
    "    if len(speakers_and_spokens) == 0:\n",
    "        for new_pq_i, new_pq in zip(new_pq_indices, new_pqs):\n",
    "            new_pq.append(relevant_followups[new_pq_i][0][0]) # responder\n",
    "            new_pq.append(responder_title)\n",
    "            new_pq.append(relevant_followups[new_pq_i][0][1]) # response\n",
    "            new_pq.append([])\n",
    "            pqs.append(new_pq)\n",
    "        return\n",
    "    \n",
    "    # gotta map everything that is said, to the relevant pqs. \n",
    "    asker_to_new_pqi = dict()\n",
    "    for new_pq_i, new_pq in zip(new_pq_indices, new_pqs):\n",
    "        asker_to_new_pqi[new_pq[0]] = new_pq_i\n",
    "\n",
    "    pqs_with_new_responses_since_last_time_first_responder_spoke = set()\n",
    "    pqs_that_first_responder_covered_with_last_reply = set(new_pq_indices)\n",
    "    \n",
    "    for i in range(len(speakers_and_spokens)):\n",
    "        speaker, spoken = speakers_and_spokens[i]\n",
    "        #print(f'pqs w new responses: {pqs_with_new_responses_since_last_time_first_responder_spoke}')\n",
    "        #print(f'pqs last covered: {pqs_that_first_responder_covered_with_last_reply}')\n",
    "        \n",
    "        if speaker in asker_to_new_pqi.keys(): # something is said by someone who asked a pq. so it's relevant to that pq. \n",
    "            #print(f'said by someone who asked a pq. {asker_to_new_pqi[speaker]} {[speaker, spoken[:100]]}')\n",
    "            relevant_followups[asker_to_new_pqi[speaker]].append([speaker, spoken])\n",
    "            pqs_with_new_responses_since_last_time_first_responder_spoke.add(asker_to_new_pqi[speaker])\n",
    "            continue\n",
    "        \n",
    "        # something is said by someone who did not ask any pqs. \n",
    "        \n",
    "        if speaker == first_responder:\n",
    "            # it's the original responder, ofc responding to some followup qns. \n",
    "            # find out which qns these are by seeing who said stuff since the last time this guy spoke.\n",
    "            #print(f'said by responder. adding to pqs: {pqs_with_new_responses_since_last_time_first_responder_spoke}. {[speaker, spoken[:100]]}')\n",
    "            for pq_with_new_response in pqs_with_new_responses_since_last_time_first_responder_spoke:\n",
    "                relevant_followups[pq_with_new_response].append([speaker, spoken])\n",
    "            pqs_that_first_responder_covered_with_last_reply = pqs_with_new_responses_since_last_time_first_responder_spoke\n",
    "            pqs_with_new_responses_since_last_time_first_responder_spoke = set()\n",
    "            continue\n",
    "        else:\n",
    "            # otherwise, it's a follow-up qn from someone originally unrelated. naturally the qn would be targeted at the first responder, and the\n",
    "            # content has to be rel8ed to whatever the responder last said. so we assign it to the same set of pqs.\n",
    "            #print(f'new followup qn. adding to pqs: {pqs_that_first_responder_covered_with_last_reply}. {[speaker, spoken[:100]]}')\n",
    "            for pq_covered in pqs_that_first_responder_covered_with_last_reply:\n",
    "                relevant_followups[pq_covered].append([speaker, spoken])\n",
    "                pqs_with_new_responses_since_last_time_first_responder_spoke.add(pq_covered)\n",
    "            continue\n",
    "    \n",
    "    for new_pq_i, new_pq in zip(new_pq_indices, new_pqs):\n",
    "        new_pq.append(relevant_followups[new_pq_i][0][0]) # responder\n",
    "        new_pq.append(responder_title)\n",
    "        new_pq.append(relevant_followups[new_pq_i][0][1]) # response\n",
    "        new_pq.append(relevant_followups[new_pq_i][1:])\n",
    "        pqs.append(new_pq)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0314366-9a4d-4d9e-b74d-9fd5ebfd7830",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3810\n",
      "levenshtein matched mrs josephine teo to josephine teo\n",
      "levenshtein matched assoc prof dr muhammad faishal ibrahim to muhammad faishal ibrahim\n",
      "no title for this speaker Assoc Prof Dr Muhammad Faishal Ibrahim  in this file sprs3topic_reportid=oral-answer-167.html\n",
      "25/3810\n",
      "allowing omitted words in name matched mr murali pillai to murali pillai sc\n",
      "allowing omitted words in name matched mr alex yam to alex yam ziming\n",
      "levenshtein matched mr masagos zulkifli b m m to masagos zulkifli bin masagos mohamad\n",
      "found minister: minister for transport; matched to Minister for Transport\n",
      "50/3810\n",
      "75/3810\n",
      "levenshtein matched assoc prof dr yaacob ibrahim to yaacob ibrahim\n",
      "100/3810\n",
      "levenshtein matched mrs lina chiam to lina chiam\n",
      "levenshtein matched ) to don wee\n",
      "125/3810\n",
      "150/3810\n",
      "allowing omitted words in name matched mr david ong to david ong kim huat\n",
      "no title for this speaker Ms Ellen Lee (Sembawang) in this file sprs3topic_reportid=oral-answer-449.html\n",
      "no title for this speaker Mr Lim Hng Kiang in this file sprs3topic_reportid=oral-answer-516.html\n",
      "no title for this speaker Mr Lawrence Wong in this file sprs3topic_reportid=oral-answer-526.html\n",
      "175/3810\n",
      "no title for this speaker Mr Khaw Boon Wan in this file sprs3topic_reportid=oral-answer-527.html\n",
      "200/3810\n",
      "225/3810\n",
      "no title for this speaker Mr Chan Chun Sing in this file sprs3topic_reportid=oral-answer-750.html\n",
      "levenshtein matched mr louis ng kok kwang : to louis ng kok kwang\n",
      "levenshtein matched ms chia yong yong  : to chia yong yong\n",
      "250/3810\n",
      "275/3810\n",
      "300/3810\n",
      "325/3810\n",
      "350/3810\n",
      "375/3810\n",
      "400/3810\n",
      "425/3810\n",
      "450/3810\n",
      "475/3810\n",
      "500/3810\n",
      "525/3810\n",
      "550/3810\n",
      "575/3810\n",
      "600/3810\n",
      "625/3810\n",
      "650/3810\n",
      "675/3810\n",
      "700/3810\n",
      "725/3810\n",
      "750/3810\n",
      "775/3810\n",
      "800/3810\n",
      "825/3810\n",
      "850/3810\n",
      "875/3810\n",
      "900/3810\n",
      "925/3810\n",
      "950/3810\n",
      "975/3810\n",
      "1000/3810\n",
      "1025/3810\n",
      "1050/3810\n",
      "exception: [Errno 13] Permission denied - sprs3topic_reportid=written-answer-2873.html\n",
      "1075/3810\n",
      "1100/3810\n",
      "1125/3810\n",
      "levenshtein matched mr chan chun sing (for the to chan chun sing\n",
      "1150/3810\n",
      "1175/3810\n",
      "levenshtein matched  to don wee\n",
      "1200/3810\n",
      "1225/3810\n",
      "1250/3810\n",
      "1275/3810\n",
      "1300/3810\n",
      "1325/3810\n",
      "1350/3810\n",
      "1375/3810\n",
      "1400/3810\n",
      "1425/3810\n",
      "1450/3810\n",
      "1475/3810\n",
      "1500/3810\n",
      "1525/3810\n",
      "1550/3810\n",
      "1575/3810\n",
      "levenshtein matched teo to don wee\n",
      "1600/3810\n",
      "1625/3810\n",
      "1650/3810\n",
      "1675/3810\n",
      "1700/3810\n",
      "1725/3810\n",
      "1750/3810\n",
      "1775/3810\n",
      "1800/3810\n",
      "1825/3810\n",
      "1850/3810\n",
      "1875/3810\n",
      "1900/3810\n",
      "1925/3810\n",
      "1950/3810\n",
      "1975/3810\n",
      "2000/3810\n",
      "2025/3810\n",
      "2050/3810\n",
      "2075/3810\n",
      "2100/3810\n",
      "2125/3810\n",
      "2150/3810\n",
      "2175/3810\n",
      "2200/3810\n",
      "2225/3810\n",
      "2250/3810\n",
      "2275/3810\n",
      "2300/3810\n",
      "2325/3810\n",
      "levenshtein matched ms grace fu hai yien : to grace fu hai yien\n",
      "2350/3810\n",
      "2375/3810\n",
      "2400/3810\n",
      "2425/3810\n",
      "2450/3810\n",
      "2475/3810\n",
      "2500/3810\n",
      "2525/3810\n",
      "2550/3810\n",
      "2575/3810\n",
      "2600/3810\n",
      "2625/3810\n",
      "2650/3810\n",
      "2675/3810\n",
      "2700/3810\n",
      "2725/3810\n",
      "2750/3810\n",
      "2775/3810\n",
      "2800/3810\n",
      "2825/3810\n",
      "2850/3810\n",
      "2875/3810\n",
      "2900/3810\n",
      "2925/3810\n",
      "2950/3810\n",
      "2975/3810\n",
      "3000/3810\n",
      "3025/3810\n",
      "3050/3810\n",
      "3075/3810\n",
      "allowing omitted words in name matched mr mohd fahmi aliman to mohd fahmi bin aliman\n",
      "3100/3810\n",
      "3125/3810\n",
      "3150/3810\n",
      "3175/3810\n",
      "3200/3810\n",
      "levenshtein matched bg [ns] tan chuan-jin to tan chuan-jin\n",
      "3225/3810\n",
      "no title for this speaker Mr S Iswaran  in this file topic_reportid=004_20120710_S0007_T0002.html\n",
      "no title for this speaker BG [NS] Tan Chuan-Jin  in this file topic_reportid=005_20111020_S0007_T0002.html\n",
      "no title for this speaker Mrs Josephine Teo  in this file topic_reportid=005_20111122_S0007_T0003.html\n",
      "3250/3810\n",
      "no title for this speaker Mr Khaw Boon Wan in this file topic_reportid=007_20111121_S0007_T0004.html\n",
      "no title for this speaker Dr Mohamad Maliki Bin Osman  in this file topic_reportid=007_20120214_S0007_T0002.html\n",
      "no title for this speaker Ms Sim Ann  in this file topic_reportid=007_20120228_S0007_T0003.html\n",
      "no title for this speaker Mr Lim Hng Kiang in this file topic_reportid=007_20120514_S0007_T0002.html\n",
      "no title for this speaker Mr Teo Chee Hean  in this file topic_reportid=007_20120709_S0007_T0003.html\n",
      "3275/3810\n",
      "no title for this speaker Mr Lim Hng Kiang in this file topic_reportid=008_20120409_S0007_T0005.html\n",
      "no title for this speaker BG [NS] Tan Chuan-Jin in this file topic_reportid=008_20120514_S0007_T0003.html\n",
      "exception: 'tuple' object has no attribute 'split' - topic_reportid=008_20120514_S0007_T0003.html\n",
      "no title for this speaker Ms Denise Phua Lay Peng (Moulmein-Kallang) in this file topic_reportid=008_20120710_S0007_T0006.html\n",
      "levenshtein matched youth and sports to hany soh\n",
      "levenshtein matched mg [ns] chan chun sing to chan chun sing\n",
      "no title for this speaker Mr Teo Chee Hean in this file topic_reportid=009_20120214_S0007_T0004.html\n",
      "no title for this speaker Mrs Josephine Teo  in this file topic_reportid=009_20120228_S0007_T0005.html\n",
      "3300/3810\n",
      "no title for this speaker BG [NS] Tan Chuan-Jin in this file topic_reportid=009_20120710_S0007_T0007.html\n",
      "no title for this speaker Mrs Josephine Teo  in this file topic_reportid=010_20111121_S0007_T0007.html\n",
      "no title for this speaker Mr Hawazi Daipi  in this file topic_reportid=010_20111122_S0007_T0008.html\n",
      "no title for this speaker Mr Teo Chee Hean  in this file topic_reportid=010_20120214_S0007_T0005.html\n",
      "no title for this speaker Mr Lui Tuck Yew in this file topic_reportid=010_20120409_S0007_T0007.html\n",
      "found minister: minister or national development; matched to Minister for National Development\n",
      "no title for this speaker BG [NS] Tan Chuan-Jin  in this file topic_reportid=011_20111021_S0007_T0009.html\n",
      "no title for this speaker Dr Amy Khor Lean Suan  in this file topic_reportid=011_20120217_S0007_T0008.html\n",
      "no title for this speaker Mr Lui Tuck Yew in this file topic_reportid=011_20120409_S0007_T0008.html\n",
      "3325/3810\n",
      "no title for this speaker Mr Khaw Boon Wan in this file topic_reportid=012_20111020_S0007_T0009.html\n",
      "no title for this speaker Mr S Iswaran  in this file topic_reportid=012_20120710_S0007_T0010.html\n",
      "no title for this speaker Mr Khaw Boon Wan in this file topic_reportid=013_20111020_S0007_T0010.html\n",
      "no title for this speaker Mr Heng Swee Keat in this file topic_reportid=013_20120116_S0007_T0010.html\n",
      "no title for this speaker Ms Sim Ann  in this file topic_reportid=013_20120409_S0007_T0010.html\n",
      "3350/3810\n",
      "no title for this speaker Mr K Shanmugam in this file topic_reportid=014_20111121_S0007_T0011.html\n",
      "no title for this speaker Ms Sim Ann  in this file topic_reportid=014_20120409_S0007_T0011.html\n",
      "no title for this speaker Mr Hri Kumar Nair in this file topic_reportid=015_20120116_S0007_T0012.html\n",
      "no title for this speaker : in this file topic_reportid=015_20120514_S0007_T0010.html\n",
      "levenshtein matched : to don wee\n",
      "no title for this speaker Mr Gan Kim Yong in this file topic_reportid=016_20111121_S0007_T0013.html\n",
      "no title for this speaker BG [NS] Tan Chuan-Jin  in this file topic_reportid=016_20120217_S0007_T0013.html\n",
      "no title for this speaker Mdm Halimah Yacob  in this file topic_reportid=017_20120116_S0007_T0014.html\n",
      "no title for this speaker Ms Sim Ann  in this file topic_reportid=017_20120217_S0007_T0014.html\n",
      "3375/3810\n",
      "no title for this speaker BG [NS] Tan Chuan-Jin in this file topic_reportid=018_20120409_S0007_T0015.html\n",
      "no title for this speaker BG [NS] Tan Chuan-Jin  in this file topic_reportid=019_20120116_S0007_T0016.html\n",
      "3400/3810\n",
      "no title for this speaker BG [NS] Tan Chuan-Jin  in this file topic_reportid=020_20120514_S0007_T0015.html\n",
      "no title for this speaker Mr Khaw Boon Wan in this file topic_reportid=021_20120514_S0007_T0016.html\n",
      "no title for this speaker : in this file topic_reportid=022_20120514_S0007_T0017.html\n",
      "3425/3810\n",
      "no title for this speaker Dr Lim Wee Kiak in this file topic_reportid=023_20120514_S0007_T0018.html\n",
      "3450/3810\n",
      "3475/3810\n",
      "3500/3810\n",
      "3525/3810\n",
      "3550/3810\n",
      "3575/3810\n",
      "3600/3810\n",
      "3625/3810\n",
      "3650/3810\n",
      "3675/3810\n",
      "no speakers? topic_reportid=059_20120514_S0015_T0029.html\n",
      "3700/3810\n",
      "3725/3810\n",
      "no speakers? topic_reportid=071_20120514_S0008_T0001.html\n",
      "3750/3810\n",
      "3775/3810\n",
      "3800/3810\n",
      "=====DONE==================================================\n",
      "total pqs: 4167\n",
      "total files: 3810\n",
      "avg pqs per file: 1.0937007874015747\n",
      "files with exceptions: [['sprs3topic_reportid=written-answer-2873.html', PermissionError(13, 'Permission denied')], ['topic_reportid=008_20120514_S0007_T0003.html', AttributeError(\"'tuple' object has no attribute 'split'\")]]\n"
     ]
    }
   ],
   "source": [
    "pqs = []\n",
    "files_and_exceptions = []\n",
    "files_to_run_through = os.listdir('scraped_content')\n",
    "\n",
    "for i in range(len(files_to_run_through)):\n",
    "    file = files_to_run_through[i]\n",
    "    filepath = os.path.join('scraped_content', file)\n",
    "    if os.stat(filepath).st_size < 200000: # the html elements alr take up more than 300kb, so if a file is this small then someth's wrong\n",
    "        continue\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            soup = bs(f, 'html.parser')\n",
    "        soup_to_pqs(soup, file)\n",
    "    except Exception as e:\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        #raise e\n",
    "        print(f'exception: {str(e)} - {file}')\n",
    "        files_and_exceptions.append([file, e])\n",
    "        continue\n",
    "        \n",
    "    if i%25==0:\n",
    "        print(f'{i}/{len(files_to_run_through)}')\n",
    "        \n",
    "print('=====DONE==================================================')\n",
    "print(f'total pqs: {len(pqs)}')\n",
    "print(f'total files: {len(files_to_run_through)}')\n",
    "print(f'avg pqs per file: {len(pqs)/len(files_to_run_through)}')\n",
    "print(f'files with exceptions: {files_and_exceptions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "883514f5-2bfa-4845-b83e-3d4cfbb4c88e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asker_name</th>\n",
       "      <th>asker_party</th>\n",
       "      <th>asker_parliaments</th>\n",
       "      <th>askees</th>\n",
       "      <th>question</th>\n",
       "      <th>parliament_no</th>\n",
       "      <th>session_no</th>\n",
       "      <th>volume_no</th>\n",
       "      <th>sitting_no</th>\n",
       "      <th>sitting_date</th>\n",
       "      <th>report_section</th>\n",
       "      <th>title</th>\n",
       "      <th>responder_name</th>\n",
       "      <th>responder_title</th>\n",
       "      <th>response</th>\n",
       "      <th>discussion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Louis Ng Kok Kwang</td>\n",
       "      <td>People's Action Party</td>\n",
       "      <td>(13, 14)</td>\n",
       "      <td>(Minister for Transport,)</td>\n",
       "      <td>(a) what are the main factors taken into consi...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>ReportSection.ORAL</td>\n",
       "      <td>Factors for Considering Underground Alignments...</td>\n",
       "      <td>Khaw Boon Wan</td>\n",
       "      <td>The Minister for Transport</td>\n",
       "      <td>Mdm Speaker, the Cross Island Line (CRL) will ...</td>\n",
       "      <td>[[Louis Ng Kok Kwang, I thank the Minister for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lim Wee Kiak</td>\n",
       "      <td>People's Action Party</td>\n",
       "      <td>(11, 12, 13, 14)</td>\n",
       "      <td>(Minister for Defence,)</td>\n",
       "      <td>whether he can provide an update on Singapore'...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>22</td>\n",
       "      <td>2016-08-15</td>\n",
       "      <td>ReportSection.ORAL</td>\n",
       "      <td>Singapore's Deployment to Support Multi-nation...</td>\n",
       "      <td>Ng Eng Hen</td>\n",
       "      <td>The Minister for Defence</td>\n",
       "      <td>Madam, in January this year, I informed this H...</td>\n",
       "      <td>[[Lim Wee Kiak, Mdm Speaker, let me thank the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lim Biow Chuan</td>\n",
       "      <td>People's Action Party</td>\n",
       "      <td>(11, 12, 13, 14)</td>\n",
       "      <td>(Minister for Manpower,)</td>\n",
       "      <td>(a) to date, how many appeals have been receiv...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>24</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>ReportSection.ORAL</td>\n",
       "      <td>Appeals to CPF Board for Inclusion in Silver S...</td>\n",
       "      <td>Lim Swee Say</td>\n",
       "      <td>The Minister for Manpower</td>\n",
       "      <td>Mdm Speaker, I would like to put Silver Suppor...</td>\n",
       "      <td>[[Lim Biow Chuan, Thank you, Mdm Speaker. Just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tan Wu Meng</td>\n",
       "      <td>People's Action Party</td>\n",
       "      <td>(13, 14)</td>\n",
       "      <td>(Minister for Manpower,)</td>\n",
       "      <td>(a) among Singaporeans turning 65 years old in...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>24</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>ReportSection.ORAL</td>\n",
       "      <td>Appeals to CPF Board for Inclusion in Silver S...</td>\n",
       "      <td>Lim Swee Say</td>\n",
       "      <td>The Minister for Manpower</td>\n",
       "      <td>Mdm Speaker, I would like to put Silver Suppor...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tin Pei Ling</td>\n",
       "      <td>People's Action Party</td>\n",
       "      <td>(12, 13, 14)</td>\n",
       "      <td>(Minister for Manpower,)</td>\n",
       "      <td>what is the success rate of appeal for the Sil...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>24</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>ReportSection.ORAL</td>\n",
       "      <td>Appeals to CPF Board for Inclusion in Silver S...</td>\n",
       "      <td>Lim Swee Say</td>\n",
       "      <td>The Minister for Manpower</td>\n",
       "      <td>Mdm Speaker, I would like to put Silver Suppor...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4162</th>\n",
       "      <td>Ang Wei Neng</td>\n",
       "      <td>People's Action Party</td>\n",
       "      <td>(12, 13, 14)</td>\n",
       "      <td>(Acting Minister for Community Development, Yo...</td>\n",
       "      <td>since the relaxation of the criteria for the P...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-08-13</td>\n",
       "      <td>ReportSection.WRITTEN</td>\n",
       "      <td>Number of Citizens Qualified for Public Assist...</td>\n",
       "      <td>Chan Chun Sing</td>\n",
       "      <td></td>\n",
       "      <td>On 1 April 2012, MCYS revised the Public Assis...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>Tan Kheng Boon Eugene</td>\n",
       "      <td>Nominated Member of Parliament</td>\n",
       "      <td>(12,)</td>\n",
       "      <td>(Acting Minister for Community Development, Yo...</td>\n",
       "      <td>(a) whether the initial lease of the Farrer Pa...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-08-13</td>\n",
       "      <td>ReportSection.WRITTEN</td>\n",
       "      <td>Lease of Farrer Park Swimming Complex to Priva...</td>\n",
       "      <td>Chan Chun Sing</td>\n",
       "      <td></td>\n",
       "      <td>Farrer Park Swimming Complex was closed to the...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>Zainal Sapari</td>\n",
       "      <td>People's Action Party</td>\n",
       "      <td>(12, 13)</td>\n",
       "      <td>(Acting Minister for Manpower,)</td>\n",
       "      <td>(a) what is the current number of Singaporeans...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-08-13</td>\n",
       "      <td>ReportSection.WRITTEN</td>\n",
       "      <td>CPF Dependants' Protection Scheme</td>\n",
       "      <td>Tan Chuan-Jin</td>\n",
       "      <td></td>\n",
       "      <td>The Dependants' Protection Scheme (DPS) is a t...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>Patrick Tay Teck Guan</td>\n",
       "      <td>People's Action Party</td>\n",
       "      <td>(12, 13, 14)</td>\n",
       "      <td>(Acting Minister for Manpower,)</td>\n",
       "      <td>(a) what is the current number of CPF account ...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-08-13</td>\n",
       "      <td>ReportSection.WRITTEN</td>\n",
       "      <td>CPF Dependants' Protection Scheme</td>\n",
       "      <td>Tan Chuan-Jin</td>\n",
       "      <td></td>\n",
       "      <td>The Dependants' Protection Scheme (DPS) is a t...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>Seng Han Thong</td>\n",
       "      <td>People's Action Party</td>\n",
       "      <td>(9, 10, 11, 12)</td>\n",
       "      <td>(Acting Minister for Manpower,)</td>\n",
       "      <td>(a) how many CPF members have opted out of the...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-08-13</td>\n",
       "      <td>ReportSection.WRITTEN</td>\n",
       "      <td>CPF Dependants' Protection Scheme</td>\n",
       "      <td>Tan Chuan-Jin</td>\n",
       "      <td></td>\n",
       "      <td>The Dependants' Protection Scheme (DPS) is a t...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4167 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 asker_name                     asker_party asker_parliaments  \\\n",
       "0        Louis Ng Kok Kwang           People's Action Party          (13, 14)   \n",
       "1              Lim Wee Kiak           People's Action Party  (11, 12, 13, 14)   \n",
       "2            Lim Biow Chuan           People's Action Party  (11, 12, 13, 14)   \n",
       "3               Tan Wu Meng           People's Action Party          (13, 14)   \n",
       "4              Tin Pei Ling           People's Action Party      (12, 13, 14)   \n",
       "...                     ...                             ...               ...   \n",
       "4162           Ang Wei Neng           People's Action Party      (12, 13, 14)   \n",
       "4163  Tan Kheng Boon Eugene  Nominated Member of Parliament             (12,)   \n",
       "4164          Zainal Sapari           People's Action Party          (12, 13)   \n",
       "4165  Patrick Tay Teck Guan           People's Action Party      (12, 13, 14)   \n",
       "4166         Seng Han Thong           People's Action Party   (9, 10, 11, 12)   \n",
       "\n",
       "                                                 askees  \\\n",
       "0                             (Minister for Transport,)   \n",
       "1                               (Minister for Defence,)   \n",
       "2                              (Minister for Manpower,)   \n",
       "3                              (Minister for Manpower,)   \n",
       "4                              (Minister for Manpower,)   \n",
       "...                                                 ...   \n",
       "4162  (Acting Minister for Community Development, Yo...   \n",
       "4163  (Acting Minister for Community Development, Yo...   \n",
       "4164                    (Acting Minister for Manpower,)   \n",
       "4165                    (Acting Minister for Manpower,)   \n",
       "4166                    (Acting Minister for Manpower,)   \n",
       "\n",
       "                                               question  parliament_no  \\\n",
       "0     (a) what are the main factors taken into consi...             13   \n",
       "1     whether he can provide an update on Singapore'...             13   \n",
       "2     (a) to date, how many appeals have been receiv...             13   \n",
       "3     (a) among Singaporeans turning 65 years old in...             13   \n",
       "4     what is the success rate of appeal for the Sil...             13   \n",
       "...                                                 ...            ...   \n",
       "4162  since the relaxation of the criteria for the P...             12   \n",
       "4163  (a) whether the initial lease of the Farrer Pa...             12   \n",
       "4164  (a) what is the current number of Singaporeans...             12   \n",
       "4165  (a) what is the current number of CPF account ...             12   \n",
       "4166  (a) how many CPF members have opted out of the...             12   \n",
       "\n",
       "      session_no  volume_no  sitting_no sitting_date         report_section  \\\n",
       "0              1         94           7   2016-02-29     ReportSection.ORAL   \n",
       "1              1         94          22   2016-08-15     ReportSection.ORAL   \n",
       "2              1         94          24   2016-09-13     ReportSection.ORAL   \n",
       "3              1         94          24   2016-09-13     ReportSection.ORAL   \n",
       "4              1         94          24   2016-09-13     ReportSection.ORAL   \n",
       "...          ...        ...         ...          ...                    ...   \n",
       "4162           1         89           5   2012-08-13  ReportSection.WRITTEN   \n",
       "4163           1         89           5   2012-08-13  ReportSection.WRITTEN   \n",
       "4164           1         89           5   2012-08-13  ReportSection.WRITTEN   \n",
       "4165           1         89           5   2012-08-13  ReportSection.WRITTEN   \n",
       "4166           1         89           5   2012-08-13  ReportSection.WRITTEN   \n",
       "\n",
       "                                                  title  responder_name  \\\n",
       "0     Factors for Considering Underground Alignments...   Khaw Boon Wan   \n",
       "1     Singapore's Deployment to Support Multi-nation...      Ng Eng Hen   \n",
       "2     Appeals to CPF Board for Inclusion in Silver S...    Lim Swee Say   \n",
       "3     Appeals to CPF Board for Inclusion in Silver S...    Lim Swee Say   \n",
       "4     Appeals to CPF Board for Inclusion in Silver S...    Lim Swee Say   \n",
       "...                                                 ...             ...   \n",
       "4162  Number of Citizens Qualified for Public Assist...  Chan Chun Sing   \n",
       "4163  Lease of Farrer Park Swimming Complex to Priva...  Chan Chun Sing   \n",
       "4164                  CPF Dependants' Protection Scheme   Tan Chuan-Jin   \n",
       "4165                  CPF Dependants' Protection Scheme   Tan Chuan-Jin   \n",
       "4166                  CPF Dependants' Protection Scheme   Tan Chuan-Jin   \n",
       "\n",
       "                 responder_title  \\\n",
       "0     The Minister for Transport   \n",
       "1       The Minister for Defence   \n",
       "2      The Minister for Manpower   \n",
       "3      The Minister for Manpower   \n",
       "4      The Minister for Manpower   \n",
       "...                          ...   \n",
       "4162                               \n",
       "4163                               \n",
       "4164                               \n",
       "4165                               \n",
       "4166                               \n",
       "\n",
       "                                               response  \\\n",
       "0     Mdm Speaker, the Cross Island Line (CRL) will ...   \n",
       "1     Madam, in January this year, I informed this H...   \n",
       "2     Mdm Speaker, I would like to put Silver Suppor...   \n",
       "3     Mdm Speaker, I would like to put Silver Suppor...   \n",
       "4     Mdm Speaker, I would like to put Silver Suppor...   \n",
       "...                                                 ...   \n",
       "4162  On 1 April 2012, MCYS revised the Public Assis...   \n",
       "4163  Farrer Park Swimming Complex was closed to the...   \n",
       "4164  The Dependants' Protection Scheme (DPS) is a t...   \n",
       "4165  The Dependants' Protection Scheme (DPS) is a t...   \n",
       "4166  The Dependants' Protection Scheme (DPS) is a t...   \n",
       "\n",
       "                                             discussion  \n",
       "0     [[Louis Ng Kok Kwang, I thank the Minister for...  \n",
       "1     [[Lim Wee Kiak, Mdm Speaker, let me thank the ...  \n",
       "2     [[Lim Biow Chuan, Thank you, Mdm Speaker. Just...  \n",
       "3                                                    []  \n",
       "4                                                    []  \n",
       "...                                                 ...  \n",
       "4162                                                 []  \n",
       "4163                                                 []  \n",
       "4164                                                 []  \n",
       "4165                                                 []  \n",
       "4166                                                 []  \n",
       "\n",
       "[4167 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq_df = pd.DataFrame(pqs, columns=['asker_name', 'asker_party', 'asker_parliaments', 'askees', 'question', 'parliament_no', 'session_no', 'volume_no', 'sitting_no', 'sitting_date', 'report_section', 'title', 'responder_name', 'responder_title', 'response', 'discussion'])\n",
    "pq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b10be6-e33f-4d37-9194-0f2c9936a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_df.to_csv('pqs.csv', index=False, sep='|') # sep=',' gives formatting issues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cda24a8-34bc-42ad-bc1f-6dc220aae435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parties: {'', \"Singapore People's Party\", 'Progress Singapore Party', 'Nominated Member of Parliament', \"People's Action Party\", \"Workers' Party\"} (len: 6)\n",
      "\n",
      "askees: {'Acting Minister for Community Development, Youth and Sports', 'Acting Minister for Education', 'Minister for Education', 'Minister for Trade and Industry', 'Acting Minister for Social and Family Development', 'Minister for Social and Family Development', 'Deputy Prime Minister', 'Minister for Home Affairs', 'Minister for National Development', 'Minister for Health', 'Minister for Communications and Information', 'Minister for Sustainability and the Environment', 'Minister for Transport', 'Minister for Manpower', 'Acting Minister for Culture, Community and Youth', 'Minister for Law', 'asked the Minister for Transport', 'Minister for the Environment and Water Resources', 'Prime Minister', 'Minister-in-charge for Muslim Affairs', 'Minister for Culture, Community and Youth', 'Minister for Defence', 'Minister for Information, Communications and the Arts', 'Acting Minister for Manpower', 'Acting Minister for Community Development, Youth, Sports', 'Minister for Foreign Affairs', 'Minister for Finance'} (len: 27)\n"
     ]
    }
   ],
   "source": [
    "assert all(pq_df.parliament_no < 15) and all(pq_df.parliament_no >= 12)\n",
    "assert all(map(lambda x: not x[0].isupper(), pq_df.question.values)) \n",
    "assert all(map(lambda x: not x[:3] == 'and', pq_df.question.values)) \n",
    "parties_set = set(pq_df.asker_party.values)\n",
    "print(f'parties: {parties_set} (len: {len(parties_set)})')\n",
    "print()\n",
    "askee_set = set([askees for sublist in pq_df.askees for askees in sublist])\n",
    "print(f'askees: {askee_set} (len: {len(askee_set)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b90b30e-8e35-4dfb-93f2-b5d381b26033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(pq_df.asker_name.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c547b906-6b9c-4934-ac3d-9b8c3a345c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'Tan Yia Swam', 185, 'Lee Bee Wah', 208, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_count = 999\n",
    "min_mp = None\n",
    "max_count = 0\n",
    "max_mp = None\n",
    "less_than_ten = 0\n",
    "just_one = 0\n",
    "for name in pq_df.asker_name.values:\n",
    "    count_here = pq_df[pq_df.asker_name == name]['asker_name'].count()\n",
    "    if count_here < min_count:\n",
    "        min_count = count_here\n",
    "        min_mp = name\n",
    "    if count_here > max_count:\n",
    "        max_count = count_here\n",
    "        max_mp = name\n",
    "    if count_here < 10:\n",
    "        less_than_ten += 1\n",
    "    if count_here == 1:\n",
    "        just_one += 1\n",
    "        \n",
    "min_count, min_mp, max_count, max_mp, less_than_ten, just_one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
