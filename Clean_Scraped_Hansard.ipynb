{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbdbd63a-9d50-493b-967f-0078c4e50214",
   "metadata": {},
   "source": [
    "run the other notebooks. should give two csv files. this one will combine them and clean up the data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911324d7-4429-41bc-b979-769a705cd945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import ast\n",
    "import os\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e9930a-84f1-483a-8415-3c2ec4d98245",
   "metadata": {},
   "source": [
    "**for merging with mps.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce675208-2543-4282-8a8f-eeb5d78f77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_df = pd.read_csv('mps.csv')\n",
    "mp_df.Party = mp_df.Party.apply(ast.literal_eval)\n",
    "mp_df.Parliaments = mp_df.Parliaments.apply(ast.literal_eval)\n",
    "mps = dict(\n",
    "    zip(mp_df.Name.apply(lambda x: x.replace('.', '').replace(',', '').lower()), # keys\n",
    "    zip(mp_df.Name, mp_df.Party, mp_df.Parliaments))) # values\n",
    "mp_names = list(mps.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c72765-1e10-4f66-b0c5-de5d4ad837c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alr_matched = set() # honorific+names that have alr been matched to names so we don't spam the print\n",
    "ministers_found = set() # minister titles that have alr been found (to be used for future searches in case of typos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a41c038-c9f4-4b92-9313-fe5fccdab091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for matching honorific+name in report to actual mp data.\n",
    "# cannot simply remove honorific as the programmer doesn't have an exhaustive list\n",
    "# of honorifics, and some are quite rare in everyday use (e.g. Inche Rahamat Bin Kenap).\n",
    "def honorific_name_to_mp_data(honorific_name):\n",
    "    honorific_name = honorific_name.replace('.','').replace(',','').lower().strip()\n",
    "    \n",
    "    # try the easy way first (find and remove honorific)\n",
    "    honorific_match = re.match(r'(mr|mrs|ms|miss|mdm|dr|er dr|prof|assoc prof|er|asst prof|assoc prof dr|inche|encik)', honorific_name)\n",
    "    if honorific_match:\n",
    "        name = honorific_name[honorific_match.span()[1]+1:]\n",
    "        if name in mps.keys():\n",
    "            return mps[name]\n",
    "        \n",
    "        # seems quite common for them to write \"asked\" twice in the hansard proceedings\n",
    "        last_asked = name.rfind(' asked')\n",
    "        if last_asked and name[:last_asked] in mps.keys():\n",
    "            return mps[name[:last_asked]]\n",
    "\n",
    "        # slightly harder way (rearranging words)\n",
    "        for mp_name in mp_names:\n",
    "            mp_name_words = set(mp_name.split(' '))\n",
    "            name_words = set(name.split(' '))\n",
    "            if mp_name_words == name_words:\n",
    "                if (honorific_name, mp_name) not in alr_matched:\n",
    "                    #print(f'rearranging matched {honorific_name} to {mp_name}')\n",
    "                    alr_matched.add((honorific_name, mp_name))\n",
    "                return mps[mp_name]\n",
    "            \n",
    "            # for omission of chinese name\n",
    "            if len(mp_name_words) - len(name_words) <= 2 and len(name_words) >= 2 and name_words.issubset(mp_name_words):\n",
    "                if (honorific_name, mp_name) not in alr_matched:\n",
    "                    print(f'allowing omitted words in name matched {honorific_name} to {mp_name}')\n",
    "                    alr_matched.add((honorific_name, mp_name))\n",
    "                return mps[mp_name]\n",
    "                \n",
    "    digit_match = re.search('\\d+', honorific_name)\n",
    "    if digit_match:\n",
    "        # names shldn't have digits\n",
    "        honorific_name = honorific_name[digit_match.span()[1]:]\n",
    "        return honorific_name_to_mp_data(honorific_name)\n",
    "        \n",
    "    # the hard way (levenshtein)\n",
    "    min_levenshtein = 99999\n",
    "    min_ind = -1\n",
    "    for i in range(len(mp_names)):\n",
    "        l_dist = levenshtein(mp_names[i], honorific_name)\n",
    "        if l_dist < min_levenshtein:\n",
    "            min_levenshtein = l_dist\n",
    "            min_ind = i\n",
    "            \n",
    "    if (honorific_name, mp_names[min_ind]) not in alr_matched:\n",
    "        print(f'levenshtein matched {honorific_name} to {mp_names[min_ind]}')\n",
    "        alr_matched.add((honorific_name, mp_names[min_ind]))\n",
    "    return mps[mp_names[min_ind]]\n",
    "\n",
    "# borrowed from: https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/\n",
    "# we use levenshtein as it helps to protect against typos too, like the \"asked asked\" in:\n",
    "# https://sprs.parl.gov.sg/search/sprs3topic?reportid=oral-answer-2822\n",
    "def levenshtein(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2eee96-c726-4f73-a0ab-a5b630687de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pqs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b55804-1d18-45fa-8518-78a1bacdc56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportSection(Enum):\n",
    "    WRITTEN = 'Written Answers to Questions'\n",
    "    WRITTEN_NA = 'Written Answers to Questions for Oral Answer Not Answered by End of Question Time'\n",
    "    ORAL = 'Oral Answers to Questions'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759f4b8-16fc-4450-a923-8bac17a53f4f",
   "metadata": {},
   "source": [
    "we assume that all pqs are prefaced with #. (non sprs) or # (sprs). ignore follow up qns since we are only interested in mapping mps to topics, and the follow up qns will always be from the same mp and on the same topic.\n",
    "\n",
    "notes regarding minister titles:\n",
    "* Minister for Culture, Community and Youth is the only minister title with a comma\n",
    "* but there used to be Minister for Information, Communication and the Arts and Minister for Community Development, Youth and Sports\n",
    "* no questions were ever directed to minister mentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd366a7a-0882-4584-a7ec-423a6a23fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_word = r'[A-Z][a-z]+'\n",
    "cap_words = f'({cap_word})( {cap_word})*'\n",
    "mccy = '(Acting )?Minister for Culture, Community and Youth'\n",
    "mica = '(Acting )?Minister for Information, Communications and the Arts'\n",
    "mcdys = '(Acting )?Minister for Community Development, Youth( and|,) Sports'\n",
    "micma = 'Minister-in-charge of Muslim Affairs'\n",
    "minister_for_something = f'({cap_words} )?Minister (for|of) (the )?{cap_words}( and (the )?{cap_words})?'\n",
    "something_minister = f'{cap_words} Minister'\n",
    "one_minister_regex = f'(({mccy})|({mica})|({mcdys})|({micma})|({minister_for_something})|({something_minister}))'\n",
    "minister_regex = re.compile(f'{one_minister_regex}( and (the )?{one_minister_regex})?') # can have multiple targets\n",
    "\n",
    "def first_two_capitalized(words):\n",
    "    return words[0][0].isupper() and words[1][0].isupper() and words[0][1] and words[0][1].islower()\n",
    "\n",
    "def trim_off_non_pq_content_at_start(para):\n",
    "    para_words = para.split(' ')\n",
    "    if first_two_capitalized(para_words):\n",
    "        return para\n",
    "    \n",
    "    # i assume honorific+name has at least two words capitalized and non-numbers\n",
    "    while not first_two_capitalized(para_words):\n",
    "        para_words = para_words[1:]\n",
    "    \n",
    "    return ' '.join(para_words)\n",
    "\n",
    "def get_ministers_and_question(para):\n",
    "    minister_match = re.search(minister_regex, para)\n",
    "    if not minister_match:\n",
    "        # report might've been in the wrong case; try to match to existing ministers\n",
    "        minister_match = re.search(\n",
    "            '(' + '|'.join(list(map(lambda s: s.lower().replace(' for ', '.{1,5}'), ministers_found))) + ')',\n",
    "            para.lower()\n",
    "        )\n",
    "        if not minister_match:\n",
    "            minister_match = re.search(\n",
    "            '(' + '|'.join(list(map(lambda s: s.lower().replace(' for ', '(\\s)*(for|of)(\\s)*'), ministers_found))) + ')',\n",
    "            para.lower()\n",
    "        )\n",
    "        if not minister_match:\n",
    "            for existing_minister in ministers_found:\n",
    "                if existing_minister.replace(' ', '') in para.replace(' ', ''):\n",
    "                    minister_match = re.search('(\\s)?'.join(c for c in existing_minister.replace(' ', '').lower()), para.lower())\n",
    "                    break   \n",
    "        min_levenshtein = 99999\n",
    "        min_minister = None\n",
    "        for existing_minister in ministers_found:\n",
    "            dist = levenshtein(existing_minister, minister_match.group())\n",
    "            if dist < min_levenshtein:\n",
    "                min_levenshtein = dist\n",
    "                min_minister = existing_minister\n",
    "        \n",
    "        print(f'found minister: {str(minister_match.group())}; matched to {min_minister}')\n",
    "        askee = min_minister\n",
    "    else:\n",
    "        askee = para[:minister_match.span()[1]].replace(' of ', ' for ')\n",
    "        ministers_found.add(askee)\n",
    "    question = para[minister_match.span()[1]:].strip()\n",
    "    if ' and Leader' in askee:\n",
    "        askee = askee[:-11]\n",
    "        print(f'removed \"and leader\" from {askee}')\n",
    "    \n",
    "    if not re.search('and (the )?Minister', askee):\n",
    "        return (askee,), question   \n",
    "    else:\n",
    "        askee = askee.replace('and the Minister', 'and Minister')\n",
    "        askees = askee.split(' and Minister')\n",
    "        return (askees[0], 'Minister' + askees[1]), question\n",
    "\n",
    "def soup_to_pqs(soup):\n",
    "    stripped_strings = list(map(\n",
    "        lambda text: re.sub(r'\\s+', ' ', text),\n",
    "        filter(\n",
    "            lambda text: not re.match(r'Page:\\s+\\d+', text) and not re.match(r'Column:\\s+\\d+', text),\n",
    "            [text for text in soup.stripped_strings])))\n",
    "    parl_no = int(stripped_strings[3])\n",
    "    sess_no = int(stripped_strings[5])\n",
    "    vol_no = int(stripped_strings[7])\n",
    "    sitting_no = int(stripped_strings[9])\n",
    "    sitting_date = datetime.strptime(stripped_strings[11], '%d-%m-%Y')\n",
    "    section_name_raw = stripped_strings[13].lower()\n",
    "    \n",
    "    if 'answered' in section_name_raw:\n",
    "        section_name = ReportSection.WRITTEN_NA\n",
    "    elif 'written' in section_name_raw:\n",
    "        section_name = ReportSection.WRITTEN\n",
    "    elif 'oral' in section_name_raw:\n",
    "        section_name = ReportSection.ORAL\n",
    "    else:\n",
    "        raise f'no section name??? {section_name_raw}'\n",
    "    \n",
    "    title = stripped_strings[15]\n",
    "    the_rest = stripped_strings[19:]\n",
    "    while not re.match(r'\\d\\d?', the_rest[0]):\n",
    "        the_rest = the_rest[1:]\n",
    "        \n",
    "    indices_corresponding_to_pqs = []\n",
    "    indices_corresponding_to_speakers = []\n",
    "    for i in range(len(the_rest)):\n",
    "        if the_rest[i][0] == ':':\n",
    "            indices_corresponding_to_speakers.append(i-1)\n",
    "        elif re.match(r'\\d\\d?', the_rest[i]):\n",
    "            indices_corresponding_to_pqs.append(i)\n",
    "        \n",
    "    pq_sublists = []\n",
    "    while len(indices_corresponding_to_pqs) > 1:\n",
    "        pq_sublists.append(the_rest[indices_corresponding_to_pqs[0]+1:indices_corresponding_to_pqs[1]])\n",
    "        indices_corresponding_to_pqs = indices_corresponding_to_pqs[1:]\n",
    "        \n",
    "    pq_sublists.append(the_rest[indices_corresponding_to_pqs[0]+1:indices_corresponding_to_speakers[0]])\n",
    "    \n",
    "    speaking_sublists = []\n",
    "    \n",
    "    while len(indices_corresponding_to_speakers) > 1:\n",
    "        speaking_sublists.append(the_rest[indices_corresponding_to_speakers[0]:indices_corresponding_to_speakers[1]])\n",
    "        indices_corresponding_to_speakers = indices_corresponding_to_speakers[1:]\n",
    "    \n",
    "    speaking_sublists.append(the_rest[indices_corresponding_to_speakers[0]:])\n",
    "    \n",
    "    pqs = list(map(lambda sl: ' '.join(sl)\n",
    "    \n",
    "    \n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    \n",
    "    para = pq_para[0]\n",
    "    para = trim_off_non_pq_content_at_start(para) # sometimes we end up mistaking other numbers in the text as being the pq numbers. so we deal w that here.\n",
    "    asker_honorific_name, para = para.split(' asked the ', 1)\n",
    "    \n",
    "    ministers, question = get_ministers_and_question(para)\n",
    "    if question[0] == ',':\n",
    "        question = question[1:].strip()\n",
    "    asker, asker_party, asker_parls = honorific_name_to_mp_data(asker_honorific_name.strip())\n",
    "    pqs.append([asker, asker_party, asker_parls, ministers, question, *pq_para[1:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0314366-9a4d-4d9e-b74d-9fd5ebfd7830",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\users\\thisi\\appdata\\local\\temp\\ipykernel_6524\\607813641.py\u001b[0m(122)\u001b[0;36msoup_to_pqs\u001b[1;34m()\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  pq_sublists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mr Louis Ng Kok Kwang', 'asked the', 'Minister for Transport (a) what are the main factors taken into consideration when deciding on the possible underground alignments in the vicinity of the Central Catchment Nature Reserve (CCNR) for the Cross Island Line; (b) in view of the moderate environmental impact on the nature reserve for the alignment option that cuts beneath the CCNR, whether the Ministry will consider the alternative alignment along Lornie Road which will allow the MRT line to serve more residents and commuters in that vicinity and also result in the protection of our nature reserve and primary forest; and (c) whether the Environmental Impact Assessment report that was recently published can be made available for viewing online.']]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  speaking_sublists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The Minister for Transport (Mr Khaw Boon Wan)', ': Mdm Speaker, the Cross Island Line (CRL) will be an important part of our future MRT network. It will link east to west, from Changi to Jurong, covering more than 50 km with about 30 stations. The exact alignment is being studied. Our preliminary estimate is that commuters from residential areas like Loyang, Pasir Ris, Hougang, Ang Mo Kio, Sin Ming, Bukit Timah, Clementi and West Coast will make at least 600,000 trips on the CRL every day. This will place the CRL higher, in terms of capacity and usage, compared, for example, to the North East Line (NEL). The CRL will also significantly enhance our network resilience as commuters will have many more routing options with the CRL connecting to other lines.', 'What this means is that – nearly half of the 30-plus new stations will be interchange stations and that means that every other station will be an exchange station where you can switch to another line. This will significantly enhance the resilience of our network.', 'Now, specific to the question raised by the Member, the Government is studying two possible alignments for the CRL in the vicinity of the Central Catchment Nature Reserve (CCNR). Both options are underground, and construction of the tunnels for this stretch of the CRL will be carried out using bored tunnelling, instead of the cut-and-cover approach. Cut-and-cover means you cut through like a huge bulldozer and chop down whatever is in between, then you build the tunnel and you cover it up. With bored tunnelling, you avoid all the trauma and damages above the tunnel.', 'For the 4-km direct alignment option, 2 km will be deep below the CCNR. How deep is deep? About 40 m – or 12 storeys – below ground level. And more importantly, at that level, this is what geologists call the hard bedrock level. In our case, this is the Bukit Timah granite. At this level, there are no vegetation, no trees, no animals. Under this option, there will not be any construction of infrastructure at surface level within the CCNR.', 'The skirting alignment option, on the other hand, is about 9 km long. Because it is 9 km long, it will require longer tunnels. And therefore, it will require ventilation shafts and facilities on the surface; whereas in the earlier option, because it is short enough, you do not have to build all those quite ugly exhaust ducts which you see at some of our road junctions.', 'This option could incur around $2 billion – $2,000 million – more in expenditure and could result in land acquisitions. The Member suggested that the skirting alignment could potentially serve more residents. However, the catchment there is already served by the Circle Line and the upcoming Thomson-East Coast Line.', 'The CRL is a massive project and the Government will decide on its entire alignment only after making a total assessment including financial viability, technical feasibility and other relevant considerations. The Environmental Impact Assessment (EIA) is only one of the many studies which we need to undertake to help us determine the best alignment for the stretch of the CRL in the vicinity of the CCNR. Later, my MND colleague will provide some details on the EIA and also describe how the Government agencies are working closely with the nature groups on the EIA. It has been a very productive collaboration, although much remains to be done.', 'As the alignments can have different impact on the environment, commuters, taxpayers, businesses and home owners, the Government has a responsibility to study both options thoroughly. Besides the EIA, there are upcoming technical site investigation works which will allow us to determine the soil profile and condition. This will feed into the Engineering Feasibility study. Only after all these environmental and technical studies on both possible alignments have been completed, and taking into account the potential impact on the nature reserve, the travelling distance and time for commuters, the cost to taxpayers, and the potential acquisition of homes and businesses, will we be able to make an informed decision on the project and its exact alignment. There will be many more public consultations so that we can adequately factor in all views. All these studies and consultations may take two more years to complete.', 'Meanwhile, the EIA Phase 1 report is available online.'], ['Mr Louis Ng Kok Kwang (Nee Soon)', ': I thank the Minister for his reply. I have two supplementary questions. One, could the Minister clarify what is the total cost for the construction of the CRL and what percentage increase that is of the total construction cost if we use the skirting alignment?', 'Second, if we do use the skirting alignment, could the Minister clarify exactly which buildings or which houses may need to be acquired?'], ['Mr Khaw Boon Wan', ': Madam, a short answer to both questions is: I do not know yet. As I have said, this is a massive project and usually, it would take easily four to five years for all the important studies to be made. In fact, although the EIA is published now, this is a product of two years of discussions and consultations. In this particular instance, it is because of the interest of nature groups and the sensitivity of the possible impact of any work of this part of the CRL on the nature reserve that the issue now surfaces.', 'For the next leg of the studies, if we are allowed to proceed with the site investigation, we will be doing much more public consultations and that will allow us, LTA, to firm up on many of the answers to many of the questions that have yet to be answered, such as – who are affected, how much will it cost and so on. We have some idea because this is not the first time we are building an MRT line. We can have some idea about how much the cost will be, but one can never be sure because what happens underground is invisible; we do not know. And soil conditions, even though we are a tiny little red dot, the geology of east and west, north and south, can be very different. That is why it is so important to do a thorough site investigation.', 'So, the bottom line is this – what we are seeking is permission, in this case, from MND, to allow us to proceed with the site investigation for which there is a necessity to do this EIA. The EIA, after two years of study, is now published online. By the gazette requirements, Singaporeans, interest groups, stakeholders, are invited to give their comments. I am quite sure MND will take all those views into consideration and decide whether they would allow the site investigation to proceed. And if they do, we can then enter into Phase 2 of the EIA, which will study what are the tunnelling methods, what will be the impact of those construction works and subsequent running of the train on the nature reserve, and more importantly whether, there are suitable mitigation measures.', 'Sorry for a long reply, which is that there are many questions which remain unanswered. What I urge of Singaporeans is this: keep an open mind. Go with the facts, keep an open mind and look for the evidence.', 'Madam, over the weekend, I took my granddaughter, 3 years old, to watch Disney\\'s latest movie \"Zootopia\", the utopia for the animal kingdom where all animal species, even though they are former predators or preys can live in harmony, peaceful with one another. It was a good movie because it was not just for the kids; it carries important values, and some political messages. It tells the story of a little female bunny whose ambition is to bring about justice and change the world, and she wants to be a police officer. The police world, at that time was largely monopolised by larger animal species and all males. But she was determined to be a police officer. So, she had to fight stereotyping, sexism, racism, bias and prejudice. In the end, she succeeded through wit and effort, and demonstrated what she can achieve. Likewise, for the EIA, let us keep an open mind. I have read some of the very toxic comments on the EIA. They were made even before the EIA was published. I think there is an English word for that – that is bias, prejudice.'], ['Mr Gan Thiam Poh (Ang Mo Kio)', ':', 'I thank the Minister. I just want to find out if maintenance cost will also be considered beside the capital cost in the study.'], ['Mr Khaw Boon Wan', ': Yes, indeed. As I have said, this four-to-five year study is a total impact study. The EIA is just an environmental impact study on a short stretch of a line, but our job is to do a total impact study: the impact on the environment, the impact on taxpayers, the impact on the commuters. I should not be biased. I should not be prejudiced. So, I am not opting for one or the other yet. I am keeping a completely open mind but there has been comments about the second option that of course, clearly, anybody reading the map would know, it will take a longer route, takes a longer time. To the commuters, it means extra time. The media have been guessing the figures; they say \"an extra four minutes\".', 'I asked LTA, \"Is their estimation correct?\" And they did a calculation. They said, \"No, not quite.\" The extra time taken to cross the reserve if it takes a longer route is six minutes. Some people commented, \"Well, that is just a few minutes.\" I am not so sure we can just brush aside the extra six minutes, just like that, because in the mindset of the MRT commuters, an extra half a minute is already terrible. We know it! When the train has a disruption, causing an extra one minute of delay, commuters can, within that one minute, send off, maybe, 100 tweets to flame LTA or SMRT. So, an extra one minute is a lot of time, let alone six minutes! That is why, in the rail industry, they define disruption as anything that causes delay of more than five minutes; and six is more than five.']]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  continue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'pq_para' is not defined\n",
      "> \u001b[1;32mc:\\users\\thisi\\appdata\\local\\temp\\ipykernel_6524\\607813641.py\u001b[0m(122)\u001b[0;36msoup_to_pqs\u001b[1;34m()\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  speaker_sublists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'speaker_sublists' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  pq_sublsits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'pq_sublsits' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  pq_sublists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mr Zainal Sapari', \"asked the Acting Minister for Manpower (a) what is the current number of Singaporeans earning below $1,700 per month who opted out of the CPF Dependants' Protection Scheme; (b) what are the reasons for their opting out of the scheme; and (c) whether the Government can consider a scheme to waive or reduce the premiums for workers earning below $1,700 per month.\"], ['Mr Patrick Tay Teck Guan', \"asked the Acting Minister for Manpower (a) what is the current number of CPF account holders, with a breakdown in terms of age, gender and salary range, who are (i) on the Dependants' Protection Scheme (DPS); and (ii) not on DPS because of their opt-out; and (b) what has been the claims experience in the last five years.\"], ['Mr Seng Han Thong', \"asked the Acting Minister for Manpower (a) how many CPF members have opted out of the Dependants' Protection Scheme (DPS) since its inception and what is the income profile of those who opted out; (b) whether there are plans to review the scheme so that lower-income Singaporeans are adequately protected in view of its opt-out nature; and (c) how will CPF Board incentivise the lower income group to remain in the scheme.\"]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for file in [os.listdir('scraped_content')[0], os.listdir('scraped_content')[-1]]:\n",
    "    filepath = os.path.join('scraped_content', file)\n",
    "    with open(filepath, 'r') as f:\n",
    "        soup = bs(f, 'html.parser')\n",
    "    try:\n",
    "        soup_to_pqs(soup)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "883514f5-2bfa-4845-b83e-3d4cfbb4c88e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asker_name</th>\n",
       "      <th>asker_party</th>\n",
       "      <th>asker_parliaments</th>\n",
       "      <th>askee</th>\n",
       "      <th>question</th>\n",
       "      <th>sitting_date</th>\n",
       "      <th>parliament_no</th>\n",
       "      <th>report_section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [asker_name, asker_party, asker_parliaments, askee, question, sitting_date, parliament_no, report_section]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq_df = pd.DataFrame(pqs, columns=['asker_name', 'asker_party', 'asker_parliaments', 'askee', 'question', 'sitting_date', 'parliament_no', 'report_section'])\n",
    "pq_df.sitting_date = pq_df.sitting_date.apply(lambda dt: dt if dt.find('00:00:00') == -1 else dt[:dt.find('00:00:00')-1])\n",
    "pq_df.sitting_date = pq_df.sitting_date.apply(lambda dt: dt if dt.find('0:00') == -1 else dt[:dt.find('0:00')-1])\n",
    "pq_df.asker_party = pq_df.asker_party.apply(lambda x: x[0])\n",
    "pq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b10be6-e33f-4d37-9194-0f2c9936a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pq_df.to_csv('pqs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cda24a8-34bc-42ad-bc1f-6dc220aae435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "assert all(pq_df.parliament_no < 15) and all(pq_df.parliament_no >= 12)\n",
    "assert all(map(lambda x: not x[0].isupper(), pq_df.question.values)) \n",
    "assert all(map(lambda x: not x[:3] == 'and', pq_df.question.values)) \n",
    "print(set(pq_df.asker_party.values))\n",
    "print()\n",
    "print(set([askee for sublist in pq_df.askee for askee in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b90b30e-8e35-4dfb-93f2-b5d381b26033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(pq_df.asker_name.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c547b906-6b9c-4934-ac3d-9b8c3a345c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, None, 0, None, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_count = 999\n",
    "min_mp = None\n",
    "max_count = 0\n",
    "max_mp = None\n",
    "less_than_ten = 0\n",
    "for name in pq_df.asker_name.values:\n",
    "    count_here = pq_df[pq_df.asker_name == name]['asker_name'].count()\n",
    "    if count_here < min_count:\n",
    "        min_count = count_here\n",
    "        min_mp = name\n",
    "    if count_here > max_count:\n",
    "        max_count = count_here\n",
    "        max_mp = name\n",
    "    if count_here < 10:\n",
    "        less_than_ten += 1\n",
    "        \n",
    "min_count, min_mp, max_count, max_mp, less_than_ten"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
