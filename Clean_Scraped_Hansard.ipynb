{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbdbd63a-9d50-493b-967f-0078c4e50214",
   "metadata": {},
   "source": [
    "run the other notebooks. should give two csv files. this one will combine them and clean up the data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911324d7-4429-41bc-b979-769a705cd945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import ast\n",
    "import os\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pdb import set_trace as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e9930a-84f1-483a-8415-3c2ec4d98245",
   "metadata": {},
   "source": [
    "**for merging with mps.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce675208-2543-4282-8a8f-eeb5d78f77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_df = pd.read_csv('mps.csv')\n",
    "mp_df.Party = mp_df.Party.apply(ast.literal_eval)\n",
    "mp_df.Parliaments = mp_df.Parliaments.apply(ast.literal_eval)\n",
    "mps = dict(\n",
    "    zip(mp_df.Name.apply(lambda x: x.replace('.', '').replace(',', '').lower()), # keys\n",
    "    zip(mp_df.Name, mp_df.Party, mp_df.Parliaments))) # values\n",
    "mp_names = list(mps.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c72765-1e10-4f66-b0c5-de5d4ad837c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alr_matched = set() # honorific+names that have alr been matched to names so we don't spam the print\n",
    "ministers_found = set() # minister titles that have alr been found (to be used for future searches in case of typos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a41c038-c9f4-4b92-9313-fe5fccdab091",
   "metadata": {},
   "outputs": [],
   "source": [
    "honorific_regex = r'(mr|mrs|ms|miss|mdm|dr|er dr|prof|assoc prof|er|asst prof|assoc prof dr|inche|encik)'\n",
    "\n",
    "# for matching honorific+name in report to actual mp data.\n",
    "# cannot simply remove honorific as the programmer doesn't have an exhaustive list\n",
    "# of honorifics, and some are quite rare in everyday use (e.g. Inche Rahamat Bin Kenap).\n",
    "def honorific_name_to_mp_data(honorific_name):\n",
    "    honorific_name = honorific_name.replace('.','').replace(',','').lower().strip()\n",
    "    \n",
    "    # try the easy way first (find and remove honorific)\n",
    "    honorific_match = re.match(honorific_regex, honorific_name)\n",
    "    if honorific_match:\n",
    "        name = honorific_name[honorific_match.span()[1]+1:]\n",
    "        if name in mps.keys():\n",
    "            return mps[name]\n",
    "        \n",
    "        # seems quite common for them to write \"asked\" twice in the hansard proceedings\n",
    "        last_asked = name.rfind(' asked')\n",
    "        if last_asked and name[:last_asked] in mps.keys():\n",
    "            return mps[name[:last_asked]]\n",
    "\n",
    "        # slightly harder way (rearranging words)\n",
    "        for mp_name in mp_names:\n",
    "            mp_name_words = set(mp_name.split(' '))\n",
    "            name_words = set(name.split(' '))\n",
    "            if mp_name_words == name_words:\n",
    "                if (honorific_name, mp_name) not in alr_matched:\n",
    "                    #print(f'rearranging matched {honorific_name} to {mp_name}')\n",
    "                    alr_matched.add((honorific_name, mp_name))\n",
    "                return mps[mp_name]\n",
    "            \n",
    "            # for omission of chinese name\n",
    "            if len(mp_name_words) - len(name_words) <= 2 and len(name_words) >= 2 and name_words.issubset(mp_name_words):\n",
    "                if (honorific_name, mp_name) not in alr_matched:\n",
    "                    print(f'allowing omitted words in name matched {honorific_name} to {mp_name}')\n",
    "                    alr_matched.add((honorific_name, mp_name))\n",
    "                return mps[mp_name]\n",
    "                \n",
    "    digit_match = re.search('\\d+', honorific_name)\n",
    "    if digit_match:\n",
    "        # names shldn't have digits\n",
    "        honorific_name = honorific_name[digit_match.span()[1]:]\n",
    "        return honorific_name_to_mp_data(honorific_name)\n",
    "        \n",
    "    # the hard way (levenshtein)\n",
    "    closest_name = levenshtein_best_match(honorific_name, mp_names)\n",
    "    \n",
    "    if (honorific_name, closest_name) not in alr_matched:\n",
    "        print(f'levenshtein matched {honorific_name} to {closest_name}')\n",
    "        alr_matched.add((honorific_name, closest_name))\n",
    "    return mps[closest_name]\n",
    "\n",
    "def levenshtein_best_match(value, options):\n",
    "    min_levenshtein = 99999\n",
    "    min_val = None\n",
    "    for option in options:\n",
    "        l_dist = levenshtein(option, value)\n",
    "        if l_dist < min_levenshtein:\n",
    "            min_levenshtein = l_dist\n",
    "            min_val = option\n",
    "    return min_val\n",
    "            \n",
    "\n",
    "# borrowed from: https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/\n",
    "# we use levenshtein as it helps to protect against typos too, like the \"asked asked\" in:\n",
    "# https://sprs.parl.gov.sg/search/sprs3topic?reportid=oral-answer-2822\n",
    "def levenshtein(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2eee96-c726-4f73-a0ab-a5b630687de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pqs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b55804-1d18-45fa-8518-78a1bacdc56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportSection(Enum):\n",
    "    WRITTEN = 'Written Answers to Questions'\n",
    "    WRITTEN_NA = 'Written Answers to Questions for Oral Answer Not Answered by End of Question Time'\n",
    "    ORAL = 'Oral Answers to Questions'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759f4b8-16fc-4450-a923-8bac17a53f4f",
   "metadata": {},
   "source": [
    "we assume that all pqs are prefaced with #. (non sprs) or # (sprs). ignore follow up qns since we are only interested in mapping mps to topics, and the follow up qns will always be from the same mp and on the same topic.\n",
    "\n",
    "notes regarding minister titles:\n",
    "* Minister for Culture, Community and Youth is the only minister title with a comma\n",
    "* but there used to be Minister for Information, Communication and the Arts and Minister for Community Development, Youth and Sports\n",
    "* no questions were ever directed to minister mentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd366a7a-0882-4584-a7ec-423a6a23fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_word = r'[A-Z][a-z]+'\n",
    "cap_words = f'({cap_word})( {cap_word})*'\n",
    "mccy = '(Acting )?Minister for Culture, Community and Youth'\n",
    "mica = '(Acting )?Minister for Information, Communications and the Arts'\n",
    "mcdys = '(Acting )?Minister for Community Development, Youth( and|,) Sports'\n",
    "micma = 'Minister-in-charge of Muslim Affairs'\n",
    "minister_for_something = f'({cap_words} )?Minister (for|of) (the )?{cap_words}( and (the )?{cap_words})?'\n",
    "something_minister = f'{cap_words} Minister'\n",
    "one_minister_regex = f'(({mccy})|({mica})|({mcdys})|({micma})|({minister_for_something})|({something_minister}))'\n",
    "minister_regex = re.compile(f'{one_minister_regex}( and (the )?{one_minister_regex})?') # can have multiple targets\n",
    "\n",
    "def first_two_capitalized(words):\n",
    "    return words[0][0].isupper() and words[1][0].isupper() and words[0][1] and words[0][1].islower()\n",
    "\n",
    "def trim_off_non_pq_content_at_start(para):\n",
    "    para_words = para.split(' ')\n",
    "    if first_two_capitalized(para_words):\n",
    "        return para\n",
    "    \n",
    "    # i assume honorific+name has at least two words capitalized and non-numbers\n",
    "    while not first_two_capitalized(para_words):\n",
    "        para_words = para_words[1:]\n",
    "    \n",
    "    return ' '.join(para_words)\n",
    "\n",
    "def get_ministers_and_question(para):\n",
    "    minister_match = re.search(minister_regex, para)\n",
    "    if not minister_match:\n",
    "        # report might've been in the wrong case; try to match to existing ministers\n",
    "        minister_match = re.search(\n",
    "            '(' + '|'.join(list(map(lambda s: s.lower().replace(' for ', '.{1,5}'), ministers_found))) + ')',\n",
    "            para.lower()\n",
    "        )\n",
    "        if not minister_match:\n",
    "            minister_match = re.search(\n",
    "            '(' + '|'.join(list(map(lambda s: s.lower().replace(' for ', '(\\s)*(for|of)(\\s)*'), ministers_found))) + ')',\n",
    "            para.lower()\n",
    "        )\n",
    "        if not minister_match:\n",
    "            for existing_minister in ministers_found:\n",
    "                if existing_minister.replace(' ', '') in para.replace(' ', ''):\n",
    "                    minister_match = re.search('(\\s)?'.join(c for c in existing_minister.replace(' ', '').lower()), para.lower())\n",
    "                    break\n",
    "        min_minister = levenshtein_best_match(minister_match.group(), ministers_found)\n",
    "        print(f'found minister: {str(minister_match.group())}; matched to {min_minister}')\n",
    "        askee = min_minister\n",
    "    else:\n",
    "        askee = para[:minister_match.span()[1]].replace(' of ', ' for ')\n",
    "        ministers_found.add(askee)\n",
    "    question = para[minister_match.span()[1]:].strip()\n",
    "    if ' and Leader' in askee:\n",
    "        askee = askee[:-11]\n",
    "        print(f'removed \"and leader\" from {askee}')\n",
    "    \n",
    "    if not re.search('and (the )?Minister', askee):\n",
    "        return (askee,), question   \n",
    "    else:\n",
    "        askee = askee.replace('and the Minister', 'and Minister')\n",
    "        askees = askee.split(' and Minister')\n",
    "        return (askees[0], 'Minister' + askees[1]), question\n",
    "\n",
    "def soup_to_pqs(soup, file):\n",
    "    # seems to happen quite often\n",
    "    if soup.get_text() == '':\n",
    "        return\n",
    "    \n",
    "    stripped_strings = list(map(\n",
    "        lambda text: re.sub(r'\\s+', ' ', text),\n",
    "        filter(\n",
    "            lambda text: not re.match(r'Page:\\s+\\d+', text) and not re.match(r'Column:\\s+\\d+', text),\n",
    "            [text for text in soup.stripped_strings])))\n",
    "    parl_no = int(stripped_strings[3])\n",
    "    sess_no = int(stripped_strings[5])\n",
    "    vol_no = int(stripped_strings[7])\n",
    "    sitting_no = int(stripped_strings[9])\n",
    "    sitting_date = datetime.strptime(stripped_strings[11], '%d-%m-%Y')\n",
    "    section_name_raw = stripped_strings[13].lower()\n",
    "    \n",
    "    if 'answered' in section_name_raw:\n",
    "        section_name = ReportSection.WRITTEN_NA\n",
    "    elif 'written' in section_name_raw:\n",
    "        section_name = ReportSection.WRITTEN\n",
    "    elif 'oral' in section_name_raw:\n",
    "        section_name = ReportSection.ORAL\n",
    "    else:\n",
    "        raise f'no section name??? {section_name_raw}'\n",
    "    \n",
    "    title = stripped_strings[15]\n",
    "    the_rest = stripped_strings[19:]\n",
    "    while len(the_rest) > 0 and not re.match(r'\\d\\d?', the_rest[0]):\n",
    "        the_rest = the_rest[1:]\n",
    "        \n",
    "    if len(the_rest) == 0:\n",
    "        return\n",
    "        \n",
    "    indices_corresponding_to_pqs = []\n",
    "    indices_corresponding_to_speakers = []\n",
    "    maybe_more_pqs = True\n",
    "    for i in range(len(the_rest)):\n",
    "        if the_rest[i][0] == ':':\n",
    "            indices_corresponding_to_speakers.append(i-1)\n",
    "            maybe_more_pqs = False\n",
    "        elif re.match(r'\\d\\d?', the_rest[i]) and maybe_more_pqs:\n",
    "            indices_corresponding_to_pqs.append(i)\n",
    "        \n",
    "    pq_sublists = []\n",
    "    pq_qn_indices = []\n",
    "    while len(indices_corresponding_to_pqs) > 1:\n",
    "        pq_qn_indices.append(the_rest[indices_corresponding_to_pqs[0]])\n",
    "        pq_sublists.append(the_rest[indices_corresponding_to_pqs[0]+1:indices_corresponding_to_pqs[1]])\n",
    "        indices_corresponding_to_pqs = indices_corresponding_to_pqs[1:]\n",
    "        \n",
    "    pq_qn_indices.append(the_rest[indices_corresponding_to_pqs[0]])\n",
    "    pq_sublists.append(the_rest[indices_corresponding_to_pqs[0]+1:indices_corresponding_to_speakers[0]])\n",
    "    \n",
    "    speaking_sublists = []\n",
    "    \n",
    "    while len(indices_corresponding_to_speakers) > 1:\n",
    "        speaking_sublists.append(the_rest[indices_corresponding_to_speakers[0]:indices_corresponding_to_speakers[1]])\n",
    "        indices_corresponding_to_speakers = indices_corresponding_to_speakers[1:]\n",
    "    \n",
    "    speaking_sublists.append(the_rest[indices_corresponding_to_speakers[0]:])\n",
    "    \n",
    "    new_pqs = []\n",
    "    new_pq_indices = []\n",
    "    \n",
    "    for pq_i, sl in zip(pq_qn_indices, pq_sublists):\n",
    "        pq_para = ' '.join(sl)\n",
    "        \n",
    "        #pq_para = trim_off_non_pq_content_at_start(pq_para) # sometimes we end up mistaking other numbers in the text as being the pq numbers. so we deal w that here.\n",
    "        if ' asked the ' not in pq_para:\n",
    "            continue\n",
    "        asker_honorific_name, pq_para = pq_para.split(' asked the ', 1)    \n",
    "        ministers, question = get_ministers_and_question(pq_para)\n",
    "\n",
    "        if question[0] == ',':\n",
    "            question = question[1:].strip()\n",
    "        if len(asker_honorific_name.strip()) == 0:\n",
    "            return\n",
    "        asker, asker_party, asker_parls = honorific_name_to_mp_data(asker_honorific_name.strip())\n",
    "        new_pq_indices.append(int(pq_i))\n",
    "        new_pqs.append([asker, asker_party, asker_parls, ministers, question, parl_no, sess_no, vol_no, sitting_no, sitting_date, section_name, title])\n",
    "    \n",
    "    speakers_and_spokens = []\n",
    "    for sl in speaking_sublists:\n",
    "        speaker = sl[0]\n",
    "        if 'speaker' in speaker.lower():\n",
    "            continue\n",
    "        spoken = ' '.join(sl[1:])\n",
    "        while not spoken[0].isalpha():\n",
    "            spoken = spoken[1:]\n",
    "        if spoken[:len('Question No')] == 'Question No':\n",
    "            continue\n",
    "        speaker = re.sub(minister_regex, '', speaker)\n",
    "        speaker = re.sub(f'\\(for the .*\\)', '', speaker)\n",
    "        speaker = re.sub(f'\\(on behalf of the .*\\)', '', speaker)\n",
    "        in_bracket_honorific_match = re.search(f'\\({honorific_regex}.+\\)', speaker.lower())\n",
    "        if in_bracket_honorific_match:\n",
    "            honorific_match_group = in_bracket_honorific_match.group()[1:-1]\n",
    "            if len(honorific_match_group) == 0:\n",
    "                return\n",
    "            speaker = honorific_name_to_mp_data(honorific_match_group)[0]\n",
    "        else:\n",
    "            speaker = re.sub(f'\\(.+\\)', '', speaker)\n",
    "            if len(speaker) == 0:\n",
    "                return\n",
    "            speaker = honorific_name_to_mp_data(speaker)[0]\n",
    "        speakers_and_spokens.append([speaker, spoken])\n",
    "        \n",
    "    assert len(new_pqs) == len(new_pq_indices)\n",
    "        \n",
    "    if len(new_pqs) == 0:\n",
    "        return\n",
    "        \n",
    "    # only 1 pq was asked. so everything else in the file must be related to that pq.\n",
    "    if len(new_pqs) == 1:\n",
    "        responder, response = speakers_and_spokens[0]\n",
    "        new_pqs[0].append(responder)\n",
    "        new_pqs[0].append(response)\n",
    "        follow_ups = speakers_and_spokens[1:]\n",
    "        new_pqs[0].append(follow_ups)\n",
    "        pqs.append(new_pqs[0])\n",
    "        return\n",
    "    \n",
    "    if len(speakers_and_spokens) == 0:\n",
    "        for new_pq in new_pqs:\n",
    "            new_pq.append('')\n",
    "            new_pq.append('')\n",
    "            new_pq.append([])\n",
    "            pqs.append(new_pq)\n",
    "        return\n",
    "    \n",
    "    # only 1 person spoke after all the pqs were asked. so this person must be responding to all the pqs.\n",
    "    if len(speakers_and_spokens) == 1:\n",
    "        responder, response = speakers_and_spokens[0]\n",
    "        for new_pq in new_pqs:\n",
    "            new_pq.append(responder)\n",
    "            new_pq.append(response)\n",
    "            new_pq.append([]) # no follow-ups after main response\n",
    "            pqs.append(new_pq)\n",
    "        return\n",
    "\n",
    "    # past this point, the html file has more than one pq, and more than one response to those pqs. \n",
    "    assert len(new_pqs) > 1\n",
    "    assert len(speakers_and_spokens) > 1\n",
    "    \n",
    "    relevant_followups = dict.fromkeys(new_pq_indices, [])\n",
    "    first_response = speakers_and_spokens[0][1]\n",
    "    qn_indices_covered_by_first_response = set()\n",
    "    range_match = re.search(r'\\d+ to \\d+', first_response)\n",
    "    if range_match:\n",
    "        qn_indices_covered_by_first_response = qn_indices_covered_by_first_response.union(set(range(*list(map(int, range_match.group().split(' to '))))))\n",
    "    range_match = re.search(r'\\d+( )?-( )?\\d+', first_response)\n",
    "    if range_match:\n",
    "        qn_indices_covered_by_first_response = qn_indices_covered_by_first_response.union(set(range(*list(map(int, range_match.group().split('-'))))))\n",
    "    qn_indices_covered_by_first_response = qn_indices_covered_by_first_response.union(set(map(int, re.findall(r'\\d+', first_response))))\n",
    "    if set(new_pq_indices).issubset(qn_indices_covered_by_first_response) or 'all' in first_response or 'together' in first_response:\n",
    "        # the first responder is responding to all the questions at once. \n",
    "        for pq_i in new_pq_indices:\n",
    "            # speakers_and_spokens[0] is asking for permission to answer all qns at once. speakers_and_spokens[1] is the actual response.\n",
    "            relevant_followups[pq_i].append(speakers_and_spokens[1])\n",
    "        speakers_and_spokens = speakers_and_spokens[2:]\n",
    "    else:\n",
    "        print(\"i genuinely don't think we'll reach this point. but if we do, find out which questions this current response is addressing\")\n",
    "        print('rmb to remove the consumed entries from speakers_and_spokens')\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "    \n",
    "    # no follow-ups after main response\n",
    "    if len(speakers_and_spokens) == 0:\n",
    "        for new_pq_i, new_pq in zip(new_pq_indices, new_pqs):\n",
    "            new_pq.append(relevant_followups[new_pq_i][0]) # responder\n",
    "            new_pq.append(relevant_followups[new_pq_i][1]) # response\n",
    "            new_pq.append([])\n",
    "            pqs.append(new_pq)\n",
    "        return\n",
    "    \n",
    "    # gotta map everything that is said, to the relevant pqs. \n",
    "    asker_to_new_pqi = dict()\n",
    "    for new_pq_i, new_pq in zip(new_pq_indices, new_pqs):\n",
    "        asker_to_new_pqi[new_pq[0]] = new_pq_i\n",
    "        \n",
    "    pqs_with_new_responses_since_last_time_first_responder_spoke = []\n",
    "        \n",
    "    for i in range(len(speakers_and_spokens)):\n",
    "        speaker, spoken = speakers_and_spokens[i]\n",
    "        if speaker in asker_to_new_pqi.keys(): # something is said by someone who asked a pq. so it's relevant to that pq. \n",
    "            relevant_followups[asker_to_new_pqi[speaker]].append([speaker, spoken])\n",
    "            pqs_with_new_responses_since_last_time_first_responder_spoke.append(asker_to_new_pqi[speaker])\n",
    "            continue\n",
    "        \n",
    "        # something is said by someone who did not ask any pqs. \n",
    "        if speaker == first_response[0]:\n",
    "            # might be the original responder, responding to some followup qns. \n",
    "            # find out which qns these are by seeing who said stuff since the last time this guy spoke.\n",
    "            for pq_with_new_response in pqs_with_new_responses_since_last_time_first_responder_spoke:\n",
    "                relevant_followups[pq_with_new_response].append([speaker, spoken])\n",
    "            pqs_with_new_responses_since_last_time_first_responder_spoke = []\n",
    "            continue\n",
    "        else:\n",
    "            # otherwise, it's a follow-up qn from someone originally unrelated. \n",
    "            # we needa think of a way to determine which qn it's following up on.\n",
    "            pqs_with_new_responses_since_last_time_first_responder_spoke\n",
    "            print(file)\n",
    "            \n",
    "        \n",
    "    \n",
    "    #st()\n",
    "    # time to match the follow-up questions to the relevant pqs.\n",
    "    # print(file)\n",
    "    \n",
    "    \n",
    "    # do someth with new_pqs. not added to main list yet.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0314366-9a4d-4d9e-b74d-9fd5ebfd7830",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sprs3topic_reportid=oral-answer-1338.html\n",
      "sprs3topic_reportid=oral-answer-1338.html\n",
      "sprs3topic_reportid=oral-answer-1338.html\n",
      "sprs3topic_reportid=oral-answer-1338.html\n",
      "sprs3topic_reportid=oral-answer-1338.html\n",
      "sprs3topic_reportid=oral-answer-1355.html\n",
      "sprs3topic_reportid=oral-answer-1355.html\n",
      "sprs3topic_reportid=oral-answer-1355.html\n",
      "sprs3topic_reportid=oral-answer-1355.html\n",
      "sprs3topic_reportid=oral-answer-1355.html\n",
      "sprs3topic_reportid=oral-answer-1355.html\n",
      "sprs3topic_reportid=oral-answer-1355.html\n",
      "sprs3topic_reportid=oral-answer-1355.html\n",
      "sprs3topic_reportid=oral-answer-1573.html\n",
      "sprs3topic_reportid=oral-answer-1850.html\n",
      "sprs3topic_reportid=oral-answer-1850.html\n",
      "sprs3topic_reportid=oral-answer-1850.html\n",
      "sprs3topic_reportid=oral-answer-1850.html\n",
      "sprs3topic_reportid=oral-answer-1850.html\n",
      "sprs3topic_reportid=oral-answer-1850.html\n",
      "sprs3topic_reportid=oral-answer-1850.html\n",
      "sprs3topic_reportid=oral-answer-1850.html\n",
      "sprs3topic_reportid=oral-answer-1850.html\n",
      "sprs3topic_reportid=oral-answer-1850.html\n",
      "sprs3topic_reportid=oral-answer-1850.html\n",
      "sprs3topic_reportid=oral-answer-1850.html\n",
      "sprs3topic_reportid=oral-answer-1850.html\n",
      "sprs3topic_reportid=oral-answer-1850.html\n",
      "sprs3topic_reportid=oral-answer-1861.html\n",
      "sprs3topic_reportid=oral-answer-1861.html\n",
      "sprs3topic_reportid=oral-answer-1861.html\n",
      "sprs3topic_reportid=oral-answer-1861.html\n",
      "sprs3topic_reportid=oral-answer-1893.html\n",
      "sprs3topic_reportid=oral-answer-1893.html\n",
      "sprs3topic_reportid=oral-answer-1893.html\n",
      "sprs3topic_reportid=oral-answer-1893.html\n",
      "sprs3topic_reportid=oral-answer-1893.html\n",
      "sprs3topic_reportid=oral-answer-1893.html\n",
      "sprs3topic_reportid=oral-answer-1893.html\n",
      "sprs3topic_reportid=oral-answer-1893.html\n",
      "allowing omitted words in name matched mr murali pillai to murali pillai sc\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "sprs3topic_reportid=oral-answer-1965.html\n",
      "allowing omitted words in name matched mr alex yam to alex yam ziming\n",
      "levenshtein matched mr masagos zulkifli b m m to masagos zulkifli bin masagos mohamad\n",
      "sprs3topic_reportid=oral-answer-2001.html\n",
      "sprs3topic_reportid=oral-answer-2001.html\n",
      "sprs3topic_reportid=oral-answer-2001.html\n",
      "sprs3topic_reportid=oral-answer-2001.html\n",
      "sprs3topic_reportid=oral-answer-2001.html\n",
      "sprs3topic_reportid=oral-answer-2045.html\n",
      "sprs3topic_reportid=oral-answer-2045.html\n",
      "sprs3topic_reportid=oral-answer-2045.html\n",
      "sprs3topic_reportid=oral-answer-2045.html\n",
      "sprs3topic_reportid=oral-answer-2045.html\n",
      "sprs3topic_reportid=oral-answer-2069.html\n",
      "sprs3topic_reportid=oral-answer-2069.html\n",
      "sprs3topic_reportid=oral-answer-2069.html\n",
      "sprs3topic_reportid=oral-answer-2069.html\n",
      "sprs3topic_reportid=oral-answer-2069.html\n",
      "sprs3topic_reportid=oral-answer-2069.html\n",
      "sprs3topic_reportid=oral-answer-2069.html\n",
      "found minister: minister for transport; matched to Minister for Transport\n",
      "sprs3topic_reportid=oral-answer-2080.html\n",
      "sprs3topic_reportid=oral-answer-2080.html\n",
      "sprs3topic_reportid=oral-answer-2080.html\n",
      "sprs3topic_reportid=oral-answer-2080.html\n",
      "sprs3topic_reportid=oral-answer-21.html\n",
      "sprs3topic_reportid=oral-answer-21.html\n",
      "sprs3topic_reportid=oral-answer-21.html\n",
      "sprs3topic_reportid=oral-answer-21.html\n",
      "sprs3topic_reportid=oral-answer-21.html\n",
      "sprs3topic_reportid=oral-answer-21.html\n",
      "sprs3topic_reportid=oral-answer-2103.html\n",
      "sprs3topic_reportid=oral-answer-2103.html\n",
      "sprs3topic_reportid=oral-answer-2103.html\n",
      "sprs3topic_reportid=oral-answer-2103.html\n",
      "sprs3topic_reportid=oral-answer-2239.html\n",
      "sprs3topic_reportid=oral-answer-2241.html\n",
      "sprs3topic_reportid=oral-answer-2241.html\n",
      "sprs3topic_reportid=oral-answer-2241.html\n",
      "sprs3topic_reportid=oral-answer-2241.html\n",
      "sprs3topic_reportid=oral-answer-2241.html\n",
      "sprs3topic_reportid=oral-answer-2241.html\n",
      "sprs3topic_reportid=oral-answer-2241.html\n",
      "sprs3topic_reportid=oral-answer-2267.html\n",
      "sprs3topic_reportid=oral-answer-2267.html\n",
      "sprs3topic_reportid=oral-answer-2267.html\n",
      "sprs3topic_reportid=oral-answer-2267.html\n",
      "sprs3topic_reportid=oral-answer-2267.html\n",
      "sprs3topic_reportid=oral-answer-2267.html\n",
      "sprs3topic_reportid=oral-answer-2267.html\n",
      "sprs3topic_reportid=oral-answer-2267.html\n",
      "sprs3topic_reportid=oral-answer-2267.html\n",
      "sprs3topic_reportid=oral-answer-2267.html\n",
      "sprs3topic_reportid=oral-answer-2267.html\n",
      "sprs3topic_reportid=oral-answer-2267.html\n",
      "sprs3topic_reportid=oral-answer-2267.html\n",
      "sprs3topic_reportid=oral-answer-2272.html\n",
      "sprs3topic_reportid=oral-answer-2276.html\n",
      "sprs3topic_reportid=oral-answer-2276.html\n",
      "sprs3topic_reportid=oral-answer-2327.html\n",
      "sprs3topic_reportid=oral-answer-2327.html\n",
      "sprs3topic_reportid=oral-answer-2327.html\n",
      "sprs3topic_reportid=oral-answer-2327.html\n",
      "sprs3topic_reportid=oral-answer-2327.html\n",
      "sprs3topic_reportid=oral-answer-2354.html\n",
      "sprs3topic_reportid=oral-answer-2354.html\n",
      "sprs3topic_reportid=oral-answer-2354.html\n",
      "sprs3topic_reportid=oral-answer-2354.html\n",
      "sprs3topic_reportid=oral-answer-2354.html\n",
      "sprs3topic_reportid=oral-answer-2354.html\n",
      "sprs3topic_reportid=oral-answer-2363.html\n",
      "sprs3topic_reportid=oral-answer-2363.html\n",
      "sprs3topic_reportid=oral-answer-2363.html\n",
      "sprs3topic_reportid=oral-answer-2363.html\n",
      "sprs3topic_reportid=oral-answer-2363.html\n",
      "sprs3topic_reportid=oral-answer-2421.html\n",
      "sprs3topic_reportid=oral-answer-2442.html\n",
      "sprs3topic_reportid=oral-answer-2442.html\n",
      "sprs3topic_reportid=oral-answer-2442.html\n",
      "sprs3topic_reportid=oral-answer-2454.html\n",
      "sprs3topic_reportid=oral-answer-2454.html\n",
      "sprs3topic_reportid=oral-answer-2454.html\n",
      "sprs3topic_reportid=oral-answer-2454.html\n",
      "levenshtein matched assoc prof dr yaacob ibrahim to yaacob ibrahim\n",
      "sprs3topic_reportid=oral-answer-2487.html\n",
      "sprs3topic_reportid=oral-answer-2487.html\n",
      "sprs3topic_reportid=oral-answer-2487.html\n",
      "sprs3topic_reportid=oral-answer-2487.html\n",
      "sprs3topic_reportid=oral-answer-251.html\n",
      "sprs3topic_reportid=oral-answer-251.html\n",
      "sprs3topic_reportid=oral-answer-251.html\n",
      "sprs3topic_reportid=oral-answer-251.html\n",
      "sprs3topic_reportid=oral-answer-251.html\n",
      "sprs3topic_reportid=oral-answer-251.html\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('scraped_content')[0:100]:\n",
    "    filepath = os.path.join('scraped_content', file)\n",
    "    with open(filepath, 'r') as f:\n",
    "        soup = bs(f, 'html.parser')\n",
    "    try:\n",
    "        soup_to_pqs(soup, file)\n",
    "    except Exception as e:\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        raise e\n",
    "        #print(f'{str(e)} - {file}')\n",
    "        #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883514f5-2bfa-4845-b83e-3d4cfbb4c88e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pq_df = pd.DataFrame(pqs, columns=['asker_name', 'asker_party', 'asker_parliaments', 'askee', 'question', 'sitting_date', 'parliament_no', 'report_section'])\n",
    "pq_df.asker_party = pq_df.asker_party.apply(lambda x: x[0])\n",
    "pq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b10be6-e33f-4d37-9194-0f2c9936a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pq_df.to_csv('pqs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda24a8-34bc-42ad-bc1f-6dc220aae435",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(pq_df.parliament_no < 15) and all(pq_df.parliament_no >= 12)\n",
    "assert all(map(lambda x: not x[0].isupper(), pq_df.question.values)) \n",
    "assert all(map(lambda x: not x[:3] == 'and', pq_df.question.values)) \n",
    "parties_set = set(pq_df.asker_party.values)\n",
    "print(f'parties: {parties_set} (len: {len(parties_set)})')\n",
    "print()\n",
    "askee_set = set([askee for sublist in pq_df.askee for askee in sublist])\n",
    "print(f'askees: {askee_set} (len: {len(askee_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90b30e-8e35-4dfb-93f2-b5d381b26033",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(pq_df.asker_name.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c547b906-6b9c-4934-ac3d-9b8c3a345c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 999\n",
    "min_mp = None\n",
    "max_count = 0\n",
    "max_mp = None\n",
    "less_than_ten = 0\n",
    "for name in pq_df.asker_name.values:\n",
    "    count_here = pq_df[pq_df.asker_name == name]['asker_name'].count()\n",
    "    if count_here < min_count:\n",
    "        min_count = count_here\n",
    "        min_mp = name\n",
    "    if count_here > max_count:\n",
    "        max_count = count_here\n",
    "        max_mp = name\n",
    "    if count_here < 10:\n",
    "        less_than_ten += 1\n",
    "        \n",
    "min_count, min_mp, max_count, max_mp, less_than_ten"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
